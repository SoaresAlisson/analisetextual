<!DOCTYPE html>
<html lang="pt-br" xml:lang="pt-br">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 8 Análise Textual (text mining) | Introdução à Análise Textual aplicada à Sociologia</title>
  <meta name="description" content="Este é um manual em progresso destinado à análise textual aplicada às ciências sociais, priorizando materiais gratuitos e de código aberto." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 8 Análise Textual (text mining) | Introdução à Análise Textual aplicada à Sociologia" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Este é um manual em progresso destinado à análise textual aplicada às ciências sociais, priorizando materiais gratuitos e de código aberto." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 8 Análise Textual (text mining) | Introdução à Análise Textual aplicada à Sociologia" />
  
  <meta name="twitter:description" content="Este é um manual em progresso destinado à análise textual aplicada às ciências sociais, priorizando materiais gratuitos e de código aberto." />
  

<meta name="author" content="Alisson Soares" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="visualização-de-dados.html"/>
<link rel="next" href="text-mining-semantic-parsing.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Análise Textual</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="objetivos-deste-manual.html"><a href="objetivos-deste-manual.html"><i class="fa fa-check"></i>Objetivos deste manual</a>
<ul>
<li class="chapter" data-level="" data-path="objetivos-deste-manual.html"><a href="objetivos-deste-manual.html#plano-do-livro"><i class="fa fa-check"></i>Plano do livro</a></li>
<li class="chapter" data-level="" data-path="objetivos-deste-manual.html"><a href="objetivos-deste-manual.html#HD"><i class="fa fa-check"></i>O termo “humanidade digitais”</a></li>
<li class="chapter" data-level="" data-path="objetivos-deste-manual.html"><a href="objetivos-deste-manual.html#fluxo-de-trabalho"><i class="fa fa-check"></i>Fluxo de trabalho</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="história-da-análise-textual.html"><a href="história-da-análise-textual.html"><i class="fa fa-check"></i><b>1</b> História da Análise Textual</a>
<ul>
<li class="chapter" data-level="1.1" data-path="história-da-análise-textual.html"><a href="história-da-análise-textual.html#linha-do-tempo-da-história-da-análise-textual"><i class="fa fa-check"></i><b>1.1</b> Linha do tempo da história da Análise Textual</a></li>
<li class="chapter" data-level="1.2" data-path="história-da-análise-textual.html"><a href="história-da-análise-textual.html#história-da-análise-textual-técnicas-antes-do-uso-de-computadores"><i class="fa fa-check"></i><b>1.2</b> História da análise textual: Técnicas antes do uso de computadores</a></li>
<li class="chapter" data-level="1.3" data-path="história-da-análise-textual.html"><a href="história-da-análise-textual.html#história-da-análise-textual-análise-textual-com-auxílio-de-computadores"><i class="fa fa-check"></i><b>1.3</b> História da análise textual: Análise Textual com auxílio de computadores</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="história-da-análise-textual.html"><a href="história-da-análise-textual.html#o-problema-das-digitais-linguísticas-linguistic-fingerprint"><i class="fa fa-check"></i><b>1.3.1</b> O problema das “digitais linguísticas” (<em>linguistic fingerprint</em>)</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="história-da-análise-textual.html"><a href="história-da-análise-textual.html#história-da-análise-textual-a-inteligência-artificial-machine-learning"><i class="fa fa-check"></i><b>1.4</b> História da análise textual: A inteligência artificial, machine learning</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="exemplos-de-pesquisas-em-humanidades-digitais.html"><a href="exemplos-de-pesquisas-em-humanidades-digitais.html"><i class="fa fa-check"></i><b>2</b> Exemplos de Pesquisas em Humanidades Digitais</a>
<ul>
<li class="chapter" data-level="2.1" data-path="exemplos-de-pesquisas-em-humanidades-digitais.html"><a href="exemplos-de-pesquisas-em-humanidades-digitais.html#bibliometria-cientometria-cienciometria"><i class="fa fa-check"></i><b>2.1</b> Bibliometria / cientometria / cienciometria</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="exemplos-de-pesquisas-em-humanidades-digitais.html"><a href="exemplos-de-pesquisas-em-humanidades-digitais.html#exemplo-filósofos-da-ciência-na-sociologia"><i class="fa fa-check"></i><b>2.1.1</b> Exemplo: Filósofos da ciência na Sociologia</a></li>
<li class="chapter" data-level="2.1.2" data-path="exemplos-de-pesquisas-em-humanidades-digitais.html"><a href="exemplos-de-pesquisas-em-humanidades-digitais.html#exemplo-a-teoria-dos-sistemas-sociais-de-niklas-luhmann"><i class="fa fa-check"></i><b>2.1.2</b> Exemplo: A teoria dos sistemas sociais de Niklas Luhmann</a></li>
<li class="chapter" data-level="2.1.3" data-path="exemplos-de-pesquisas-em-humanidades-digitais.html"><a href="exemplos-de-pesquisas-em-humanidades-digitais.html#exemplo-tendência-de-termos-chave-da-sociologia"><i class="fa fa-check"></i><b>2.1.3</b> Exemplo: Tendência de termos chave da Sociologia</a></li>
<li class="chapter" data-level="2.1.4" data-path="exemplos-de-pesquisas-em-humanidades-digitais.html"><a href="exemplos-de-pesquisas-em-humanidades-digitais.html#exemplo-tendências-das-correntes-na-filosofia"><i class="fa fa-check"></i><b>2.1.4</b> Exemplo: Tendências das correntes na filosofia</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="exemplos-de-pesquisas-em-humanidades-digitais.html"><a href="exemplos-de-pesquisas-em-humanidades-digitais.html#exGoogleTrends"><i class="fa fa-check"></i><b>2.2</b> Exemplo: Google Trends como Proxy para epidemias</a></li>
<li class="chapter" data-level="2.3" data-path="exemplos-de-pesquisas-em-humanidades-digitais.html"><a href="exemplos-de-pesquisas-em-humanidades-digitais.html#ExFakesNewsMundo"><i class="fa fa-check"></i><b>2.3</b> Exemplo: Como as fake news sobre a pandemia de Covid-19 se assemelham/divergem entre os países?</a></li>
<li class="chapter" data-level="2.4" data-path="exemplos-de-pesquisas-em-humanidades-digitais.html"><a href="exemplos-de-pesquisas-em-humanidades-digitais.html#exemplo-mudança-de-significado-de-palavras"><i class="fa fa-check"></i><b>2.4</b> Exemplo: Mudança de significado de palavras</a></li>
<li class="chapter" data-level="2.5" data-path="exemplos-de-pesquisas-em-humanidades-digitais.html"><a href="exemplos-de-pesquisas-em-humanidades-digitais.html#exemplo-análise-de-complexidade-musical"><i class="fa fa-check"></i><b>2.5</b> Exemplo: Análise de complexidade musical</a></li>
<li class="chapter" data-level="2.6" data-path="exemplos-de-pesquisas-em-humanidades-digitais.html"><a href="exemplos-de-pesquisas-em-humanidades-digitais.html#riqueza-vocabulário"><i class="fa fa-check"></i><b>2.6</b> Riqueza vocabulário</a></li>
<li class="chapter" data-level="2.7" data-path="exemplos-de-pesquisas-em-humanidades-digitais.html"><a href="exemplos-de-pesquisas-em-humanidades-digitais.html#exemplo-polarização"><i class="fa fa-check"></i><b>2.7</b> Exemplo: Polarização</a></li>
<li class="chapter" data-level="2.8" data-path="exemplos-de-pesquisas-em-humanidades-digitais.html"><a href="exemplos-de-pesquisas-em-humanidades-digitais.html#exemplo-de-integração-quali-quanti-complementando-dados-qualitativos"><i class="fa fa-check"></i><b>2.8</b> Exemplo de integração quali-quanti: Complementando dados qualitativos</a></li>
<li class="chapter" data-level="2.9" data-path="exemplos-de-pesquisas-em-humanidades-digitais.html"><a href="exemplos-de-pesquisas-em-humanidades-digitais.html#exemplo-de-integração-quali-quanti-depurando-dados-quantitativos"><i class="fa fa-check"></i><b>2.9</b> Exemplo de integração quali-quanti: Depurando dados quantitativos</a></li>
<li class="chapter" data-level="2.10" data-path="exemplos-de-pesquisas-em-humanidades-digitais.html"><a href="exemplos-de-pesquisas-em-humanidades-digitais.html#exemplo-processo-civilizador"><i class="fa fa-check"></i><b>2.10</b> Exemplo: Processo Civilizador</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="estrutura-de-dados-e-tipos-de-formatos.html"><a href="estrutura-de-dados-e-tipos-de-formatos.html"><i class="fa fa-check"></i><b>3</b> Estrutura de dados e tipos de formatos</a>
<ul>
<li class="chapter" data-level="3.1" data-path="estrutura-de-dados-e-tipos-de-formatos.html"><a href="estrutura-de-dados-e-tipos-de-formatos.html#dados-estruturados"><i class="fa fa-check"></i><b>3.1</b> Dados estruturados</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="estrutura-de-dados-e-tipos-de-formatos.html"><a href="estrutura-de-dados-e-tipos-de-formatos.html#os-formatos-csv-comma-separeted-values-e-tsv."><i class="fa fa-check"></i><b>3.1.1</b> Os formatos csv (<em>comma separeted values</em>) e tsv.</a></li>
<li class="chapter" data-level="3.1.2" data-path="estrutura-de-dados-e-tipos-de-formatos.html"><a href="estrutura-de-dados-e-tipos-de-formatos.html#formatoJson"><i class="fa fa-check"></i><b>3.1.2</b> O formato Json</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="estrutura-de-dados-e-tipos-de-formatos.html"><a href="estrutura-de-dados-e-tipos-de-formatos.html#dados-não-estruturados"><i class="fa fa-check"></i><b>3.2</b> Dados não estruturados</a></li>
<li class="chapter" data-level="3.3" data-path="estrutura-de-dados-e-tipos-de-formatos.html"><a href="estrutura-de-dados-e-tipos-de-formatos.html#dados-semi-estruturados"><i class="fa fa-check"></i><b>3.3</b> Dados semi-estruturados</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="estrutura-de-dados-e-tipos-de-formatos.html"><a href="estrutura-de-dados-e-tipos-de-formatos.html#exemplos-de-dados-semi-estruturados"><i class="fa fa-check"></i><b>3.3.1</b> Exemplos de dados semi-estruturados</a></li>
<li class="chapter" data-level="3.3.2" data-path="estrutura-de-dados-e-tipos-de-formatos.html"><a href="estrutura-de-dados-e-tipos-de-formatos.html#formatoMarkdown"><i class="fa fa-check"></i><b>3.3.2</b> O formato Markdown</a></li>
<li class="chapter" data-level="3.3.3" data-path="estrutura-de-dados-e-tipos-de-formatos.html"><a href="estrutura-de-dados-e-tipos-de-formatos.html#formatoYaml"><i class="fa fa-check"></i><b>3.3.3</b> O formato YAML</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="estrutura-de-dados-e-tipos-de-formatos.html"><a href="estrutura-de-dados-e-tipos-de-formatos.html#subtitulo"><i class="fa fa-check"></i><b>3.4</b> Subtitulo</a></li>
<li class="chapter" data-level="3.5" data-path="estrutura-de-dados-e-tipos-de-formatos.html"><a href="estrutura-de-dados-e-tipos-de-formatos.html#subtítulo-2"><i class="fa fa-check"></i><b>3.5</b> Subtítulo 2</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="estrutura-de-dados-e-tipos-de-formatos.html"><a href="estrutura-de-dados-e-tipos-de-formatos.html#formatoLatex"><i class="fa fa-check"></i><b>3.5.1</b> O Formato LaTex</a></li>
<li class="chapter" data-level="3.5.2" data-path="estrutura-de-dados-e-tipos-de-formatos.html"><a href="estrutura-de-dados-e-tipos-de-formatos.html#formatoBibtex"><i class="fa fa-check"></i><b>3.5.2</b> O formato BibTex</a></li>
<li class="chapter" data-level="3.5.3" data-path="estrutura-de-dados-e-tipos-de-formatos.html"><a href="estrutura-de-dados-e-tipos-de-formatos.html#formatosXmlHtml"><i class="fa fa-check"></i><b>3.5.3</b> Os formatos xml e html</a></li>
<li class="chapter" data-level="3.5.4" data-path="estrutura-de-dados-e-tipos-de-formatos.html"><a href="estrutura-de-dados-e-tipos-de-formatos.html#formatos-mais-raros"><i class="fa fa-check"></i><b>3.5.4</b> Formatos mais raros</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="estrutura-de-dados-e-tipos-de-formatos.html"><a href="estrutura-de-dados-e-tipos-de-formatos.html#observações-finais"><i class="fa fa-check"></i><b>3.6</b> Observações finais</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="noções-básicas-de-programação-em-r.html"><a href="noções-básicas-de-programação-em-r.html"><i class="fa fa-check"></i><b>4</b> Noções básicas de programação em R</a>
<ul>
<li class="chapter" data-level="4.1" data-path="noções-básicas-de-programação-em-r.html"><a href="noções-básicas-de-programação-em-r.html#sequências-de-scaping"><i class="fa fa-check"></i><b>4.1</b> Sequências de scaping</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="noções-básicas-de-programação-em-r.html"><a href="noções-básicas-de-programação-em-r.html#comentando-o-código"><i class="fa fa-check"></i><b>4.1.1</b> Comentando o código</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="noções-básicas-de-programação-em-r.html"><a href="noções-básicas-de-programação-em-r.html#variavel"><i class="fa fa-check"></i><b>4.2</b> Variável e atribuição</a></li>
<li class="chapter" data-level="4.3" data-path="noções-básicas-de-programação-em-r.html"><a href="noções-básicas-de-programação-em-r.html#funções-no-r"><i class="fa fa-check"></i><b>4.3</b> Funções no R</a></li>
<li class="chapter" data-level="4.4" data-path="noções-básicas-de-programação-em-r.html"><a href="noções-básicas-de-programação-em-r.html#condicionais-seentão-ifelse"><i class="fa fa-check"></i><b>4.4</b> Condicionais: se/então, If/else</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="noções-básicas-de-programação-em-r.html"><a href="noções-básicas-de-programação-em-r.html#else"><i class="fa fa-check"></i><b>4.4.1</b> Else</a></li>
<li class="chapter" data-level="4.4.2" data-path="noções-básicas-de-programação-em-r.html"><a href="noções-básicas-de-programação-em-r.html#else-if"><i class="fa fa-check"></i><b>4.4.2</b> else if</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="noções-básicas-de-programação-em-r.html"><a href="noções-básicas-de-programação-em-r.html#operadores"><i class="fa fa-check"></i><b>4.5</b> Operadores</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="noções-básicas-de-programação-em-r.html"><a href="noções-básicas-de-programação-em-r.html#operadores-de-atribuição-assignment"><i class="fa fa-check"></i><b>4.5.1</b> Operadores de atribuição (assignment)</a></li>
<li class="chapter" data-level="4.5.2" data-path="noções-básicas-de-programação-em-r.html"><a href="noções-básicas-de-programação-em-r.html#operadores-aritiméticos"><i class="fa fa-check"></i><b>4.5.2</b> Operadores Aritiméticos</a></li>
<li class="chapter" data-level="4.5.3" data-path="noções-básicas-de-programação-em-r.html"><a href="noções-básicas-de-programação-em-r.html#operadores_relacionais"><i class="fa fa-check"></i><b>4.5.3</b> Operadores relacionais</a></li>
<li class="chapter" data-level="4.5.4" data-path="noções-básicas-de-programação-em-r.html"><a href="noções-básicas-de-programação-em-r.html#operadores_booleanos"><i class="fa fa-check"></i><b>4.5.4</b> Operadores booleanos</a></li>
<li class="chapter" data-level="4.5.5" data-path="noções-básicas-de-programação-em-r.html"><a href="noções-básicas-de-programação-em-r.html#outros-operadores"><i class="fa fa-check"></i><b>4.5.5</b> Outros operadores</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="noções-básicas-de-programação-em-r.html"><a href="noções-básicas-de-programação-em-r.html#loops-repetições"><i class="fa fa-check"></i><b>4.6</b> Loops, repetições</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="noções-básicas-de-programação-em-r.html"><a href="noções-básicas-de-programação-em-r.html#for-loops"><i class="fa fa-check"></i><b>4.6.1</b> For Loops</a></li>
<li class="chapter" data-level="4.6.2" data-path="noções-básicas-de-programação-em-r.html"><a href="noções-básicas-de-programação-em-r.html#while-loop"><i class="fa fa-check"></i><b>4.6.2</b> While loop</a></li>
<li class="chapter" data-level="4.6.3" data-path="noções-básicas-de-programação-em-r.html"><a href="noções-básicas-de-programação-em-r.html#apply-lapply-sapply-tapply-e-mapply"><i class="fa fa-check"></i><b>4.6.3</b> apply (lapply, sapply, tapply e mapply)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="introdução-ao-r.html"><a href="introdução-ao-r.html"><i class="fa fa-check"></i><b>5</b> Introdução ao R</a>
<ul>
<li class="chapter" data-level="5.1" data-path="introdução-ao-r.html"><a href="introdução-ao-r.html#obtendo-ajuda-no-r"><i class="fa fa-check"></i><b>5.1</b> Obtendo Ajuda no R</a></li>
<li class="chapter" data-level="5.2" data-path="introdução-ao-r.html"><a href="introdução-ao-r.html#rcommander"><i class="fa fa-check"></i><b>5.2</b> R em modo gráfico: RKWard e RCommander</a></li>
<li class="chapter" data-level="5.3" data-path="introdução-ao-r.html"><a href="introdução-ao-r.html#RDataTypes"><i class="fa fa-check"></i><b>5.3</b> Tipos de Dados no R (data types)</a></li>
<li class="chapter" data-level="5.4" data-path="introdução-ao-r.html"><a href="introdução-ao-r.html#estrutura-de-dados-no-r-data-structures"><i class="fa fa-check"></i><b>5.4</b> Estrutura de dados no R (Data Structures)</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="introdução-ao-r.html"><a href="introdução-ao-r.html#vetor-vector"><i class="fa fa-check"></i><b>5.4.1</b> Vetor (vector)</a></li>
<li class="chapter" data-level="5.4.2" data-path="introdução-ao-r.html"><a href="introdução-ao-r.html#fatores"><i class="fa fa-check"></i><b>5.4.2</b> Fator (<em>Factor</em>)</a></li>
<li class="chapter" data-level="5.4.3" data-path="introdução-ao-r.html"><a href="introdução-ao-r.html#matrix"><i class="fa fa-check"></i><b>5.4.3</b> Matriz (Matrix)</a></li>
<li class="chapter" data-level="5.4.4" data-path="introdução-ao-r.html"><a href="introdução-ao-r.html#listas-list"><i class="fa fa-check"></i><b>5.4.4</b> Listas (<em>list</em>)</a></li>
<li class="chapter" data-level="5.4.5" data-path="introdução-ao-r.html"><a href="introdução-ao-r.html#dataframes"><i class="fa fa-check"></i><b>5.4.5</b> Data Frames</a></li>
<li class="chapter" data-level="5.4.6" data-path="introdução-ao-r.html"><a href="introdução-ao-r.html#considerações-finais-sobre-estrutura-de-dados"><i class="fa fa-check"></i><b>5.4.6</b> Considerações finais sobre estrutura de dados</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="introdução-ao-r.html"><a href="introdução-ao-r.html#instalandopacotes"><i class="fa fa-check"></i><b>5.5</b> Instalando pacotes no R</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="introdução-ao-r.html"><a href="introdução-ao-r.html#modo-1-instalando-via-linha-de-comando"><i class="fa fa-check"></i><b>5.5.1</b> Modo 1: instalando via linha de comando</a></li>
<li class="chapter" data-level="5.5.2" data-path="introdução-ao-r.html"><a href="introdução-ao-r.html#modo-2-modo-gráfico"><i class="fa fa-check"></i><b>5.5.2</b> Modo 2: Modo gráfico</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="introdução-ao-r.html"><a href="introdução-ao-r.html#tidyverse"><i class="fa fa-check"></i><b>5.6</b> A suíte de pacotes <code>tidyverse</code></a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="introdução-ao-r.html"><a href="introdução-ao-r.html#pipes"><i class="fa fa-check"></i><b>5.6.1</b> Pipes</a></li>
<li class="chapter" data-level="5.6.2" data-path="introdução-ao-r.html"><a href="introdução-ao-r.html#tibbles"><i class="fa fa-check"></i><b>5.6.2</b> Tibbles</a></li>
<li class="chapter" data-level="5.6.3" data-path="introdução-ao-r.html"><a href="introdução-ao-r.html#dplyr"><i class="fa fa-check"></i><b>5.6.3</b> Dplyr: Verbos (ou comandos)</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="introdução-ao-r.html"><a href="introdução-ao-r.html#RDataHora"><i class="fa fa-check"></i><b>5.7</b> Manipulando data e hora</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="introdução-ao-r.html"><a href="introdução-ao-r.html#gerando-uma-sequencia-de-datas-no-r"><i class="fa fa-check"></i><b>5.7.1</b> Gerando uma sequencia de datas no R</a></li>
<li class="chapter" data-level="5.7.2" data-path="introdução-ao-r.html"><a href="introdução-ao-r.html#lubridate"><i class="fa fa-check"></i><b>5.7.2</b> Lubridate: facilitando manipulação de datas</a></li>
<li class="chapter" data-level="5.7.3" data-path="introdução-ao-r.html"><a href="introdução-ao-r.html#converter-data-em-nome-por-extenso-do-mês"><i class="fa fa-check"></i><b>5.7.3</b> Converter data em nome por extenso do mês</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="normalização-de-texto-e-expressões-regulares.html"><a href="normalização-de-texto-e-expressões-regulares.html"><i class="fa fa-check"></i><b>6</b> Normalização de texto e Expressões Regulares</a>
<ul>
<li class="chapter" data-level="6.1" data-path="normalização-de-texto-e-expressões-regulares.html"><a href="normalização-de-texto-e-expressões-regulares.html#expressões-regulares-regex"><i class="fa fa-check"></i><b>6.1</b> Expressões regulares (RegEx)</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="normalização-de-texto-e-expressões-regulares.html"><a href="normalização-de-texto-e-expressões-regulares.html#parâmetros-das-regex"><i class="fa fa-check"></i><b>6.1.1</b> Parâmetros das Regex</a></li>
<li class="chapter" data-level="6.1.2" data-path="normalização-de-texto-e-expressões-regulares.html"><a href="normalização-de-texto-e-expressões-regulares.html#dicassugestões"><i class="fa fa-check"></i><b>6.1.2</b> Dicas/Sugestões</a></li>
<li class="chapter" data-level="6.1.3" data-path="normalização-de-texto-e-expressões-regulares.html"><a href="normalização-de-texto-e-expressões-regulares.html#indicação-de-leitura-sobre-regex"><i class="fa fa-check"></i><b>6.1.3</b> Indicação de leitura sobre Regex</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="normalização-de-texto-e-expressões-regulares.html"><a href="normalização-de-texto-e-expressões-regulares.html#regex-no-r"><i class="fa fa-check"></i><b>6.2</b> RegEx no R</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="normalização-de-texto-e-expressões-regulares.html"><a href="normalização-de-texto-e-expressões-regulares.html#grep"><i class="fa fa-check"></i><b>6.2.1</b> Grep</a></li>
<li class="chapter" data-level="6.2.2" data-path="normalização-de-texto-e-expressões-regulares.html"><a href="normalização-de-texto-e-expressões-regulares.html#gsub"><i class="fa fa-check"></i><b>6.2.2</b> gsub()</a></li>
<li class="chapter" data-level="6.2.3" data-path="normalização-de-texto-e-expressões-regulares.html"><a href="normalização-de-texto-e-expressões-regulares.html#exercício-qual-o-qualis-de-certas-revistas-quais-revistas-possuem-certo-qualis"><i class="fa fa-check"></i><b>6.2.3</b> Exercício: Qual o Qualis de certas revistas? Quais revistas possuem certo Qualis?</a></li>
<li class="chapter" data-level="6.2.4" data-path="normalização-de-texto-e-expressões-regulares.html"><a href="normalização-de-texto-e-expressões-regulares.html#transformando-strings-em-vetores-com-strsplit"><i class="fa fa-check"></i><b>6.2.4</b> Transformando strings em vetores com <code>strsplit()</code></a></li>
<li class="chapter" data-level="6.2.5" data-path="normalização-de-texto-e-expressões-regulares.html"><a href="normalização-de-texto-e-expressões-regulares.html#exemplo-regex"><i class="fa fa-check"></i><b>6.2.5</b> Exemplo regex</a></li>
<li class="chapter" data-level="6.2.6" data-path="normalização-de-texto-e-expressões-regulares.html"><a href="normalização-de-texto-e-expressões-regulares.html#lookaround-lookadead-e-lookbehind"><i class="fa fa-check"></i><b>6.2.6</b> Lookaround lookadead e lookbehind</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="normalização-de-texto-e-expressões-regulares.html"><a href="normalização-de-texto-e-expressões-regulares.html#pacote-stringr"><i class="fa fa-check"></i><b>6.3</b> Pacote stringr</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="normalização-de-texto-e-expressões-regulares.html"><a href="normalização-de-texto-e-expressões-regulares.html#normalização-com-stringr"><i class="fa fa-check"></i><b>6.3.1</b> Normalização com stringr</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="normalização-de-texto-e-expressões-regulares.html"><a href="normalização-de-texto-e-expressões-regulares.html#dicassugestões-regex-no-r"><i class="fa fa-check"></i><b>6.4</b> Dicas/Sugestões: Regex no R</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="visualização-de-dados.html"><a href="visualização-de-dados.html"><i class="fa fa-check"></i><b>7</b> Visualização de dados</a>
<ul>
<li class="chapter" data-level="7.1" data-path="visualização-de-dados.html"><a href="visualização-de-dados.html#base-plots"><i class="fa fa-check"></i><b>7.1</b> Base plots</a></li>
<li class="chapter" data-level="7.2" data-path="visualização-de-dados.html"><a href="visualização-de-dados.html#cores"><i class="fa fa-check"></i><b>7.2</b> Cores</a></li>
<li class="chapter" data-level="7.3" data-path="visualização-de-dados.html"><a href="visualização-de-dados.html#o-pacote-lattice"><i class="fa fa-check"></i><b>7.3</b> O pacote Lattice</a></li>
<li class="chapter" data-level="7.4" data-path="visualização-de-dados.html"><a href="visualização-de-dados.html#ggplot2"><i class="fa fa-check"></i><b>7.4</b> O pacote ggplot2</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="visualização-de-dados.html"><a href="visualização-de-dados.html#ggplot-nível-aes"><i class="fa fa-check"></i><b>7.4.1</b> ggplot: nível aes</a></li>
<li class="chapter" data-level="7.4.2" data-path="visualização-de-dados.html"><a href="visualização-de-dados.html#ggplot-nível-geom"><i class="fa fa-check"></i><b>7.4.2</b> ggplot: Nível geom</a></li>
<li class="chapter" data-level="7.4.3" data-path="visualização-de-dados.html"><a href="visualização-de-dados.html#ggplot-nível-facet"><i class="fa fa-check"></i><b>7.4.3</b> ggplot: nível facet</a></li>
<li class="chapter" data-level="7.4.4" data-path="visualização-de-dados.html"><a href="visualização-de-dados.html#ggplot-nível-stat"><i class="fa fa-check"></i><b>7.4.4</b> ggplot: nível stat</a></li>
<li class="chapter" data-level="7.4.5" data-path="visualização-de-dados.html"><a href="visualização-de-dados.html#ggplot-nível-sistema-de-coordenadas"><i class="fa fa-check"></i><b>7.4.5</b> ggplot: nível sistema de coordenadas</a></li>
<li class="chapter" data-level="7.4.6" data-path="visualização-de-dados.html"><a href="visualização-de-dados.html#cores-no-ggplot"><i class="fa fa-check"></i><b>7.4.6</b> Cores no ggplot</a></li>
<li class="chapter" data-level="7.4.7" data-path="visualização-de-dados.html"><a href="visualização-de-dados.html#dicas-ggplot"><i class="fa fa-check"></i><b>7.4.7</b> Dicas ggplot</a></li>
<li class="chapter" data-level="7.4.8" data-path="visualização-de-dados.html"><a href="visualização-de-dados.html#dicas-outros-pacotes-gráficos"><i class="fa fa-check"></i><b>7.4.8</b> Dicas outros pacotes gráficos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="análise-textual-text-mining.html"><a href="análise-textual-text-mining.html"><i class="fa fa-check"></i><b>8</b> Análise Textual (<em>text mining</em>)</a>
<ul>
<li class="chapter" data-level="8.1" data-path="análise-textual-text-mining.html"><a href="análise-textual-text-mining.html#introdução"><i class="fa fa-check"></i><b>8.1</b> Introdução</a></li>
<li class="chapter" data-level="8.2" data-path="análise-textual-text-mining.html"><a href="análise-textual-text-mining.html#abordagens-saco-de-palavras-bag-of-words-e-análise-semântica-semantic-parsing"><i class="fa fa-check"></i><b>8.2</b> Abordagens: saco de palavras (<em>bag of words</em>) e análise semântica (<em>semantic parsing</em>)</a></li>
<li class="chapter" data-level="8.3" data-path="análise-textual-text-mining.html"><a href="análise-textual-text-mining.html#abordagem-bag-of-words"><i class="fa fa-check"></i><b>8.3</b> Abordagem <em>Bag of words</em></a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="análise-textual-text-mining.html"><a href="análise-textual-text-mining.html#frequência-de-palavrastermos-e-ngrams"><i class="fa fa-check"></i><b>8.3.1</b> Frequência de palavras/termos e Ngrams</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="análise-textual-text-mining.html"><a href="análise-textual-text-mining.html#wordcloud"><i class="fa fa-check"></i><b>8.4</b> Nuvem de palavras</a></li>
<li class="chapter" data-level="8.5" data-path="análise-textual-text-mining.html"><a href="análise-textual-text-mining.html#stopwrds"><i class="fa fa-check"></i><b>8.5</b> Remoção de palavra vazia (<em>stopwords</em>)</a></li>
<li class="chapter" data-level="8.6" data-path="análise-textual-text-mining.html"><a href="análise-textual-text-mining.html#estemização-stemming-e-lematização"><i class="fa fa-check"></i><b>8.6</b> Estemização (<em>stemming</em>) e lematização</a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="análise-textual-text-mining.html"><a href="análise-textual-text-mining.html#stemming"><i class="fa fa-check"></i><b>8.6.1</b> Estemização</a></li>
<li class="chapter" data-level="8.6.2" data-path="análise-textual-text-mining.html"><a href="análise-textual-text-mining.html#lematização"><i class="fa fa-check"></i><b>8.6.2</b> Lematização</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="análise-textual-text-mining.html"><a href="análise-textual-text-mining.html#kwic"><i class="fa fa-check"></i><b>8.7</b> Palavras em contexto (<em>keyword-in-context KWIC</em>)</a></li>
<li class="chapter" data-level="8.8" data-path="análise-textual-text-mining.html"><a href="análise-textual-text-mining.html#key-term-extraction"><i class="fa fa-check"></i><b>8.8</b> Key term extraction</a>
<ul>
<li class="chapter" data-level="8.8.1" data-path="análise-textual-text-mining.html"><a href="análise-textual-text-mining.html#tf-idf"><i class="fa fa-check"></i><b>8.8.1</b> TF-IDF: Term-Frequency Inverse Document Frequency</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="text-mining-semantic-parsing.html"><a href="text-mining-semantic-parsing.html"><i class="fa fa-check"></i><b>9</b> Text mining: Semantic Parsing</a>
<ul>
<li class="chapter" data-level="9.1" data-path="text-mining-semantic-parsing.html"><a href="text-mining-semantic-parsing.html#pos---part-of-speech-tagging"><i class="fa fa-check"></i><b>9.1</b> POS - Part-of-speech tagging</a></li>
<li class="chapter" data-level="9.2" data-path="text-mining-semantic-parsing.html"><a href="text-mining-semantic-parsing.html#udpipe"><i class="fa fa-check"></i><b>9.2</b> Pacote UDPipe</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="text-mining-semantic-parsing.html"><a href="text-mining-semantic-parsing.html#coocorrência-de-palavras"><i class="fa fa-check"></i><b>9.2.1</b> Coocorrência de palavras</a></li>
<li class="chapter" data-level="9.2.2" data-path="text-mining-semantic-parsing.html"><a href="text-mining-semantic-parsing.html#rede-de-palavras-wordnet"><i class="fa fa-check"></i><b>9.2.2</b> Rede de palavras (<em>wordnet</em>)</a></li>
<li class="chapter" data-level="9.2.3" data-path="text-mining-semantic-parsing.html"><a href="text-mining-semantic-parsing.html#análise-de-semelhanças"><i class="fa fa-check"></i><b>9.2.3</b> Análise de semelhanças</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="análise-de-redes-sociais.html"><a href="análise-de-redes-sociais.html"><i class="fa fa-check"></i><b>10</b> Análise de Redes Sociais</a>
<ul>
<li class="chapter" data-level="10.1" data-path="análise-de-redes-sociais.html"><a href="análise-de-redes-sociais.html#o-pacote-igraph"><i class="fa fa-check"></i><b>10.1</b> O pacote Igraph</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="análise-de-redes-sociais.html"><a href="análise-de-redes-sociais.html#clusterização"><i class="fa fa-check"></i><b>10.1.1</b> Clusterização</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="análise-de-redes-sociais.html"><a href="análise-de-redes-sociais.html#os-pacotes-ggraph-e-tidygraph-.-construindo-grafos-com-o-tidyverse."><i class="fa fa-check"></i><b>10.2</b> Os pacotes <code>ggraph</code> e <code>tidygraph</code> . Construindo grafos com o <code>tidyverse</code>.</a></li>
<li class="chapter" data-level="10.3" data-path="análise-de-redes-sociais.html"><a href="análise-de-redes-sociais.html#redes-de-palavras"><i class="fa fa-check"></i><b>10.3</b> Redes de palavras</a></li>
<li class="chapter" data-level="10.4" data-path="análise-de-redes-sociais.html"><a href="análise-de-redes-sociais.html#redes-de-citação"><i class="fa fa-check"></i><b>10.4</b> Redes de citação</a></li>
<li class="chapter" data-level="10.5" data-path="análise-de-redes-sociais.html"><a href="análise-de-redes-sociais.html#gráfico-de-centralidade"><i class="fa fa-check"></i><b>10.5</b> Gráfico de centralidade</a></li>
<li class="chapter" data-level="10.6" data-path="análise-de-redes-sociais.html"><a href="análise-de-redes-sociais.html#comunidades"><i class="fa fa-check"></i><b>10.6</b> Comunidades</a></li>
<li class="chapter" data-level="10.7" data-path="análise-de-redes-sociais.html"><a href="análise-de-redes-sociais.html#SugestaoLinksredes"><i class="fa fa-check"></i><b>10.7</b> Sugestões de links</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="links-úteis.html"><a href="links-úteis.html"><i class="fa fa-check"></i><b>11</b> Links úteis</a>
<ul>
<li class="chapter" data-level="11.1" data-path="links-úteis.html"><a href="links-úteis.html#humanidades-digitais"><i class="fa fa-check"></i><b>11.1</b> Humanidades digitais</a></li>
<li class="chapter" data-level="11.2" data-path="links-úteis.html"><a href="links-úteis.html#análise-de-redes-sociais-1"><i class="fa fa-check"></i><b>11.2</b> Análise de redes sociais</a></li>
<li class="chapter" data-level="11.3" data-path="links-úteis.html"><a href="links-úteis.html#textos-sobre-análise-textual"><i class="fa fa-check"></i><b>11.3</b> Textos sobre análise textual</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="links-úteis.html"><a href="links-úteis.html#sociologia-digital-sociologia-computacional"><i class="fa fa-check"></i><b>11.3.1</b> Sociologia Digital / Sociologia Computacional</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="links-úteis.html"><a href="links-úteis.html#processamento-linguagem-natural-pln-ou-nlp"><i class="fa fa-check"></i><b>11.4</b> Processamento Linguagem Natural (PLN ou NLP)</a></li>
<li class="chapter" data-level="11.5" data-path="links-úteis.html"><a href="links-úteis.html#revistas-journals-acadêmicos"><i class="fa fa-check"></i><b>11.5</b> Revistas / Journals acadêmicos</a></li>
<li class="chapter" data-level="11.6" data-path="links-úteis.html"><a href="links-úteis.html#dados-abertos"><i class="fa fa-check"></i><b>11.6</b> Dados Abertos</a></li>
<li class="chapter" data-level="11.7" data-path="links-úteis.html"><a href="links-úteis.html#vídeos"><i class="fa fa-check"></i><b>11.7</b> Vídeos</a></li>
<li class="chapter" data-level="11.8" data-path="links-úteis.html"><a href="links-úteis.html#sites-blogs"><i class="fa fa-check"></i><b>11.8</b> Sites / Blogs</a></li>
<li class="chapter" data-level="11.9" data-path="links-úteis.html"><a href="links-úteis.html#organizações"><i class="fa fa-check"></i><b>11.9</b> Organizações</a></li>
<li class="chapter" data-level="11.10" data-path="links-úteis.html"><a href="links-úteis.html#podcasts-relacionados-à-digital-humanities"><i class="fa fa-check"></i><b>11.10</b> Podcasts relacionados à Digital Humanities</a></li>
<li class="chapter" data-level="11.11" data-path="links-úteis.html"><a href="links-úteis.html#links-programação"><i class="fa fa-check"></i><b>11.11</b> Links Programação</a>
<ul>
<li class="chapter" data-level="11.11.1" data-path="links-úteis.html"><a href="links-úteis.html#r-introdução"><i class="fa fa-check"></i><b>11.11.1</b> R introdução</a></li>
<li class="chapter" data-level="11.11.2" data-path="links-úteis.html"><a href="links-úteis.html#r---tópicos-específicos"><i class="fa fa-check"></i><b>11.11.2</b> R - tópicos específicos</a></li>
<li class="chapter" data-level="11.11.3" data-path="links-úteis.html"><a href="links-úteis.html#r---avançado"><i class="fa fa-check"></i><b>11.11.3</b> R - avançado</a></li>
<li class="chapter" data-level="11.11.4" data-path="links-úteis.html"><a href="links-úteis.html#links-python"><i class="fa fa-check"></i><b>11.11.4</b> Links Python</a></li>
<li class="chapter" data-level="11.11.5" data-path="links-úteis.html"><a href="links-úteis.html#python---tópicos-específicos"><i class="fa fa-check"></i><b>11.11.5</b> Python - tópicos específicos</a></li>
</ul></li>
<li class="chapter" data-level="11.12" data-path="links-úteis.html"><a href="links-úteis.html#links-de-cursos-online"><i class="fa fa-check"></i><b>11.12</b> Links de Cursos Online</a></li>
<li class="chapter" data-level="11.13" data-path="links-úteis.html"><a href="links-úteis.html#grupos-de-discussãoforum"><i class="fa fa-check"></i><b>11.13</b> Grupos de discussão/Forum</a>
<ul>
<li class="chapter" data-level="11.13.1" data-path="links-úteis.html"><a href="links-úteis.html#telegram"><i class="fa fa-check"></i><b>11.13.1</b> Telegram</a></li>
</ul></li>
<li class="chapter" data-level="11.14" data-path="links-úteis.html"><a href="links-úteis.html#links-de-folhas-de-dicas-cheat-sheets"><i class="fa fa-check"></i><b>11.14</b> Links de folhas de dicas (<em>Cheat-sheets</em>)</a></li>
<li class="chapter" data-level="11.15" data-path="links-úteis.html"><a href="links-úteis.html#tm_datasets"><i class="fa fa-check"></i><b>11.15</b> Alguns datasets/databases para análise textual</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introdução à Análise Textual aplicada à Sociologia</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="análise-textual-text-mining" class="section level1" number="8">
<h1><span class="header-section-number">Capítulo 8</span> Análise Textual (<em>text mining</em>)</h1>
<div class="infobox obra">
<p><strong>CAPÍTULO AINDA EM CONSTRUÇÃO</strong></p>
<p>Conteúdo planejado:</p>
<ul>
<li>Introdução à análise textual via computador</li>
<li>Tipos de abordagens: bag of words, semantic parsing.</li>
<li>Frequência de termos (bag of words, n-grams, skipgrams, TF-IDF)</li>
<li>nuvem de palavras (<em>wordclouds</em>), Polarized tag cloud, pyramid plot (em expansão).</li>
<li>Correlação de palavras, tipos de distâncias, dendogramas</li>
<li>parts-of-speech tagging</li>
<li>keyword extraction (em expansão)</li>
<li>redes de palavras (<em>word networks</em>)</li>
<li>Inteligência Artificial: clusterização; topic modelling</li>
<li>Análise de sentimentos.</li>
</ul>
</div>
<p><strong>Orientações para ler este capítulo:</strong> Em vários dos códigos aqui presentes, usaremos a notação <code>pacote::função</code>, que dispensa carregar o pacote previamente. Apesar de desnecessária caso o pacote seja carregado anteriormente, ele facilitar saber qual função de que pacote está sendo usada, além de desambiguar, uma vez que há funções de nome idêntico em pacotes diferentes.
Assim, sempre confira se o pacote utilizado no exemplo já está instalado em sua máquina. No Rstudio, basta ir à aba “packages” e fazer a busca na lupa para conferir. Se preferir usar o console do R, use o comando <code>installed.packages()[,1]</code> para listar todos os pacotes instalados, e <code>grep("dplyr", installed.packages()[,1], value=T)</code> para checar se um pacote (no caso, o dplyr) está instalado.</p>
<p>Há também uma listagem com <a href="links-úteis.html#tm_datasets">datasets</a> para usar na análise textual, algumas inclusive já no formato R.</p>
<div id="introdução" class="section level2" number="8.1">
<h2><span class="header-section-number">8.1</span> Introdução</h2>
<p>A análise computacional de textos é praticamente um sinônimo de Mineração de Texto (<em>text mining</em>) e tem muito em comum com o campo de Processamento de Língua Natural ou Processamento de Linguagem Natural, mas não são exatamente a mesma coisa. Como vimos no capítulo sobre história da análise textual, esta existia antes antes da inteligência artifical e mesmo dos computadores.
Há diversas funções nativas do R que usamos na mineração de texto/análise textual, mas também há diversas suítes de pacotes (pacotes com vários pacotes, com várias funções) focados em análise textual com diversas ferramentas, como o
<a href="https://www.tidytextmining.com/tidytext.html">tidytext</a>,
<a href="https://cran.r-project.org/web/packages/quanteda/index.html">quanteda (QUantitative ANalysis TExtual DAta)</a>,
<!-- [Rweka]( https://cran.r-project.org/web/packages/RWeka/index.html ) -->
<a href="https://cran.r-project.org/web/packages/openNLP/index.html">OpenNLP</a>, <a href="https://cran.r-project.org/web/packages/RWeka/index.html">Rweka</a>,
<a href="https://cran.r-project.org/web/packages/languageR/index.html">languageR</a>,
<a href="https://cran.r-project.org/web/packages/koRpus/index.html">koRpus</a>,
<a href="https://cran.r-project.org/web/packages/RcmdrPlugin.temis/index.html">RcmdrPlugin.temis</a>, <a href="https://cran.r-project.org/web/packages/RWeka/index.html">RKEA (R Keyphrase Extraction Algorithm)</a>,
<a href="https://cran.r-project.org/web/packages/tm/tm.pdf">tm (Text Mining Package)</a> e
<a href="https://www.rdocumentation.org/packages/qdap/">qdap (Quantitative Discourse Analysis Package)</a>.
Estas são algumas das mais famosas suítes de pacotes, com diversas ferramentas, mas há alguns outros pacotes focados em funções mais específicas, como o pacote <a href="https://cran.r-project.org/web/packages/wordcloud/index.html">wordcloud</a>,
<a href="https://lepennec.github.io/ggwordcloud/">ggwordcloud</a> (nuvem de palavras para o ggplot2, com mais opções), por exemplo.
Há redundância entre estes pacotes, isto é, eles tem funções próprias muito semalhantes às funções de outros pacotes, o que não quer dizer que não existam diferenças significativas.
<!-- O pacote quanteda acompanha outros pacotes, como o quanteda.textstats, quanteda.textplots e o quanteda.textmodels que aconselhamos instalar também. --></p>
<p>Há também pacotes em R para análise textual em modo gráfico.
Um software bem conhecido de análise textual e que possui interface gráfica é o <a href="http://www.iramuteq.org/">iramuteq</a> (Interface de R pour les Analyses Multidimensionnelles de Textes et de Questionnaires), criado em 2009 por Pierre Ratinaud. Apesar de ainda ser bastante utilizado, o Iramuteq tem diversas limitações.
Vimos um pouco sobre o <a href="introdução-ao-r.html#rcommander">RCommander</a>. Há um plugin para ele dedicado à análise textual, o <a href="https://cran.r-project.org/web/packages/RcmdrPlugin.temis/index.html">RcmdrPlugin.temis</a>. Porém, sua última atualização ocorreu em 2018.</p>
<div class="infobox note">
<p><strong>Dicas</strong></p>
<ul>
<li>lista com <a href="https://cran.r-project.org/web/views/NaturalLanguageProcessing.html">diversos pacotes R, relacionados à Processamento de Linguagem Natural</a>. Lista extensa, porém desatualizada.</li>
</ul>
</div>
</div>
<div id="abordagens-saco-de-palavras-bag-of-words-e-análise-semântica-semantic-parsing" class="section level2" number="8.2">
<h2><span class="header-section-number">8.2</span> Abordagens: saco de palavras (<em>bag of words</em>) e análise semântica (<em>semantic parsing</em>)</h2>
<p>Na análise textual podemos analisar levando ou não em consideração a ordem das palavras ou sua função gramatical.
Se o ordenamento ou a função das palavras não é importante, e queremos saber, por exemplo, apenas a frequência de termos, então faremos uma abordagem tipo “saco de palavras” (<em>bag of words</em>).
Se precisamos saber as classes gramaticais, então a ordem das palavras é importante.
<!-- In semantic parsing you care about word type and order. -->
Vamos começar os exemplos com um pacote que pega dados do Google Ngram e nos retorna frequência de termos longitudinalmente, com base de dados do Google Books.</p>
<!-- "Oportunidade? Fulano de Tal perdeu uma boa oportunidade" -->
<!-- noun phrase -- fulano de tal -->
<!-- verb frase-- perdeu uma boa oportunidade -->
<!-- named entity -- Fulano de tal; verbo: perdeu; artigo: uma; adjetivo: boa; substantivo: oportunidade. -->
</div>
<div id="abordagem-bag-of-words" class="section level2" number="8.3">
<h2><span class="header-section-number">8.3</span> Abordagem <em>Bag of words</em></h2>
<p>Na abordagem de “saco de palavras” (<em>bag of words</em>) a ordem dos termos não importa, bem como geralmente não importa a sua classe gramatical.</p>
<div id="frequência-de-palavrastermos-e-ngrams" class="section level3" number="8.3.1">
<h3><span class="header-section-number">8.3.1</span> Frequência de palavras/termos e Ngrams</h3>
<p>Numa abordagem do tipo saco-de-palavras, a abordagem mais simples, mas sempre útil, é verificar a frequência de certos termos.
Apesar de simples, análises mais sofisticadas podem começar com a análise de frequência e partir para abordagens mais sofisticadas.</p>
<ul>
<li>aprendizado instrumental de uma língua, ao identificar as palavras mais frequentes em certa área do conhecimento.</li>
<li>detecção de língua</li>
<li>detecção de termos mais frequentes em uma busca</li>
<li>identificação de palavras compostas</li>
</ul>
<div id="ngram" class="section level4" number="8.3.1.1">
<h4><span class="header-section-number">8.3.1.1</span> n-gram: explicando o conceito</h4>
<p>Se partirmos do exemplo da frase “Ivo viu a uva” teremos</p>
<table>
<tbody>
<tr class="odd">
<td>unigram</td>
<td>N=1</td>
<td>“a” “viu” “Ivo” “uva”</td>
</tr>
<tr class="even">
<td>bigrams</td>
<td>N=2</td>
<td>“a uva” “Ivo viu” “viu a”</td>
</tr>
<tr class="odd">
<td>trigrams</td>
<td>N=3</td>
<td>“Ivo viu a” “viu a uva”</td>
</tr>
<tr class="even">
<td>ngram=4</td>
<td>N=4</td>
<td>“Ivo viu a uva”</td>
</tr>
<tr class="odd">
<td>…</td>
<td>…</td>
<td>…</td>
</tr>
</tbody>
</table>
<p>Quando o N passa de 3, chamamos de ngram e seu valor. Agora um exemplo com o R. Primeiro veremos exemplos com o Google Ngram, que é mais simples, e depois montaremos nosso próprio ngram.</p>
</div>
<div id="ngramr" class="section level4" number="8.3.1.2">
<h4><span class="header-section-number">8.3.1.2</span> GoogleNgrams</h4>
<p>A Google pegou sua enorme base de dados dos milhares de livros do Google Books e extraiu os termos mais frequentes, e os colocou disponível para consulta no site <a href="https://books.google.com/ngrams">Goolge Books Ngram Viewer</a>.
O Google Ngrams facilitou a busca por ngrams nesta base de dados, naquilo que chamavam de “<a href="http://www.culturomics.org/">culturonomics</a>”. O nome não pegou, a ferramenta tem suas limitações, mas ainda assim pode ser bem útil. A base de dados possui 5.2 milhões de livros, cerca de 4% de todos os livros já publicados.
Para mais informações sobre a <a href="http://www.culturomics.org/Resources/A-users-guide-to-culturomics">base de dados</a> e sobre o GoogleNgram <a href="https://books.google.com/ngrams/info">no site</a>. Tanto o Python (com o <a href="http://www.culturomics.org/Resources/get-ngrams">get-ngrams</a>) como o R (<a href="https://github.com/seancarmody/ngramr">ngramr</a>) possuem pacotes que usam os dados do Google Ngram.</p>
<p>Instalando o pacote ngramr</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="análise-textual-text-mining.html#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&#39;ngramr&#39;</span>)</span></code></pre></div>
<p>Carregando os pacote</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="análise-textual-text-mining.html#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ngramr)</span></code></pre></div>
<p>E um exemplo de uso</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="análise-textual-text-mining.html#cb3-1" aria-hidden="true" tabindex="-1"></a>ng  <span class="ot">&lt;-</span> ngramr<span class="sc">::</span><span class="fu">ngram</span>(<span class="fu">c</span>(<span class="st">&quot;Max Weber&quot;</span>, <span class="st">&quot;Émile Durkheim&quot;</span>), <span class="at">year_start =</span> <span class="dv">1890</span>)</span>
<span id="cb3-2"><a href="análise-textual-text-mining.html#cb3-2" aria-hidden="true" tabindex="-1"></a>ggplot2<span class="sc">::</span><span class="fu">ggplot</span>(ng, <span class="fu">aes</span>(<span class="at">x=</span>Year, <span class="at">y=</span>Frequency, <span class="at">colour=</span>Phrase)) <span class="sc">+</span></span>
<span id="cb3-3"><a href="análise-textual-text-mining.html#cb3-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>()</span></code></pre></div>
<p><img src="analise_textual_sociologia_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>Um exemplo da <a href="https://github.com/seancarmody/ngramr">página do ngramr no Github</a> com mais opções, usando a função <a href="https://www.rdocumentation.org/packages/ngramr/versions/1.7.4/topics/ggram"><code>ggram()</code></a> no ngramr, que pega dados do GoogleNgram e plota os dados com o ggplot2:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="análise-textual-text-mining.html#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggram</span>(<span class="fu">c</span>(<span class="st">&quot;monarchy&quot;</span>, <span class="st">&quot;democracy&quot;</span>), <span class="at">year_start =</span> <span class="dv">1500</span>, <span class="at">year_end =</span> <span class="dv">2000</span>, </span>
<span id="cb4-2"><a href="análise-textual-text-mining.html#cb4-2" aria-hidden="true" tabindex="-1"></a>      <span class="at">corpus =</span> <span class="st">&quot;eng_gb_2012&quot;</span>, <span class="at">ignore_case =</span> <span class="cn">TRUE</span>, </span>
<span id="cb4-3"><a href="análise-textual-text-mining.html#cb4-3" aria-hidden="true" tabindex="-1"></a>      <span class="at">geom =</span> <span class="st">&quot;area&quot;</span>, <span class="at">geom_options =</span> <span class="fu">list</span>(<span class="at">position =</span> <span class="st">&quot;stack&quot;</span>)) <span class="sc">+</span> </span>
<span id="cb4-4"><a href="análise-textual-text-mining.html#cb4-4" aria-hidden="true" tabindex="-1"></a>      <span class="fu">labs</span>(<span class="at">y =</span> <span class="cn">NULL</span>)</span></code></pre></div>
<p><img src="analise_textual_sociologia_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>É possível mudar entre diferentes corpus, que neste caso representam as diferentes línguas, como “eng_us_2019”, “eng_gb_2019”, “chi_sim_2019”, “fre_2019”, “ger_2019”, “heb_2019”, “ger_2012”, “spa_2012”, “rus_2012”, “ita_2012”.
Para ver todos os corpus disponíveis <a href="https://books.google.com/ngrams/info#">veja no site</a> busque a sessão “Corpora”. Infelizmente, não há corpus em português no Google Ngram.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="análise-textual-text-mining.html#cb5-1" aria-hidden="true" tabindex="-1"></a>classicos <span class="ot">=</span> <span class="fu">c</span>(<span class="st">&quot;Max Weber&quot;</span>, <span class="st">&quot;Émile Durkheim&quot;</span>, <span class="st">&quot;Karl Marx&quot;</span>, <span class="st">&quot;Gabriel Tarde&quot;</span>, <span class="st">&quot;Georg Simmel&quot;</span>)</span>
<span id="cb5-2"><a href="análise-textual-text-mining.html#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggram</span>(classicos, <span class="at">year_start =</span> <span class="dv">1980</span>, <span class="at">year_end =</span> <span class="dv">2000</span>,</span>
<span id="cb5-3"><a href="análise-textual-text-mining.html#cb5-3" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Para mudar lingua, mude o corpus</span></span>
<span id="cb5-4"><a href="análise-textual-text-mining.html#cb5-4" aria-hidden="true" tabindex="-1"></a>      <span class="co"># ignore case: se diferencia maiúsculo de minúsculo</span></span>
<span id="cb5-5"><a href="análise-textual-text-mining.html#cb5-5" aria-hidden="true" tabindex="-1"></a>      <span class="at">corpus =</span> <span class="st">&quot;fre_2019&quot;</span>, <span class="at">ignore_case =</span> <span class="cn">TRUE</span>,</span>
<span id="cb5-6"><a href="análise-textual-text-mining.html#cb5-6" aria-hidden="true" tabindex="-1"></a>      <span class="co"># tipo de grafico em geom</span></span>
<span id="cb5-7"><a href="análise-textual-text-mining.html#cb5-7" aria-hidden="true" tabindex="-1"></a>      <span class="at">geom =</span> <span class="st">&quot;line&quot;</span>, <span class="at">geom_options =</span> <span class="fu">list</span>()) <span class="sc">+</span></span>
<span id="cb5-8"><a href="análise-textual-text-mining.html#cb5-8" aria-hidden="true" tabindex="-1"></a>      <span class="co"># labs: label do eixo y</span></span>
<span id="cb5-9"><a href="análise-textual-text-mining.html#cb5-9" aria-hidden="true" tabindex="-1"></a>      <span class="fu">labs</span>(<span class="at">y =</span> <span class="cn">NULL</span>) </span></code></pre></div>
<p><img src="analise_textual_sociologia_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<div class="infobox note">
<p><strong>Dicas Ngramr:</strong></p>
<ul>
<li>Site do <a href="https://books.google.com/ngrams/info">Books Ngram Viewer</a> explicando seus parâmetros.</li>
<li><a href="https://cran.r-project.org/web//packages/ngramr/ngramr.pdf">PDF com a documentação do ngramr</a></li>
<li>Instalação/Primeiros passos com o Ngramr <a href="https://github.com/seancarmody/ngramr">na página do Github do ngramr</a></li>
<li>Um projeto similar ao Google Ngram - inclusive usando parte do mesmo pessoal - é o <a href="https://bookworm.htrc.illinois.edu/develop/">bookworm:HalthiTrust</a> do projeto <a href="https://www.hathitrust.org/">Halthi Trust-Digital Livrary</a>, com muito mais línguas, inclusive o português e mais opções de busca.</li>
</ul>
</div>
</div>
<div id="ngram" class="section level4" number="8.3.1.3">
<h4><span class="header-section-number">8.3.1.3</span> N-grams no R</h4>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="análise-textual-text-mining.html#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ngram)</span>
<span id="cb6-2"><a href="análise-textual-text-mining.html#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb6-3"><a href="análise-textual-text-mining.html#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="do">## Attaching package: &#39;ngram&#39;</span></span>
<span id="cb6-4"><a href="análise-textual-text-mining.html#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="do">## The following object is masked from &#39;package:ngramr&#39;:</span></span>
<span id="cb6-5"><a href="análise-textual-text-mining.html#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb6-6"><a href="análise-textual-text-mining.html#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="do">##     ngram</span></span></code></pre></div>
<p>Vamos pegar um trecho de Alfred Shutz.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="análise-textual-text-mining.html#cb7-1" aria-hidden="true" tabindex="-1"></a>txt<span class="ot">=</span><span class="st">&quot;A Fenomenologia busca o início real de todo pensamento filosófico... Seu lugar é além - ou melhor, antes - de todas as distinções entre realismo e idealismo.&quot;</span></span></code></pre></div>
<p>Vamos quebrar o texto em ngrams. Geralmente usa-se valores entre 1 e 3.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="análise-textual-text-mining.html#cb8-1" aria-hidden="true" tabindex="-1"></a>ng <span class="ot">&lt;-</span> ngram<span class="sc">::</span><span class="fu">ngram</span>(txt,</span>
<span id="cb8-2"><a href="análise-textual-text-mining.html#cb8-2" aria-hidden="true" tabindex="-1"></a>        <span class="co"># n = valor do ngram</span></span>
<span id="cb8-3"><a href="análise-textual-text-mining.html#cb8-3" aria-hidden="true" tabindex="-1"></a>        <span class="at">n=</span><span class="dv">3</span>)</span>
<span id="cb8-4"><a href="análise-textual-text-mining.html#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co"># imprimindo o objeto que criamos, que mostra o total de ngrams</span></span>
<span id="cb8-5"><a href="análise-textual-text-mining.html#cb8-5" aria-hidden="true" tabindex="-1"></a>ng</span>
<span id="cb8-6"><a href="análise-textual-text-mining.html#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="do">## An ngram object with 25 3-grams</span></span>
<span id="cb8-7"><a href="análise-textual-text-mining.html#cb8-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-8"><a href="análise-textual-text-mining.html#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="co"># imprimindo os ngrams gerados.</span></span>
<span id="cb8-9"><a href="análise-textual-text-mining.html#cb8-9" aria-hidden="true" tabindex="-1"></a>ngram<span class="sc">::</span><span class="fu">get.ngrams</span>(ng)</span>
<span id="cb8-10"><a href="análise-textual-text-mining.html#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="do">##  [1] &quot;além - ou&quot;                     &quot;início real de&quot;               </span></span>
<span id="cb8-11"><a href="análise-textual-text-mining.html#cb8-11" aria-hidden="true" tabindex="-1"></a><span class="do">##  [3] &quot;- de todas&quot;                    &quot;antes - de&quot;                   </span></span>
<span id="cb8-12"><a href="análise-textual-text-mining.html#cb8-12" aria-hidden="true" tabindex="-1"></a><span class="do">##  [5] &quot;busca o início&quot;                &quot;entre realismo e&quot;             </span></span>
<span id="cb8-13"><a href="análise-textual-text-mining.html#cb8-13" aria-hidden="true" tabindex="-1"></a><span class="do">##  [7] &quot;o início real&quot;                 &quot;A Fenomenologia busca&quot;        </span></span>
<span id="cb8-14"><a href="análise-textual-text-mining.html#cb8-14" aria-hidden="true" tabindex="-1"></a><span class="do">##  [9] &quot;distinções entre realismo&quot;     &quot;lugar é além&quot;                 </span></span>
<span id="cb8-15"><a href="análise-textual-text-mining.html#cb8-15" aria-hidden="true" tabindex="-1"></a><span class="do">## [11] &quot;as distinções entre&quot;           &quot;de todo pensamento&quot;           </span></span>
<span id="cb8-16"><a href="análise-textual-text-mining.html#cb8-16" aria-hidden="true" tabindex="-1"></a><span class="do">## [13] &quot;filosófico... Seu lugar&quot;       &quot;é além -&quot;                     </span></span>
<span id="cb8-17"><a href="análise-textual-text-mining.html#cb8-17" aria-hidden="true" tabindex="-1"></a><span class="do">## [15] &quot;- ou melhor,&quot;                  &quot;de todas as&quot;                  </span></span>
<span id="cb8-18"><a href="análise-textual-text-mining.html#cb8-18" aria-hidden="true" tabindex="-1"></a><span class="do">## [17] &quot;Fenomenologia busca o&quot;         &quot;melhor, antes -&quot;              </span></span>
<span id="cb8-19"><a href="análise-textual-text-mining.html#cb8-19" aria-hidden="true" tabindex="-1"></a><span class="do">## [19] &quot;todo pensamento filosófico...&quot; &quot;todas as distinções&quot;          </span></span>
<span id="cb8-20"><a href="análise-textual-text-mining.html#cb8-20" aria-hidden="true" tabindex="-1"></a><span class="do">## [21] &quot;ou melhor, antes&quot;              &quot;realismo e idealismo.&quot;        </span></span>
<span id="cb8-21"><a href="análise-textual-text-mining.html#cb8-21" aria-hidden="true" tabindex="-1"></a><span class="do">## [23] &quot;real de todo&quot;                  &quot;Seu lugar é&quot;                  </span></span>
<span id="cb8-22"><a href="análise-textual-text-mining.html#cb8-22" aria-hidden="true" tabindex="-1"></a><span class="do">## [25] &quot;pensamento filosófico... Seu&quot;</span></span></code></pre></div>
<p>Diversos outros pacotes::funções fazem a quebra em ngrams, como <code>RWeka::NGramTokenizer</code> ou o quanteda.
A função de ngram do quanteda tem a vantagem de poder definir um escopo de valores de ngram de uma vez, podendo gerar unigramas, bigramas e trigramas com um só comando. Em outros pacotes isto é possível apenas com pós processamento.</p>
<p>A quebra do texto em ngrams faz mais sentido quando, com eles, observamos os termos mais repetidos. Isso é o que vamos fazer a seguir.
Num exemplo mais prático, fomos até o <a href="https://www.gutenberg.org/">site gutenberg</a> (site com vários livros gratuitos) e pegamos o link para o txt do livro “O Príncipe” de Maquiavel, em inglês.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="análise-textual-text-mining.html#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># link para o livro &quot;The Prince&quot; de Maquiavel.</span></span>
<span id="cb9-2"><a href="análise-textual-text-mining.html#cb9-2" aria-hidden="true" tabindex="-1"></a>url.prince <span class="ot">=</span> <span class="st">&quot;https://www.gutenberg.org/files/1232/1232-0.txt&quot;</span></span>
<span id="cb9-3"><a href="análise-textual-text-mining.html#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="co"># carregando o url num objeto R</span></span>
<span id="cb9-4"><a href="análise-textual-text-mining.html#cb9-4" aria-hidden="true" tabindex="-1"></a>maquiavel <span class="ot">&lt;-</span> <span class="fu">readLines</span>(<span class="fu">url</span>(url.prince))</span></code></pre></div>
<p>Observando a estrutura do objeto “maquiavel” que acabamos de criar:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="análise-textual-text-mining.html#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Como o objeto importado está como um vetor com vários elementos:</span></span>
<span id="cb10-2"><a href="análise-textual-text-mining.html#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(maquiavel)</span>
<span id="cb10-3"><a href="análise-textual-text-mining.html#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="do">##  chr [1:5188] &quot;The Project Gutenberg eBook of The Prince, by Nicolo Machiavelli&quot; ...</span></span>
<span id="cb10-4"><a href="análise-textual-text-mining.html#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="co"># vemos que é um vetor com 5.188 itens. Precisamos transformar estes vários vetores em um só elemento com o comando</span></span>
<span id="cb10-5"><a href="análise-textual-text-mining.html#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="co"># paste0(var, collapse = &quot; &quot;)</span></span>
<span id="cb10-6"><a href="análise-textual-text-mining.html#cb10-6" aria-hidden="true" tabindex="-1"></a>maquiavel2 <span class="ot">&lt;-</span> <span class="fu">paste</span>(maquiavel, <span class="at">collapse =</span> <span class="st">&quot; &quot;</span>)</span></code></pre></div>
<!-- Vamos pegar a frequência de termos. Um modo comum de contar termos repetidos em um vetor é usando o `table()`. Outro método é utilizar o `plyr::count()` que entrega os termos e suas frequências, porém em formato de dataframe. -->
<p>Por hora, usaremos o pacote tradicional <a href="https://cran.r-project.org/web/packages/ngram/index.html">ngram</a>, escrito em C, e por isso, rápido.
Podemos fazer a sumarização (<em>summarizing</em>) obtendo a frequência de vezes que um ngram apareceu no texto, bem como também a frequência relativa (proporcional) com a função <code>ngram:: get.phrasetable</code>, que retorna um data frame. Rode o ngram com diferentes valores para ver qual deles ertorna resultados mais informativos do conteúdo.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="análise-textual-text-mining.html#cb11-1" aria-hidden="true" tabindex="-1"></a>prince_ngrams <span class="ot">&lt;-</span> ngram<span class="sc">::</span><span class="fu">get.phrasetable</span>(ngram<span class="sc">::</span><span class="fu">ngram</span>(maquiavel2, <span class="at">n =</span> <span class="dv">3</span>)) </span>
<span id="cb11-2"><a href="análise-textual-text-mining.html#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="co"># restringindo aos trigramas mais frequentes</span></span>
<span id="cb11-3"><a href="análise-textual-text-mining.html#cb11-3" aria-hidden="true" tabindex="-1"></a>prince_ngrams[<span class="dv">1</span><span class="sc">:</span><span class="dv">16</span>,]</span>
<span id="cb11-4"><a href="análise-textual-text-mining.html#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="do">##                              ngrams freq         prop</span></span>
<span id="cb11-5"><a href="análise-textual-text-mining.html#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="do">## 1                       he did not    20 0.0003770526</span></span>
<span id="cb11-6"><a href="análise-textual-text-mining.html#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="do">## 2                  it is necessary    20 0.0003770526</span></span>
<span id="cb11-7"><a href="análise-textual-text-mining.html#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="do">## 3                      in order to    19 0.0003582000</span></span>
<span id="cb11-8"><a href="análise-textual-text-mining.html#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="do">## 4                      the King of    19 0.0003582000</span></span>
<span id="cb11-9"><a href="análise-textual-text-mining.html#cb11-9" aria-hidden="true" tabindex="-1"></a><span class="do">## 5  Project Gutenberg-tm electronic    18 0.0003393473</span></span>
<span id="cb11-10"><a href="análise-textual-text-mining.html#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="do">## 6                      ought to be    18 0.0003393473</span></span>
<span id="cb11-11"><a href="análise-textual-text-mining.html#cb11-11" aria-hidden="true" tabindex="-1"></a><span class="do">## 7                        in such a    18 0.0003393473</span></span>
<span id="cb11-12"><a href="análise-textual-text-mining.html#cb11-12" aria-hidden="true" tabindex="-1"></a><span class="do">## 8                  prince ought to    18 0.0003393473</span></span>
<span id="cb11-13"><a href="análise-textual-text-mining.html#cb11-13" aria-hidden="true" tabindex="-1"></a><span class="do">## 9                         so as to    17 0.0003204947</span></span>
<span id="cb11-14"><a href="análise-textual-text-mining.html#cb11-14" aria-hidden="true" tabindex="-1"></a><span class="do">## 10                     that it was    15 0.0002827894</span></span>
<span id="cb11-15"><a href="análise-textual-text-mining.html#cb11-15" aria-hidden="true" tabindex="-1"></a><span class="do">## 11                  those who have    15 0.0002827894</span></span>
<span id="cb11-16"><a href="análise-textual-text-mining.html#cb11-16" aria-hidden="true" tabindex="-1"></a><span class="do">## 12                       if he had    15 0.0002827894</span></span>
<span id="cb11-17"><a href="análise-textual-text-mining.html#cb11-17" aria-hidden="true" tabindex="-1"></a><span class="do">## 13                      for him to    14 0.0002639368</span></span>
<span id="cb11-18"><a href="análise-textual-text-mining.html#cb11-18" aria-hidden="true" tabindex="-1"></a><span class="do">## 14           the Project Gutenberg    14 0.0002639368</span></span>
<span id="cb11-19"><a href="análise-textual-text-mining.html#cb11-19" aria-hidden="true" tabindex="-1"></a><span class="do">## 15                      such a way    14 0.0002639368</span></span>
<span id="cb11-20"><a href="análise-textual-text-mining.html#cb11-20" aria-hidden="true" tabindex="-1"></a><span class="do">## 16                    the death of    13 0.0002450842</span></span></code></pre></div>
<!-- PENDENTE: fazer um ggplot disso, para mostrar importância das stopwords, antes de entrar em wordcloud -->
<div class="infobox note">
<p><strong>Dicas</strong></p>
<p><strong>Sugestão de leitura</strong></p>
<ul>
<li>JURAFSKY, Dan.; MARTIN, James H. cap.3 <a href="https://web.stanford.edu/~jurafsky/slp3/3.pdf">N-gram Language Models</a></li>
<li>Manual do pacote <a href="https://cran.r-project.org/web/packages/ngram/vignettes/ngram-guide.pdf">ngram</a></li>
</ul>
</div>
</div>
</div>
</div>
<div id="wordcloud" class="section level2" number="8.4">
<h2><span class="header-section-number">8.4</span> Nuvem de palavras</h2>
<p>Vários pacotes fazem as chamadas nuvem de palavras no R. Um deles é o <a href="https://cran.r-project.org/web/packages/wordcloud/">wordcloud</a>, que além de fazer nuvens de palavras, também é capaz de fazê-lo comparando documentos,</p>
<p>Em sua forma mais simples</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="análise-textual-text-mining.html#cb12-1" aria-hidden="true" tabindex="-1"></a>texto_tocqueville <span class="ot">&lt;-</span> <span class="st">&quot;Em nosso tempo, a liberdade de associação tornou-se uma garantia necessária contra a tirania da maioria.  Nos Estados Unidos, quando uma vez um partido se toma dominante. todo o poder público passa para as suas mãos; seus amigos particulares ocupam todos os empregos e dispõem de todas as forças organizadas. Como os homens mais distintos do partido contrário não podem atravessar a barreira que os separa do poder, é preciso que possam se estabelecer fora; é preciso que a minoria oponha sua força moral inteira ao poderio material que a oprime. Opõe-se, pois, um perigo a um perigo mais temível. A onipotência da maioria parece-me um risco tão grande para as repúblicas americanas que o meio perigoso que se usa para limitá-la parece-me, ainda assim, um bem.</span></span>
<span id="cb12-2"><a href="análise-textual-text-mining.html#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="st">Exprimirei aqui um pensamento que lembrará o que disse em outra parte a respeito das liberdades comunais: não há país em que as associações sejam mais necessárias, para impedir o despotismo dos partidos ou a arbitrariedade do príncipe, do que aquele em que o estado social é democrático. Nas nações aristocráticas, os corpos secundários formam associações naturais que detêm os abusos de poder. Nos países em que semelhantes associações não existem, se os particulares não podem criar artificial e momentaneamente alguma coisa que se lhes assemelhe, não percebo mais nenhum dique contra nenhuma sorte de tirania, e um grande povo pode ser oprimido impunemente por um punhado de facciosos ou por um homem.</span></span>
<span id="cb12-3"><a href="análise-textual-text-mining.html#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="st">... Não podemos dissimular que a liberdade ilimitada de associação, em matéria política, é, de todas as liberdades, a última que um povo pode suportar. Se ela não o faz cair na anarquia, o faz tocá-la por assim dizer a cada instante. Essa liberdade, tão perigosa, oferece porém num ponto algumas garantias: nos países em que as associações são livres, as sociedades secretas são desconhecidas. Na América, há facciosos, mas não conspiradores.&quot;</span></span></code></pre></div>
<p>E para criar uma nuvem de palavras simples, basta usar o comando:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="análise-textual-text-mining.html#cb13-1" aria-hidden="true" tabindex="-1"></a>wordcloud<span class="sc">::</span><span class="fu">wordcloud</span>(texto_tocqueville)</span>
<span id="cb13-2"><a href="análise-textual-text-mining.html#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning in tm_map.SimpleCorpus(corpus, tm::removePunctuation): transformation</span></span>
<span id="cb13-3"><a href="análise-textual-text-mining.html#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="do">## drops documents</span></span>
<span id="cb13-4"><a href="análise-textual-text-mining.html#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning in tm_map.SimpleCorpus(corpus, function(x) tm::removeWords(x,</span></span>
<span id="cb13-5"><a href="análise-textual-text-mining.html#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="do">## tm::stopwords())): transformation drops documents</span></span></code></pre></div>
<p><img src="analise_textual_sociologia_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="análise-textual-text-mining.html#cb14-1" aria-hidden="true" tabindex="-1"></a>wordcloud<span class="sc">::</span><span class="fu">wordcloud</span>(texto_tocqueville, </span>
<span id="cb14-2"><a href="análise-textual-text-mining.html#cb14-2" aria-hidden="true" tabindex="-1"></a>                     <span class="co"># número mínimo de repetições que uma palavra tem de ter para entrar no gráfico</span></span>
<span id="cb14-3"><a href="análise-textual-text-mining.html#cb14-3" aria-hidden="true" tabindex="-1"></a>                     <span class="at">min.freq =</span> <span class="dv">2</span>,</span>
<span id="cb14-4"><a href="análise-textual-text-mining.html#cb14-4" aria-hidden="true" tabindex="-1"></a>                     <span class="co"># cores, do menos frequente ao mais frequente</span></span>
<span id="cb14-5"><a href="análise-textual-text-mining.html#cb14-5" aria-hidden="true" tabindex="-1"></a>                     <span class="at">colors =</span> <span class="fu">c</span>(<span class="st">&quot;royalblue&quot;</span>,<span class="st">&quot;blue&quot;</span>, <span class="st">&quot;darkblue&quot;</span>))</span>
<span id="cb14-6"><a href="análise-textual-text-mining.html#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning in tm_map.SimpleCorpus(corpus, tm::removePunctuation): transformation</span></span>
<span id="cb14-7"><a href="análise-textual-text-mining.html#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="do">## drops documents</span></span>
<span id="cb14-8"><a href="análise-textual-text-mining.html#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning in tm_map.SimpleCorpus(corpus, function(x) tm::removeWords(x,</span></span>
<span id="cb14-9"><a href="análise-textual-text-mining.html#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="do">## tm::stopwords())): transformation drops documents</span></span></code></pre></div>
<p><img src="analise_textual_sociologia_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<p>Vemos que algumas palavras frequentes não nos dizem muita coisa, como “que”, “nos”, “para”. Como queremos apreender algo do sentido do texto com a nuvem de palavras, seria interessante remover tais termos pouco significativos, as chamadas <a href="#stopwords">“palavras vazias” ou “stopwords”</a>.</p>
</div>
<div id="stopwrds" class="section level2" number="8.5">
<h2><span class="header-section-number">8.5</span> Remoção de palavra vazia (<em>stopwords</em>)</h2>
<p>Ao analisarmos texto, o mais frequente são palavras bem pouco informativas, como artigos “o”, “a” “os”, “as”. Para termos uma noção melhor removemos as chamadas “stopwords”.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="análise-textual-text-mining.html#cb15-1" aria-hidden="true" tabindex="-1"></a>manifesto <span class="ot">&lt;-</span> <span class="st">&quot;A História de toda a sociedade até hoje é a história da luta de classes.&quot;</span></span>
<span id="cb15-2"><a href="análise-textual-text-mining.html#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="co"># criamos uma pequena lista de stopwords</span></span>
<span id="cb15-3"><a href="análise-textual-text-mining.html#cb15-3" aria-hidden="true" tabindex="-1"></a>minhas_sw <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;a&quot;</span>,<span class="st">&quot;o&quot;</span>, <span class="st">&quot;e&quot;</span>, <span class="st">&quot;da&quot;</span>, <span class="st">&quot;de&quot;</span>, <span class="st">&quot;do&quot;</span>)</span>
<span id="cb15-4"><a href="análise-textual-text-mining.html#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="co"># transformando o texto em vetor</span></span>
<span id="cb15-5"><a href="análise-textual-text-mining.html#cb15-5" aria-hidden="true" tabindex="-1"></a>manif_vetor <span class="ot">&lt;-</span> manifesto <span class="sc">%&gt;%</span> </span>
<span id="cb15-6"><a href="análise-textual-text-mining.html#cb15-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># convertendo o texto todo para minúsculo</span></span>
<span id="cb15-7"><a href="análise-textual-text-mining.html#cb15-7" aria-hidden="true" tabindex="-1"></a>  tolower <span class="sc">%&gt;%</span> </span>
<span id="cb15-8"><a href="análise-textual-text-mining.html#cb15-8" aria-hidden="true" tabindex="-1"></a>  <span class="co"># quebrando o texto em vetores</span></span>
<span id="cb15-9"><a href="análise-textual-text-mining.html#cb15-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">strsplit</span>(., <span class="st">&quot; &quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb15-10"><a href="análise-textual-text-mining.html#cb15-10" aria-hidden="true" tabindex="-1"></a>  <span class="co"># o comando strplit retorna lista. Vamos forçar para retornar como vetor char</span></span>
<span id="cb15-11"><a href="análise-textual-text-mining.html#cb15-11" aria-hidden="true" tabindex="-1"></a>  unlist</span>
<span id="cb15-12"><a href="análise-textual-text-mining.html#cb15-12" aria-hidden="true" tabindex="-1"></a>manif_vetor</span>
<span id="cb15-13"><a href="análise-textual-text-mining.html#cb15-13" aria-hidden="true" tabindex="-1"></a><span class="do">##  [1] &quot;a&quot;         &quot;história&quot;  &quot;de&quot;        &quot;toda&quot;      &quot;a&quot;         &quot;sociedade&quot;</span></span>
<span id="cb15-14"><a href="análise-textual-text-mining.html#cb15-14" aria-hidden="true" tabindex="-1"></a><span class="do">##  [7] &quot;até&quot;       &quot;hoje&quot;      &quot;é&quot;         &quot;a&quot;         &quot;história&quot;  &quot;da&quot;       </span></span>
<span id="cb15-15"><a href="análise-textual-text-mining.html#cb15-15" aria-hidden="true" tabindex="-1"></a><span class="do">## [13] &quot;luta&quot;      &quot;de&quot;        &quot;classes.&quot;</span></span></code></pre></div>
<p>Por se tratar de vetor, podemos usar comando tradicionais, com os <a href="noções-básicas-de-programação-em-r.html#operadores">operadores</a> <code>!</code> que indica negação, e <code>%in%</code> que checa se algo está contido em um vetor.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="análise-textual-text-mining.html#cb16-1" aria-hidden="true" tabindex="-1"></a>manif_vetor[<span class="sc">!</span>(manif_vetor) <span class="sc">%in%</span> minhas_sw]</span>
<span id="cb16-2"><a href="análise-textual-text-mining.html#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] &quot;história&quot;  &quot;toda&quot;      &quot;sociedade&quot; &quot;até&quot;       &quot;hoje&quot;      &quot;é&quot;        </span></span>
<span id="cb16-3"><a href="análise-textual-text-mining.html#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="do">## [7] &quot;história&quot;  &quot;luta&quot;      &quot;classes.&quot;</span></span></code></pre></div>
<!-- # ou -->
<!-- dplyr::filter(!manif_vetor %in% minhas_sw) -->
<!-- https://stackoverflow.com/questions/43441884/removing-stop-words-with-tidytext -->
<!-- tidy_document <- tidy_document %>% anti_join(stop_words, by = c("word" = "word")) -->
<p>Explicando:</p>
<ul>
<li><code>(manif_vetor) %in% minhas_sw</code> checa se itens de “manif_vetor” estão contidos em “minhas_sw”. Retorna um booleanoo de “TRUE” e “FALSE”.</li>
<li><code>!</code> inverte o comando anterior, checando agora quais itens de “manif_vetor” não estão contidos em “minhas_sw”, também retornando um vetor com booleanos de “TRUE” e “FALSE”.</li>
<li>Para obter os valores (as palavras), jogamos esta fórmula anterior dentro de “manif_vetor[fórmula_anterior]”.
<!-- dplyr::anti_join(manif_vetor, minhas_sw) --></li>
</ul>
<p>As stopwords costumam ser as mesmas. E se já houvesse uma lista pronta? Existe. É possível encontrar listas prontas na internet, mas diversas funções no R já incluem em si tais listas.
Para ver a lista padrão no R, use:</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="análise-textual-text-mining.html#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tm, <span class="at">quietly =</span> T)</span></code></pre></div>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="análise-textual-text-mining.html#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># pegando apenas as primeiras 20 stopwrods em inglês</span></span>
<span id="cb18-2"><a href="análise-textual-text-mining.html#cb18-2" aria-hidden="true" tabindex="-1"></a>tm<span class="sc">::</span><span class="fu">stopwords</span>(<span class="st">&quot;en&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">head</span>(.,<span class="dv">20</span>)</span>
<span id="cb18-3"><a href="análise-textual-text-mining.html#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="do">##  [1] &quot;i&quot;          &quot;me&quot;         &quot;my&quot;         &quot;myself&quot;     &quot;we&quot;        </span></span>
<span id="cb18-4"><a href="análise-textual-text-mining.html#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="do">##  [6] &quot;our&quot;        &quot;ours&quot;       &quot;ourselves&quot;  &quot;you&quot;        &quot;your&quot;      </span></span>
<span id="cb18-5"><a href="análise-textual-text-mining.html#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="do">## [11] &quot;yours&quot;      &quot;yourself&quot;   &quot;yourselves&quot; &quot;he&quot;         &quot;him&quot;       </span></span>
<span id="cb18-6"><a href="análise-textual-text-mining.html#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="do">## [16] &quot;his&quot;        &quot;himself&quot;    &quot;she&quot;        &quot;her&quot;        &quot;hers&quot;</span></span>
<span id="cb18-7"><a href="análise-textual-text-mining.html#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="co"># vendo a lista em português</span></span>
<span id="cb18-8"><a href="análise-textual-text-mining.html#cb18-8" aria-hidden="true" tabindex="-1"></a>tm<span class="sc">::</span><span class="fu">stopwords</span>(<span class="st">&quot;pt&quot;</span>)</span>
<span id="cb18-9"><a href="análise-textual-text-mining.html#cb18-9" aria-hidden="true" tabindex="-1"></a><span class="do">##   [1] &quot;de&quot;           &quot;a&quot;            &quot;o&quot;            &quot;que&quot;          &quot;e&quot;           </span></span>
<span id="cb18-10"><a href="análise-textual-text-mining.html#cb18-10" aria-hidden="true" tabindex="-1"></a><span class="do">##   [6] &quot;do&quot;           &quot;da&quot;           &quot;em&quot;           &quot;um&quot;           &quot;para&quot;        </span></span>
<span id="cb18-11"><a href="análise-textual-text-mining.html#cb18-11" aria-hidden="true" tabindex="-1"></a><span class="do">##  [11] &quot;com&quot;          &quot;não&quot;          &quot;uma&quot;          &quot;os&quot;           &quot;no&quot;          </span></span>
<span id="cb18-12"><a href="análise-textual-text-mining.html#cb18-12" aria-hidden="true" tabindex="-1"></a><span class="do">##  [16] &quot;se&quot;           &quot;na&quot;           &quot;por&quot;          &quot;mais&quot;         &quot;as&quot;          </span></span>
<span id="cb18-13"><a href="análise-textual-text-mining.html#cb18-13" aria-hidden="true" tabindex="-1"></a><span class="do">##  [21] &quot;dos&quot;          &quot;como&quot;         &quot;mas&quot;          &quot;ao&quot;           &quot;ele&quot;         </span></span>
<span id="cb18-14"><a href="análise-textual-text-mining.html#cb18-14" aria-hidden="true" tabindex="-1"></a><span class="do">##  [26] &quot;das&quot;          &quot;à&quot;            &quot;seu&quot;          &quot;sua&quot;          &quot;ou&quot;          </span></span>
<span id="cb18-15"><a href="análise-textual-text-mining.html#cb18-15" aria-hidden="true" tabindex="-1"></a><span class="do">##  [31] &quot;quando&quot;       &quot;muito&quot;        &quot;nos&quot;          &quot;já&quot;           &quot;eu&quot;          </span></span>
<span id="cb18-16"><a href="análise-textual-text-mining.html#cb18-16" aria-hidden="true" tabindex="-1"></a><span class="do">##  [36] &quot;também&quot;       &quot;só&quot;           &quot;pelo&quot;         &quot;pela&quot;         &quot;até&quot;         </span></span>
<span id="cb18-17"><a href="análise-textual-text-mining.html#cb18-17" aria-hidden="true" tabindex="-1"></a><span class="do">##  [41] &quot;isso&quot;         &quot;ela&quot;          &quot;entre&quot;        &quot;depois&quot;       &quot;sem&quot;         </span></span>
<span id="cb18-18"><a href="análise-textual-text-mining.html#cb18-18" aria-hidden="true" tabindex="-1"></a><span class="do">##  [46] &quot;mesmo&quot;        &quot;aos&quot;          &quot;seus&quot;         &quot;quem&quot;         &quot;nas&quot;         </span></span>
<span id="cb18-19"><a href="análise-textual-text-mining.html#cb18-19" aria-hidden="true" tabindex="-1"></a><span class="do">##  [51] &quot;me&quot;           &quot;esse&quot;         &quot;eles&quot;         &quot;você&quot;         &quot;essa&quot;        </span></span>
<span id="cb18-20"><a href="análise-textual-text-mining.html#cb18-20" aria-hidden="true" tabindex="-1"></a><span class="do">##  [56] &quot;num&quot;          &quot;nem&quot;          &quot;suas&quot;         &quot;meu&quot;          &quot;às&quot;          </span></span>
<span id="cb18-21"><a href="análise-textual-text-mining.html#cb18-21" aria-hidden="true" tabindex="-1"></a><span class="do">##  [61] &quot;minha&quot;        &quot;numa&quot;         &quot;pelos&quot;        &quot;elas&quot;         &quot;qual&quot;        </span></span>
<span id="cb18-22"><a href="análise-textual-text-mining.html#cb18-22" aria-hidden="true" tabindex="-1"></a><span class="do">##  [66] &quot;nós&quot;          &quot;lhe&quot;          &quot;deles&quot;        &quot;essas&quot;        &quot;esses&quot;       </span></span>
<span id="cb18-23"><a href="análise-textual-text-mining.html#cb18-23" aria-hidden="true" tabindex="-1"></a><span class="do">##  [71] &quot;pelas&quot;        &quot;este&quot;         &quot;dele&quot;         &quot;tu&quot;           &quot;te&quot;          </span></span>
<span id="cb18-24"><a href="análise-textual-text-mining.html#cb18-24" aria-hidden="true" tabindex="-1"></a><span class="do">##  [76] &quot;vocês&quot;        &quot;vos&quot;          &quot;lhes&quot;         &quot;meus&quot;         &quot;minhas&quot;      </span></span>
<span id="cb18-25"><a href="análise-textual-text-mining.html#cb18-25" aria-hidden="true" tabindex="-1"></a><span class="do">##  [81] &quot;teu&quot;          &quot;tua&quot;          &quot;teus&quot;         &quot;tuas&quot;         &quot;nosso&quot;       </span></span>
<span id="cb18-26"><a href="análise-textual-text-mining.html#cb18-26" aria-hidden="true" tabindex="-1"></a><span class="do">##  [86] &quot;nossa&quot;        &quot;nossos&quot;       &quot;nossas&quot;       &quot;dela&quot;         &quot;delas&quot;       </span></span>
<span id="cb18-27"><a href="análise-textual-text-mining.html#cb18-27" aria-hidden="true" tabindex="-1"></a><span class="do">##  [91] &quot;esta&quot;         &quot;estes&quot;        &quot;estas&quot;        &quot;aquele&quot;       &quot;aquela&quot;      </span></span>
<span id="cb18-28"><a href="análise-textual-text-mining.html#cb18-28" aria-hidden="true" tabindex="-1"></a><span class="do">##  [96] &quot;aqueles&quot;      &quot;aquelas&quot;      &quot;isto&quot;         &quot;aquilo&quot;       &quot;estou&quot;       </span></span>
<span id="cb18-29"><a href="análise-textual-text-mining.html#cb18-29" aria-hidden="true" tabindex="-1"></a><span class="do">## [101] &quot;está&quot;         &quot;estamos&quot;      &quot;estão&quot;        &quot;estive&quot;       &quot;esteve&quot;      </span></span>
<span id="cb18-30"><a href="análise-textual-text-mining.html#cb18-30" aria-hidden="true" tabindex="-1"></a><span class="do">## [106] &quot;estivemos&quot;    &quot;estiveram&quot;    &quot;estava&quot;       &quot;estávamos&quot;    &quot;estavam&quot;     </span></span>
<span id="cb18-31"><a href="análise-textual-text-mining.html#cb18-31" aria-hidden="true" tabindex="-1"></a><span class="do">## [111] &quot;estivera&quot;     &quot;estivéramos&quot;  &quot;esteja&quot;       &quot;estejamos&quot;    &quot;estejam&quot;     </span></span>
<span id="cb18-32"><a href="análise-textual-text-mining.html#cb18-32" aria-hidden="true" tabindex="-1"></a><span class="do">## [116] &quot;estivesse&quot;    &quot;estivéssemos&quot; &quot;estivessem&quot;   &quot;estiver&quot;      &quot;estivermos&quot;  </span></span>
<span id="cb18-33"><a href="análise-textual-text-mining.html#cb18-33" aria-hidden="true" tabindex="-1"></a><span class="do">## [121] &quot;estiverem&quot;    &quot;hei&quot;          &quot;há&quot;           &quot;havemos&quot;      &quot;hão&quot;         </span></span>
<span id="cb18-34"><a href="análise-textual-text-mining.html#cb18-34" aria-hidden="true" tabindex="-1"></a><span class="do">## [126] &quot;houve&quot;        &quot;houvemos&quot;     &quot;houveram&quot;     &quot;houvera&quot;      &quot;houvéramos&quot;  </span></span>
<span id="cb18-35"><a href="análise-textual-text-mining.html#cb18-35" aria-hidden="true" tabindex="-1"></a><span class="do">## [131] &quot;haja&quot;         &quot;hajamos&quot;      &quot;hajam&quot;        &quot;houvesse&quot;     &quot;houvéssemos&quot; </span></span>
<span id="cb18-36"><a href="análise-textual-text-mining.html#cb18-36" aria-hidden="true" tabindex="-1"></a><span class="do">## [136] &quot;houvessem&quot;    &quot;houver&quot;       &quot;houvermos&quot;    &quot;houverem&quot;     &quot;houverei&quot;    </span></span>
<span id="cb18-37"><a href="análise-textual-text-mining.html#cb18-37" aria-hidden="true" tabindex="-1"></a><span class="do">## [141] &quot;houverá&quot;      &quot;houveremos&quot;   &quot;houverão&quot;     &quot;houveria&quot;     &quot;houveríamos&quot; </span></span>
<span id="cb18-38"><a href="análise-textual-text-mining.html#cb18-38" aria-hidden="true" tabindex="-1"></a><span class="do">## [146] &quot;houveriam&quot;    &quot;sou&quot;          &quot;somos&quot;        &quot;são&quot;          &quot;era&quot;         </span></span>
<span id="cb18-39"><a href="análise-textual-text-mining.html#cb18-39" aria-hidden="true" tabindex="-1"></a><span class="do">## [151] &quot;éramos&quot;       &quot;eram&quot;         &quot;fui&quot;          &quot;foi&quot;          &quot;fomos&quot;       </span></span>
<span id="cb18-40"><a href="análise-textual-text-mining.html#cb18-40" aria-hidden="true" tabindex="-1"></a><span class="do">## [156] &quot;foram&quot;        &quot;fora&quot;         &quot;fôramos&quot;      &quot;seja&quot;         &quot;sejamos&quot;     </span></span>
<span id="cb18-41"><a href="análise-textual-text-mining.html#cb18-41" aria-hidden="true" tabindex="-1"></a><span class="do">## [161] &quot;sejam&quot;        &quot;fosse&quot;        &quot;fôssemos&quot;     &quot;fossem&quot;       &quot;for&quot;         </span></span>
<span id="cb18-42"><a href="análise-textual-text-mining.html#cb18-42" aria-hidden="true" tabindex="-1"></a><span class="do">## [166] &quot;formos&quot;       &quot;forem&quot;        &quot;serei&quot;        &quot;será&quot;         &quot;seremos&quot;     </span></span>
<span id="cb18-43"><a href="análise-textual-text-mining.html#cb18-43" aria-hidden="true" tabindex="-1"></a><span class="do">## [171] &quot;serão&quot;        &quot;seria&quot;        &quot;seríamos&quot;     &quot;seriam&quot;       &quot;tenho&quot;       </span></span>
<span id="cb18-44"><a href="análise-textual-text-mining.html#cb18-44" aria-hidden="true" tabindex="-1"></a><span class="do">## [176] &quot;tem&quot;          &quot;temos&quot;        &quot;tém&quot;          &quot;tinha&quot;        &quot;tínhamos&quot;    </span></span>
<span id="cb18-45"><a href="análise-textual-text-mining.html#cb18-45" aria-hidden="true" tabindex="-1"></a><span class="do">## [181] &quot;tinham&quot;       &quot;tive&quot;         &quot;teve&quot;         &quot;tivemos&quot;      &quot;tiveram&quot;     </span></span>
<span id="cb18-46"><a href="análise-textual-text-mining.html#cb18-46" aria-hidden="true" tabindex="-1"></a><span class="do">## [186] &quot;tivera&quot;       &quot;tivéramos&quot;    &quot;tenha&quot;        &quot;tenhamos&quot;     &quot;tenham&quot;      </span></span>
<span id="cb18-47"><a href="análise-textual-text-mining.html#cb18-47" aria-hidden="true" tabindex="-1"></a><span class="do">## [191] &quot;tivesse&quot;      &quot;tivéssemos&quot;   &quot;tivessem&quot;     &quot;tiver&quot;        &quot;tivermos&quot;    </span></span>
<span id="cb18-48"><a href="análise-textual-text-mining.html#cb18-48" aria-hidden="true" tabindex="-1"></a><span class="do">## [196] &quot;tiverem&quot;      &quot;terei&quot;        &quot;terá&quot;         &quot;teremos&quot;      &quot;terão&quot;       </span></span>
<span id="cb18-49"><a href="análise-textual-text-mining.html#cb18-49" aria-hidden="true" tabindex="-1"></a><span class="do">## [201] &quot;teria&quot;        &quot;teríamos&quot;     &quot;teriam&quot;</span></span></code></pre></div>
<!-- stopwords("pt-br") -->
<p>Há também o pacote <a href="https://github.com/quanteda/stopwords">stopwords</a>, que no momento possui, para o português, de fontes como snowball, nltk e stopwords-iso. Para instalar, basta rodar o já conhecido <code>install.packages("stopwords")</code>.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="análise-textual-text-mining.html#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># vendo as linguagens disponiveis</span></span>
<span id="cb19-2"><a href="análise-textual-text-mining.html#cb19-2" aria-hidden="true" tabindex="-1"></a>stopwords<span class="sc">::</span><span class="fu">stopwords_getlanguages</span>(<span class="st">&quot;snowball&quot;</span>)</span>
<span id="cb19-3"><a href="análise-textual-text-mining.html#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="do">##  [1] &quot;da&quot; &quot;de&quot; &quot;en&quot; &quot;es&quot; &quot;fi&quot; &quot;fr&quot; &quot;hu&quot; &quot;ir&quot; &quot;it&quot; &quot;nl&quot; &quot;no&quot; &quot;pt&quot; &quot;ro&quot; &quot;ru&quot; &quot;sv&quot;</span></span>
<span id="cb19-4"><a href="análise-textual-text-mining.html#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="co"># vendo as fontes de stopwords disponíveis</span></span>
<span id="cb19-5"><a href="análise-textual-text-mining.html#cb19-5" aria-hidden="true" tabindex="-1"></a>stopwords<span class="sc">::</span><span class="fu">stopwords_getsources</span>()</span>
<span id="cb19-6"><a href="análise-textual-text-mining.html#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] &quot;snowball&quot;      &quot;stopwords-iso&quot; &quot;misc&quot;          &quot;smart&quot;        </span></span>
<span id="cb19-7"><a href="análise-textual-text-mining.html#cb19-7" aria-hidden="true" tabindex="-1"></a><span class="do">## [5] &quot;marimo&quot;        &quot;ancient&quot;       &quot;nltk&quot;          &quot;perseus&quot;</span></span>
<span id="cb19-8"><a href="análise-textual-text-mining.html#cb19-8" aria-hidden="true" tabindex="-1"></a><span class="co"># vendo um extrato das stopwords em português, fonte snowball</span></span>
<span id="cb19-9"><a href="análise-textual-text-mining.html#cb19-9" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(stopwords<span class="sc">::</span><span class="fu">stopwords</span>(<span class="st">&quot;pt&quot;</span>, <span class="at">source =</span> <span class="st">&quot;snowball&quot;</span>), <span class="dv">20</span>)</span>
<span id="cb19-10"><a href="análise-textual-text-mining.html#cb19-10" aria-hidden="true" tabindex="-1"></a><span class="do">##  [1] &quot;de&quot;   &quot;a&quot;    &quot;o&quot;    &quot;que&quot;  &quot;e&quot;    &quot;do&quot;   &quot;da&quot;   &quot;em&quot;   &quot;um&quot;   &quot;para&quot;</span></span>
<span id="cb19-11"><a href="análise-textual-text-mining.html#cb19-11" aria-hidden="true" tabindex="-1"></a><span class="do">## [11] &quot;com&quot;  &quot;não&quot;  &quot;uma&quot;  &quot;os&quot;   &quot;no&quot;   &quot;se&quot;   &quot;na&quot;   &quot;por&quot;  &quot;mais&quot; &quot;as&quot;</span></span>
<span id="cb19-12"><a href="análise-textual-text-mining.html#cb19-12" aria-hidden="true" tabindex="-1"></a><span class="co"># vendo um extrato das stopwords em português, fonte stopwords-iso</span></span>
<span id="cb19-13"><a href="análise-textual-text-mining.html#cb19-13" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(stopwords<span class="sc">::</span><span class="fu">stopwords</span>(<span class="st">&quot;pt&quot;</span>, <span class="at">source =</span> <span class="st">&quot;stopwords-iso&quot;</span>), <span class="dv">20</span>)</span>
<span id="cb19-14"><a href="análise-textual-text-mining.html#cb19-14" aria-hidden="true" tabindex="-1"></a><span class="do">##  [1] &quot;a&quot;       &quot;acerca&quot;  &quot;adeus&quot;   &quot;agora&quot;   &quot;ainda&quot;   &quot;alem&quot;    &quot;algmas&quot; </span></span>
<span id="cb19-15"><a href="análise-textual-text-mining.html#cb19-15" aria-hidden="true" tabindex="-1"></a><span class="do">##  [8] &quot;algo&quot;    &quot;algumas&quot; &quot;alguns&quot;  &quot;ali&quot;     &quot;além&quot;    &quot;ambas&quot;   &quot;ambos&quot;  </span></span>
<span id="cb19-16"><a href="análise-textual-text-mining.html#cb19-16" aria-hidden="true" tabindex="-1"></a><span class="do">## [15] &quot;ano&quot;     &quot;anos&quot;    &quot;antes&quot;   &quot;ao&quot;      &quot;aonde&quot;   &quot;aos&quot;</span></span></code></pre></div>
<p>E comparando o número de elementos das diferentes fontes de stopwords</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="análise-textual-text-mining.html#cb20-1" aria-hidden="true" tabindex="-1"></a>stopwords<span class="sc">::</span><span class="fu">stopwords</span>(<span class="st">&quot;pt&quot;</span>, <span class="at">source =</span> <span class="st">&quot;stopwords-iso&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">length</span>()</span>
<span id="cb20-2"><a href="análise-textual-text-mining.html#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 560</span></span>
<span id="cb20-3"><a href="análise-textual-text-mining.html#cb20-3" aria-hidden="true" tabindex="-1"></a>stopwords<span class="sc">::</span><span class="fu">stopwords</span>(<span class="st">&quot;pt&quot;</span>, <span class="at">source =</span> <span class="st">&quot;snowball&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">length</span>()</span>
<span id="cb20-4"><a href="análise-textual-text-mining.html#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 203</span></span>
<span id="cb20-5"><a href="análise-textual-text-mining.html#cb20-5" aria-hidden="true" tabindex="-1"></a>stopwords<span class="sc">::</span><span class="fu">stopwords</span>(<span class="st">&quot;pt&quot;</span>, <span class="at">source =</span> <span class="st">&quot;nltk&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">length</span>()</span>
<span id="cb20-6"><a href="análise-textual-text-mining.html#cb20-6" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 204</span></span></code></pre></div>
<p>Para aplicar esta função no nosso texto, podemos usar <code>removeWords(texto, stopwords("pt"))</code>. Diferentes pacotes de análise textual possuem diferentes formas de retirar as stopwords.
<!-- ?stopwords_getlanguages` for more information on supported languages--></p>
<p>Para adicionar novas palavras à lista de stopwords que vamos usar no momento, cria-se um novo vetor - chamamos aqui de “novas_stopwords” - com as novas palavras a serem retiradas, e em seguida o <code>stopwords()</code></p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="análise-textual-text-mining.html#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># checando o tamanho do vetor stopwords disponível</span></span>
<span id="cb21-2"><a href="análise-textual-text-mining.html#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="fu">length</span>(tm<span class="sc">::</span><span class="fu">stopwords</span>(<span class="st">&quot;pt&quot;</span>))</span>
<span id="cb21-3"><a href="análise-textual-text-mining.html#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 203</span></span>
<span id="cb21-4"><a href="análise-textual-text-mining.html#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="co"># criando novo vetor com mais palavras</span></span>
<span id="cb21-5"><a href="análise-textual-text-mining.html#cb21-5" aria-hidden="true" tabindex="-1"></a>novas_stopwords <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;então&quot;</span>, <span class="st">&quot;portanto&quot;</span>, tm<span class="sc">::</span><span class="fu">stopwords</span>(<span class="st">&quot;pt&quot;</span>)) </span>
<span id="cb21-6"><a href="análise-textual-text-mining.html#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="co"># checando se nossos termos foram incluídos</span></span>
<span id="cb21-7"><a href="análise-textual-text-mining.html#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="fu">length</span>(novas_stopwords)</span>
<span id="cb21-8"><a href="análise-textual-text-mining.html#cb21-8" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 205</span></span></code></pre></div>
<p>Ou para facilitar a inclusão de novos termos, podemos fazer do seguinte modo:</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="análise-textual-text-mining.html#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Separamos nossos termos por espaço</span></span>
<span id="cb22-2"><a href="análise-textual-text-mining.html#cb22-2" aria-hidden="true" tabindex="-1"></a>novas <span class="ot">&lt;-</span> <span class="st">&quot;então portanto&quot;</span></span>
<span id="cb22-3"><a href="análise-textual-text-mining.html#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="co"># quebrando o char em vetor de termos</span></span>
<span id="cb22-4"><a href="análise-textual-text-mining.html#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="co"># ao invés de usarmos unlist, podemos usar [[1]]</span></span>
<span id="cb22-5"><a href="análise-textual-text-mining.html#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="fu">strsplit</span>(novas, <span class="st">&quot; &quot;</span>)[[<span class="dv">1</span>]]</span>
<span id="cb22-6"><a href="análise-textual-text-mining.html#cb22-6" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] &quot;então&quot;    &quot;portanto&quot;</span></span>
<span id="cb22-7"><a href="análise-textual-text-mining.html#cb22-7" aria-hidden="true" tabindex="-1"></a><span class="co"># colocando os novos termos em um novo vetor</span></span>
<span id="cb22-8"><a href="análise-textual-text-mining.html#cb22-8" aria-hidden="true" tabindex="-1"></a>novas_stopwords <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">strsplit</span>(novas, <span class="st">&quot; &quot;</span>)[[<span class="dv">1</span>]], tm<span class="sc">::</span><span class="fu">stopwords</span>(<span class="st">&quot;pt&quot;</span>))</span>
<span id="cb22-9"><a href="análise-textual-text-mining.html#cb22-9" aria-hidden="true" tabindex="-1"></a><span class="fu">length</span>(novas_stopwords)</span>
<span id="cb22-10"><a href="análise-textual-text-mining.html#cb22-10" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 205</span></span></code></pre></div>
<p>Deste modo, podemos ir acrescentando mais facilmente novos termos à nossa lista de stopwords.</p>
<p>Há outras funções com listas de stopwords, como <a href="https://www.rdocumentation.org/packages/qdap/versions/0.2.5/topics/stopwords">qdap::stopwords</a>.
<!-- removeWords(texto, novas_stopwords) # removendo as stopwords --></p>
<p>Para remover stopwords, temos diferentes pacotes com diferentes funções, como <code>dplyr::anti_join()</code>, <code>tm::tm_map(corpus, removeWords, stopwords("english")</code> e <a href="https://search.r-project.org/CRAN/refmans/qdap/html/rm_stopwords.html"><code>qdap::rm_stopwords()</code></a>.
O dplyr possui ainda a função <code>semi_join</code> que mostra termos em comum, que se repetem em x e y.
Já <code>anti_join</code> faz o oposto, mostra todas linhas de ‘x’ sem match em ‘y’, e é com ela que retiramos as stopwords.</p>
<!-- Data_corpus <-  Corpus(VectorSource(Data_clean$Review.clean.lower))  -->
<!-- Data_clean <- tm_map(Data_corpus,  removeWords, stopwords("english")) -->
</div>
<div id="estemização-stemming-e-lematização" class="section level2" number="8.6">
<h2><span class="header-section-number">8.6</span> Estemização (<em>stemming</em>) e lematização</h2>
<!-- stemDocument(c("bananeira", "bananal", "bananada")) -->
<!-- stemDocument(c("bananada", "andando", "amarelo"), language = "portuguese") -->
<!-- palavras_stem <- stemDocument(c("bananada", "andando", "amarelo"), language = "portuguese") -->
<!-- completar palavras usando -->
<!-- stemCompletion(stem_words, c("complicado"), language = "portuguese") -->
<p>Imagine que tenha palavras como “escrever, escrevi, escreveu” e você está interessado nos verbos mais frequentes. É útil considerar estas variações do verbo como uma palavra só. Isso pode ser obtido de dois modos, através da stemização e por lematização. Em ambos o objetivo é o mesmo, reduzir a flexão a uma base comum ou raiz. A estemização funciona cortando um pedaço do final da palavra, ao passo que lematização reduz as variações à raiz, podendo inclusive pegar verbos irregulares. Por que então usar estemização? A construção de lematizadores é mais complicada, além de ser um processo mais demorado e que consome mais recursos.</p>
<div id="stemming" class="section level3" number="8.6.1">
<h3><span class="header-section-number">8.6.1</span> Estemização</h3>
<p>A estemização pode ser feita com o pacote <a href="https://cran.r-project.org/web/packages/SnowballC/SnowballC.pdf">SnowballC</a>,que é baseado no <a href="https://snowballstem.org/">snowball</a>, que continua sendo desenvolvido no <a href="https://github.com/snowballstem">GitHub do projeto</a>.
Desenvolvida originalmente por Martin Porter, seu nome é um tributo ao SNOBOL, uma linguagem dos anos 1960 que lidava com strings.
Para entender o algoritmo de estemização em português e alguns exemplos, <a href="https://snowballstem.org/algorithms/portuguese/stemmer.html">veja aqui</a>.</p>
<p>Carregando o pacote SnowballC</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="análise-textual-text-mining.html#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(SnowballC)</span></code></pre></div>
<p>Exemplo de estemização</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="análise-textual-text-mining.html#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Vendo as línguas disponíveis</span></span>
<span id="cb24-2"><a href="análise-textual-text-mining.html#cb24-2" aria-hidden="true" tabindex="-1"></a>SnowballC<span class="sc">::</span><span class="fu">getStemLanguages</span>()</span>
<span id="cb24-3"><a href="análise-textual-text-mining.html#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="do">##  [1] &quot;arabic&quot;     &quot;basque&quot;     &quot;catalan&quot;    &quot;danish&quot;     &quot;dutch&quot;     </span></span>
<span id="cb24-4"><a href="análise-textual-text-mining.html#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="do">##  [6] &quot;english&quot;    &quot;finnish&quot;    &quot;french&quot;     &quot;german&quot;     &quot;greek&quot;     </span></span>
<span id="cb24-5"><a href="análise-textual-text-mining.html#cb24-5" aria-hidden="true" tabindex="-1"></a><span class="do">## [11] &quot;hindi&quot;      &quot;hungarian&quot;  &quot;indonesian&quot; &quot;irish&quot;      &quot;italian&quot;   </span></span>
<span id="cb24-6"><a href="análise-textual-text-mining.html#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="do">## [16] &quot;lithuanian&quot; &quot;nepali&quot;     &quot;norwegian&quot;  &quot;porter&quot;     &quot;portuguese&quot;</span></span>
<span id="cb24-7"><a href="análise-textual-text-mining.html#cb24-7" aria-hidden="true" tabindex="-1"></a><span class="do">## [21] &quot;romanian&quot;   &quot;russian&quot;    &quot;spanish&quot;    &quot;swedish&quot;    &quot;tamil&quot;     </span></span>
<span id="cb24-8"><a href="análise-textual-text-mining.html#cb24-8" aria-hidden="true" tabindex="-1"></a><span class="do">## [26] &quot;turkish&quot;</span></span>
<span id="cb24-9"><a href="análise-textual-text-mining.html#cb24-9" aria-hidden="true" tabindex="-1"></a><span class="co"># criando um vetor de palavras</span></span>
<span id="cb24-10"><a href="análise-textual-text-mining.html#cb24-10" aria-hidden="true" tabindex="-1"></a>palavras<span class="ot">=</span> <span class="fu">c</span>(<span class="st">&quot;plantar&quot;</span>, <span class="st">&quot;plantei&quot;</span>, <span class="st">&quot;ajudou&quot;</span>, <span class="st">&quot;ajudarás&quot;</span>, <span class="st">&quot;comer&quot;</span>, <span class="st">&quot;comendo&quot;</span>)</span>
<span id="cb24-11"><a href="análise-textual-text-mining.html#cb24-11" aria-hidden="true" tabindex="-1"></a><span class="co"># testando a stemização</span></span>
<span id="cb24-12"><a href="análise-textual-text-mining.html#cb24-12" aria-hidden="true" tabindex="-1"></a>SnowballC<span class="sc">::</span><span class="fu">wordStem</span>(palavras, <span class="at">language =</span> <span class="st">&quot;portuguese&quot;</span>)</span>
<span id="cb24-13"><a href="análise-textual-text-mining.html#cb24-13" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] &quot;plant&quot; &quot;plant&quot; &quot;ajud&quot;  &quot;ajud&quot;  &quot;com&quot;   &quot;com&quot;</span></span></code></pre></div>
<p>Vamos testar com outras palavras:</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="análise-textual-text-mining.html#cb25-1" aria-hidden="true" tabindex="-1"></a>palavras<span class="ot">=</span> <span class="fu">c</span>(<span class="st">&quot;estou&quot;</span>, <span class="st">&quot;está&quot;</span>, <span class="st">&quot;estamos&quot;</span>, <span class="st">&quot;sou&quot;</span>, <span class="st">&quot;és&quot;</span>)</span>
<span id="cb25-2"><a href="análise-textual-text-mining.html#cb25-2" aria-hidden="true" tabindex="-1"></a>SnowballC<span class="sc">::</span><span class="fu">wordStem</span>(palavras, <span class="at">language =</span> <span class="st">&quot;portuguese&quot;</span>)</span>
<span id="cb25-3"><a href="análise-textual-text-mining.html#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] &quot;estou&quot; &quot;está&quot;  &quot;estam&quot; &quot;sou&quot;   &quot;és&quot;</span></span></code></pre></div>
<p>Repare que verbos irregulares como “ser” e “estar” não funcionaram muito bem.
Uma alternativa é usar a lematização ao invés da stemização.</p>
</div>
<div id="lematização" class="section level3" number="8.6.2">
<h3><span class="header-section-number">8.6.2</span> Lematização</h3>
<div class="infobox obra">
<p><em>EM CONSTRUÇÃO</em></p>
</div>
<p>A lematização reduz variações/inflexões de uma palavra, de modo que sejam analisados como um termo único. A lematização chega à forma raiz da palavra, ainda que sejam verbos irregulares.
<!-- https://www.christianlehmann.eu/ling/ling_meth/ling_description/lexicography/index.html?https://www.christianlehmann.eu/ling/ling_meth/ling_description/lexicography/lemmatization.html --></p>
<p>Funções como <code>textstem::lemmatize_words()</code> , <code>koRpus::treetag</code>, <code>SnowballC::wordStem</code> e <code>udpipe</code> fazem este trabalho de lematização.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="análise-textual-text-mining.html#cb26-1" aria-hidden="true" tabindex="-1"></a>goffman_stigma <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;The central feature of the stigmatized individual&#39;s situation in life can now be stated.&quot;</span>, </span>
<span id="cb26-2"><a href="análise-textual-text-mining.html#cb26-2" aria-hidden="true" tabindex="-1"></a>                    <span class="st">&quot;It is a question of what is often, if vaguely, called `acceptance&#39;.&quot;</span>,</span>
<span id="cb26-3"><a href="análise-textual-text-mining.html#cb26-3" aria-hidden="true" tabindex="-1"></a>                    <span class="st">&quot;How does the stigmatized person respond to his situation?&quot;</span>)</span>
<span id="cb26-4"><a href="análise-textual-text-mining.html#cb26-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-5"><a href="análise-textual-text-mining.html#cb26-5" aria-hidden="true" tabindex="-1"></a><span class="do">## Default lexicon::hash_lemmas dictionary</span></span>
<span id="cb26-6"><a href="análise-textual-text-mining.html#cb26-6" aria-hidden="true" tabindex="-1"></a>textstem<span class="sc">::</span><span class="fu">lemmatize_strings</span>(goffman_stigma)</span></code></pre></div>
<pre><code>## [1] &quot;The central feature of the stigmatize individual&#39;s situation in life can now be state.&quot;
## [2] &quot;It be a question of what be often, if vague, call `acceptance&#39;.&quot;                       
## [3] &quot;How do the stigmatize person respond to his situation?&quot;</code></pre>
</div>
</div>
<div id="kwic" class="section level2" number="8.7">
<h2><span class="header-section-number">8.7</span> Palavras em contexto (<em>keyword-in-context KWIC</em>)</h2>
<!-- ::: {.infobox .obra data-latex="{construcao}"} -->
<!-- **CAPÍTULO AINDA EM CONSTRUÇÃO** -->
<!-- ::: -->
<p>Podemos ver como certas palavras são usadas em diversas frases no texto para ter uma ideia melhor do contexto em que aparecem.
No quanteda, usamos a função <code>kwic(Dados, pattern = "padrão")</code>, após o texto ter sido tokenizado.</p>
<p>Se ainda não tiver carregado o pacote Quanteda:</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="análise-textual-text-mining.html#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(quanteda)</span>
<span id="cb28-2"><a href="análise-textual-text-mining.html#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="do">## Package version: 3.1.0</span></span>
<span id="cb28-3"><a href="análise-textual-text-mining.html#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="do">## Unicode version: 13.0</span></span>
<span id="cb28-4"><a href="análise-textual-text-mining.html#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="do">## ICU version: 69.1</span></span>
<span id="cb28-5"><a href="análise-textual-text-mining.html#cb28-5" aria-hidden="true" tabindex="-1"></a><span class="do">## Parallel computing: 4 of 4 threads used.</span></span>
<span id="cb28-6"><a href="análise-textual-text-mining.html#cb28-6" aria-hidden="true" tabindex="-1"></a><span class="do">## See https://quanteda.io for tutorials and examples.</span></span></code></pre></div>
<p>Vamos para um exemplo do texto “Ciência como vocação” de Max Weber:</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="análise-textual-text-mining.html#cb29-1" aria-hidden="true" tabindex="-1"></a>texto <span class="ot">=</span> <span class="st">&quot;Por fim, é da sabedoria quotidiana que algo pode ser verdadeiro, embora não seja nem belo, nem sagrado, nem bom. Mas estes são apenas os casos mais elementares da luta que entre si travam os deuses dos ordenamentos e valores singulares. Como será possível pretender decidir &#39;cientificamente&#39; entre o valor da cultura francesa e o da alemã é coisa que não enxergo. Também aqui diferentes deuses lutam entre si, e para sempre. Acontece, embora noutro sentido, o mesmo que ocorria no mundo antigo, quando ainda se não tinha desencantado dos seus deuses e demónios: tal como os Gregos ofereciam sacrifícios, umas vezes, a Afrodite, outras a Apolo e, sobretudo, aos deuses da sua cidade, assim acontece ainda hoje, embora o culto se tenha desmistificado e careça da plástica mítica, mas intimamente verdadeira, daquela conduta. Sobre estes deuses e a sua eterna luta decide o destino, não decerto uma &#39;ciência&#39;. Apenas se pode compreender o que seja o divino para uma e outra ordem ou numa e noutra ordem&quot;</span></span></code></pre></div>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="análise-textual-text-mining.html#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># termos a serem buscados</span></span>
<span id="cb30-2"><a href="análise-textual-text-mining.html#cb30-2" aria-hidden="true" tabindex="-1"></a>termos.vetor<span class="ot">=</span> <span class="fu">c</span>(<span class="st">&quot;deus*&quot;</span>, <span class="st">&quot;divin*&quot;</span>, <span class="st">&quot;luta&quot;</span>)</span>
<span id="cb30-3"><a href="análise-textual-text-mining.html#cb30-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-4"><a href="análise-textual-text-mining.html#cb30-4" aria-hidden="true" tabindex="-1"></a>texto <span class="sc">%&gt;%</span> </span>
<span id="cb30-5"><a href="análise-textual-text-mining.html#cb30-5" aria-hidden="true" tabindex="-1"></a>  <span class="co"># precisamos primeiro tokenizar</span></span>
<span id="cb30-6"><a href="análise-textual-text-mining.html#cb30-6" aria-hidden="true" tabindex="-1"></a>  tokens<span class="sc">%&gt;%</span> </span>
<span id="cb30-7"><a href="análise-textual-text-mining.html#cb30-7" aria-hidden="true" tabindex="-1"></a>  <span class="co"># rodando a função de palavras chave em contexto</span></span>
<span id="cb30-8"><a href="análise-textual-text-mining.html#cb30-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kwic</span>(., </span>
<span id="cb30-9"><a href="análise-textual-text-mining.html#cb30-9" aria-hidden="true" tabindex="-1"></a>                 <span class="co"># termos a serem buscados. Pode ser um termo ou um vetor</span></span>
<span id="cb30-10"><a href="análise-textual-text-mining.html#cb30-10" aria-hidden="true" tabindex="-1"></a>                 termos.vetor, </span>
<span id="cb30-11"><a href="análise-textual-text-mining.html#cb30-11" aria-hidden="true" tabindex="-1"></a>                 <span class="co"># quantas palavras devem ser mostradas ao redor</span></span>
<span id="cb30-12"><a href="análise-textual-text-mining.html#cb30-12" aria-hidden="true" tabindex="-1"></a>                 <span class="dv">4</span>, </span>
<span id="cb30-13"><a href="análise-textual-text-mining.html#cb30-13" aria-hidden="true" tabindex="-1"></a>                 <span class="co"># Para pegar tanto palavras minúculas como as em maiúsculo. </span></span>
<span id="cb30-14"><a href="análise-textual-text-mining.html#cb30-14" aria-hidden="true" tabindex="-1"></a>                 <span class="at">case_insensitive =</span> <span class="cn">TRUE</span>)</span>
<span id="cb30-15"><a href="análise-textual-text-mining.html#cb30-15" aria-hidden="true" tabindex="-1"></a><span class="do">## Keyword-in-context with 8 matches.                                                                               </span></span>
<span id="cb30-16"><a href="análise-textual-text-mining.html#cb30-16" aria-hidden="true" tabindex="-1"></a><span class="do">##   [text1, 35]   casos mais elementares da |  luta  | que entre si travam       </span></span>
<span id="cb30-17"><a href="análise-textual-text-mining.html#cb30-17" aria-hidden="true" tabindex="-1"></a><span class="do">##   [text1, 41]          entre si travam os | deuses | dos ordenamentos e valores</span></span>
<span id="cb30-18"><a href="análise-textual-text-mining.html#cb30-18" aria-hidden="true" tabindex="-1"></a><span class="do">##   [text1, 75]    . Também aqui diferentes | deuses | lutam entre si,           </span></span>
<span id="cb30-19"><a href="análise-textual-text-mining.html#cb30-19" aria-hidden="true" tabindex="-1"></a><span class="do">##  [text1, 106] tinha desencantado dos seus | deuses | e demónios: tal           </span></span>
<span id="cb30-20"><a href="análise-textual-text-mining.html#cb30-20" aria-hidden="true" tabindex="-1"></a><span class="do">##  [text1, 131]            , sobretudo, aos | deuses | da sua cidade,            </span></span>
<span id="cb30-21"><a href="análise-textual-text-mining.html#cb30-21" aria-hidden="true" tabindex="-1"></a><span class="do">##  [text1, 162]        conduta. Sobre estes | deuses | e a sua eterna            </span></span>
<span id="cb30-22"><a href="análise-textual-text-mining.html#cb30-22" aria-hidden="true" tabindex="-1"></a><span class="do">##  [text1, 167]              e a sua eterna |  luta  | decide o destino,         </span></span>
<span id="cb30-23"><a href="análise-textual-text-mining.html#cb30-23" aria-hidden="true" tabindex="-1"></a><span class="do">##  [text1, 187]                o que seja o | divino | para uma e outra</span></span></code></pre></div>
<p>No KWIC é possível ainda:</p>
<ul>
<li>usar regex como padrão de busca, através do parâmetro <code>valuetype = "regex</code> em</li>
<li>buscar por duas ou mais palavras em contexto com <code>pattern = phrase(</code></li>
</ul>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="análise-textual-text-mining.html#cb31-1" aria-hidden="true" tabindex="-1"></a>texto <span class="sc">%&gt;%</span> </span>
<span id="cb31-2"><a href="análise-textual-text-mining.html#cb31-2" aria-hidden="true" tabindex="-1"></a>  <span class="co"># precisamos primeiro tokenizar</span></span>
<span id="cb31-3"><a href="análise-textual-text-mining.html#cb31-3" aria-hidden="true" tabindex="-1"></a>  tokens<span class="sc">%&gt;%</span> </span>
<span id="cb31-4"><a href="análise-textual-text-mining.html#cb31-4" aria-hidden="true" tabindex="-1"></a>  <span class="co"># rodando a função de palavras chave em contexto</span></span>
<span id="cb31-5"><a href="análise-textual-text-mining.html#cb31-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kwic</span>(., </span>
<span id="cb31-6"><a href="análise-textual-text-mining.html#cb31-6" aria-hidden="true" tabindex="-1"></a>                 <span class="co"># termos a serem buscados. Pode ser um termo ou um vetor</span></span>
<span id="cb31-7"><a href="análise-textual-text-mining.html#cb31-7" aria-hidden="true" tabindex="-1"></a>                  <span class="at">pattern =</span> <span class="fu">phrase</span>(<span class="st">&quot;eterna luta&quot;</span>),</span>
<span id="cb31-8"><a href="análise-textual-text-mining.html#cb31-8" aria-hidden="true" tabindex="-1"></a>                 <span class="co"># quantas palavras devem ser mostradas ao redor</span></span>
<span id="cb31-9"><a href="análise-textual-text-mining.html#cb31-9" aria-hidden="true" tabindex="-1"></a>                 <span class="dv">7</span>, </span>
<span id="cb31-10"><a href="análise-textual-text-mining.html#cb31-10" aria-hidden="true" tabindex="-1"></a>                 <span class="co"># Para pegar tanto palavras minúculas como as em maiúsculo. </span></span>
<span id="cb31-11"><a href="análise-textual-text-mining.html#cb31-11" aria-hidden="true" tabindex="-1"></a>                 <span class="at">case_insensitive =</span> <span class="cn">TRUE</span>)</span>
<span id="cb31-12"><a href="análise-textual-text-mining.html#cb31-12" aria-hidden="true" tabindex="-1"></a><span class="do">## Keyword-in-context with 1 match.                                                              </span></span>
<span id="cb31-13"><a href="análise-textual-text-mining.html#cb31-13" aria-hidden="true" tabindex="-1"></a><span class="do">##  [text1, 166:167] . Sobre estes deuses e a sua | eterna luta |</span></span>
<span id="cb31-14"><a href="análise-textual-text-mining.html#cb31-14" aria-hidden="true" tabindex="-1"></a><span class="do">##                                   </span></span>
<span id="cb31-15"><a href="análise-textual-text-mining.html#cb31-15" aria-hidden="true" tabindex="-1"></a><span class="do">##  decide o destino, não decerto uma</span></span></code></pre></div>
</div>
<div id="key-term-extraction" class="section level2" number="8.8">
<h2><span class="header-section-number">8.8</span> Key term extraction</h2>
<p>Dado um ou mais documentos, a extração automática de termos que descrevem estes documentos, dá se o nome de keyword extraction, podendo ser extraídas palavras, frases ou segmentos.
Exemplos de key word extraction são
<a href="análise-textual-text-mining.html#tf-idf">TF-IDF</a>,
Parts of Speech tagging (por exemplo, pegando os substantivos mais frequentes),
colocação e Coocorrências,
algoritmos textrank,
RAKE (Rapid Automatic Keyword Extraction),
YAKE! (Yet Another Keyword Extractor).</p>
<!-- https://www.r-bloggers.com/2018/04/an-overview-of-keyword-extraction-techniques/ -->
<div id="tf-idf" class="section level3" number="8.8.1">
<h3><span class="header-section-number">8.8.1</span> TF-IDF: Term-Frequency Inverse Document Frequency</h3>
<p>A “frequência do termo–inverso da frequência nos documentos”,
do inglês “<em>Term-Frequency Inverse Document Frequency</em>”, ou “TF-IDF” é utilizado para medir a relevância de palavras em uma série de documentos. Para funcionar, requer que existam vários documentos, ou textos, ou capítulos, etc.
Neste algoritmo, as palavras que aparecem em todos ou em muitos documentos - como as <a href="#stopwords">stopwords</a> - serão “penalizadas” e terão pontuação baixa.
Agora, se uma palavra aparece bastante em um documento, mas não em outros, terá pontuação alta, e isto pode indicar que seja relevante, significativa para entender a peculiaridade daquele documento/texto.
TF-IDF é útil num processo chamado de “<em>keyword extraction</em>” ou “extração de palavras chave”.</p>
<!-- Term Frequency (TF) tfi ,j : the number of occurrences of term ti in document dj -->
<p>Vamos para um exemplo:</p>
<blockquote>
<p>Documento 1: “Eu quero abacaxi”</p>
</blockquote>
<blockquote>
<p>Documento 2: “Eu? Eu quero banana”</p>
</blockquote>
<p>Frequência de termos, ou TF, representa a proporção que uma palavra tem no documento em questão. Esta frequência pode ser apresentada no formato de <a href="introdução-ao-r.html#matrix">matriz</a>.</p>
<table>
<thead>
<tr class="header">
<th><strong>Frequência</strong></th>
<th>Doc 1</th>
<th>Doc2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Eu</td>
<td>1</td>
<td>2</td>
</tr>
<tr class="even">
<td>quero</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="odd">
<td>abacaxi</td>
<td>1</td>
<td>0</td>
</tr>
<tr class="even">
<td>banana</td>
<td>0</td>
<td>1</td>
</tr>
<tr class="odd">
<td>total palavras</td>
<td>3</td>
<td>4</td>
</tr>
</tbody>
</table>
<!--  ```{r, echo=FALSE, eval=TRUE, cache=TRUE} -->
<!-- doc1 <- "Eu quero abacaxi" -->
<!-- doc2 <- "Eu? Eu quero banana" -->
<!-- corpus1 <- c(doc1,doc2) -->
<!-- meu_corpus <- tm::Corpus(tm::VectorSource(corpus1)) -->
<!-- meu_corpus2 <-  -->
<!--   # passando tudo para minúsculo -->
<!--   tm::tm_map(meu_corpus, tolower) # %>% -->
<!--   # removendo pontuações -->
<!--   # tm::tm_map(., tm::removePunctuation )  -->
<!-- # Para visualizar, transformamos nosso objeto em matriz -->
<!-- as.matrix(meu_tdm)  -->
<!--  ``` -->
<div id="tf-frequência-de-termos-term-frequency" class="section level4" number="8.8.1.1">
<h4><span class="header-section-number">8.8.1.1</span> TF: Frequência de termos (<em>Term Frequency</em>)</h4>
<p>O TF de um termo que ocorre em um documento é calculado da seguinte maneira:</p>
<blockquote>
<p><span class="math inline">\(tf(t,d)\)</span> : contagem de t(termo) em d(documento) / número de palavras no documento</p>
</blockquote>
<p>O documento 1 possui 3 palavras, o documento 2 possui 4 palavras, portanto, a frequência de termos (TF) fica assim:</p>
<table>
<thead>
<tr class="header">
<th><strong>TF</strong></th>
<th>Doc 1</th>
<th>Doc2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Eu</td>
<td>1 / 3 = 0,33333</td>
<td>2 / 4 = 0,5</td>
</tr>
<tr class="even">
<td>quero</td>
<td>1 / 3 = 0,33333</td>
<td>1 / 4 = 0,25</td>
</tr>
<tr class="odd">
<td>abacaxi</td>
<td>1 / 3 = 0,33333</td>
<td>0</td>
</tr>
<tr class="even">
<td>banana</td>
<td>0</td>
<td>1 / 4 = 0,25</td>
</tr>
<tr class="odd">
<td>Total</td>
<td>1</td>
<td>1</td>
</tr>
</tbody>
</table>
<p>No Documento 1, temos 3 palavras no total, cada uma, por ser única no documento, possui TF de 1/3, ou 0,33333.
O Documento 2 possui 4 palavras no total. “quero” e “banana” possui um TF de 1/4 cada, ou 0,25, enquanto “eu”, que apareceu duas vezes, possui TF de 2/4 ou 0,5.
TF me diz o quão frequente é uma palavra/termo em um documento. Isto pode ser feito em números absolutos bem como em termos proporcionais (bom olhar as documentações dos pacotes para entender qual o padrão utilizado)</p>
<!-- - Ver (Luhn, 1957) -->
<!-- Because of the large number of documents in many collections, this measure too is usually squashed with a log function.  -->
</div>
<div id="idf-inverse-document-frequency" class="section level4" number="8.8.1.2">
<h4><span class="header-section-number">8.8.1.2</span> IDF: Inverse Document Frequency</h4>
<p>IDF, <em>inverse document frequency</em>, mostra o peso de um termo em relação à coleção total de documentos/textos, dando um valor baixo para termos frequentes em todos os documentos e que por isso são pouco informativos sobre as peculiaridades daquele documento, bem como privilegia termos frequentes em poucos documentos.</p>
<p>Assim, no nosso exemplo, as palavras “eu” e “quero” estão presentes em dois documentos de um total de dois documentos, tendo o IDF de 0.
Já “abacaxi” e “banana”, termos que aparecem uma vez e somente em um documento cada, possuem IDF de 0,30102.</p>
<p>O <strong>cálculo</strong> é feito da seguinte forma:</p>
<blockquote>
<p>Número de documentos no corpus (no caso acima, dois), dividido pelo número de documentos onde o termo aparece. Se o termo aparece uma vez somente ou 50 vezes em um documento, em ambos os casos será computado como um.
O resultado disto é posto num logaritmo.</p>
</blockquote>
<table>
<thead>
<tr class="header">
<th></th>
<th>IDF</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Eu</td>
<td>Log(2/2) = 0</td>
<td></td>
</tr>
<tr class="even">
<td>quero</td>
<td>Log(2/2) = 0</td>
<td></td>
</tr>
<tr class="odd">
<td>abacaxi</td>
<td>Log(2/1) = 0,30102</td>
<td></td>
</tr>
<tr class="even">
<td>banana</td>
<td>Log(2/1) = 0,30102</td>
<td></td>
</tr>
</tbody>
</table>
<p>Com o IDF sabemos quais termos ocorrem em vários documentos e os que ocorrem em poucos. Para saber o peso de cada termo em cada documento, usamos então o TF-IDF.</p>
</div>
<div id="calculando-tf-idf" class="section level4" number="8.8.1.3">
<h4><span class="header-section-number">8.8.1.3</span> Calculando TF-IDF</h4>
<p>TF-IDF é a multiplicação dos dois termos, TF * IDF.
Ao multiplicar TF por IDF, obtemos o <em>score</em> da palavra no documento.</p>
<table>
<thead>
<tr class="header">
<th></th>
<th>TF Doc 1</th>
<th>TF Doc2</th>
<th>IDF</th>
<th>TF-IDF Doc1</th>
<th>TF-IDF Doc2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Eu</td>
<td>1 / 3 = 0,33333</td>
<td>2 / 4 = 0,5</td>
<td>Log(2/2) = 0</td>
<td>0,33333 * 0 = 0</td>
<td>0,5 * 0 = 0</td>
</tr>
<tr class="even">
<td>quero</td>
<td>1 / 3 = 0,33333</td>
<td>1 / 4 = 0,25</td>
<td>Log(2/2) = 0</td>
<td>0,33333 * 0 = 0</td>
<td>0,5 * 0 = 0</td>
</tr>
<tr class="odd">
<td>abacaxi</td>
<td>1 / 3 = 0,33333</td>
<td>0</td>
<td>Log(2/1) = 0,301</td>
<td>0,3 * 0,3 = 0,1003</td>
<td>0 * 0,3 = 0</td>
</tr>
<tr class="even">
<td>banana</td>
<td>0</td>
<td>1 / 4 = 0,25</td>
<td>Log(2/1) = 0,301</td>
<td>0 * 0,3 = 0</td>
<td>0,25 * 0,3 = 0,0752</td>
</tr>
</tbody>
</table>
<!-- |TF-IDF |Doc 1|Doc2| -->
<!-- |---|---|---| -->
<!-- |Eu|0|0| -->
<!-- |quero|0|0| -->
<!-- |abacaxi|0|0,6931472| -->
<!-- |banana|0,6931472|0| -->
<div class="infobox matematica">
<p><strong>Matemática</strong></p>
<p>Esta é a fórmula do tf-idf, e nos retorna o índice tf-idf para cada palavra em cada documento.</p>
<blockquote>
<p><span class="math inline">\(W_{ij} = tf_{i,j} \times \log(\frac{N}{df_i})\)</span></p>
</blockquote>
<p>Destrinchando a fórmula:</p>
<table>
<colgroup>
<col width="50%" />
<col width="50%" />
</colgroup>
<thead>
<tr class="header">
<th>Fórmula</th>
<th>Descrição</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(W_{ij}\)</span></td>
<td>um termo <span class="math inline">\(i\)</span> num documento <span class="math inline">\(j\)</span>, para o qual vamos calcular o tf-idf</td>
</tr>
<tr class="even">
<td><span class="math inline">\(tf_{i,j}\)</span></td>
<td>frequência do termo <span class="math inline">\(i\)</span>, no documento <span class="math inline">\(j\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(df_{ij}\)</span></td>
<td>Número de documentos que contenham o termo <span class="math inline">\(i\)</span>. Pouco importa se aparece apenas uma vez ou se 500 vezes num mesmo documento, seu valor em cada documento, se presente, é 1</td>
</tr>
<tr class="even">
<td><span class="math inline">\(N\)</span></td>
<td>Número total de documentos</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(df_i\)</span></td>
<td>frequência de documentos que contenham o termo <span class="math inline">\(i\)</span></td>
</tr>
</tbody>
</table>
</div>
<!-- Frequência de documento (_Document Frequency_):Número de documentos em que o termo está presente -->
<!-- > $df(t)$ = ocorrência de t em documentos -->
<p>Se o resultado encontrado se aproximar de “0”, então a palavra se encontra presente em vários documentos. Caso contrário, quanto mais se aproxima de “1”, mais rara é esta palavra em outros documentos e mais concentrada em poucos documentos.
Vale ressaltar que o cálculo TF-IDF pode ser feito tanto com a frequência absoluta ou como com a relativa.</p>
<p>Vimos exemplo de TF-IDF com apenas dois “documentos”. Vamos usar mais documentos para entender melhor o TF-IDF. Usamos um pacote de R nos bastidores para gerar a tabela à seguir, mas veremos o código que o gerou mais à frente.</p>
<!-- doc2 <- "Eu? Eu quero banana!" -->
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="análise-textual-text-mining.html#cb32-1" aria-hidden="true" tabindex="-1"></a>doc1 <span class="ot">&lt;-</span> <span class="st">&quot;Eu quero abacaxi!&quot;</span></span>
<span id="cb32-2"><a href="análise-textual-text-mining.html#cb32-2" aria-hidden="true" tabindex="-1"></a>doc2 <span class="ot">&lt;-</span> <span class="st">&quot;Eu quero açaí!&quot;</span></span>
<span id="cb32-3"><a href="análise-textual-text-mining.html#cb32-3" aria-hidden="true" tabindex="-1"></a>doc3 <span class="ot">&lt;-</span> <span class="st">&quot;Eu quero manga ou açaí! Eu quero manga! Manga!&quot;</span></span></code></pre></div>
<p>O exemplo acima possui diferentes configurações de palavras para observarmos o TF-IDF:</p>
<ul>
<li>“eu” e “quero” em todos os docs</li>
<li>“abacaxi”, “manga” e “ou” que ocorrem uma vez.</li>
<li>“açaí” que ocorre uma vez em dois documentos diferentes.</li>
<li>“manga” que aparece várias vezes em um documento somente.</li>
</ul>
<!--  ```{r, echo=F, collapse = TRUE, chache = TRUE} -->
<!-- df <- data.frame("texto" = c(doc1,doc2, doc3),  -->
<!--                  "ID" = c(1:3),  -->
<!--                  stringsAsFactors = F) -->
<!-- df %>%  -->
<!--      tidytext::unnest_tokens(output = 'word', token = 'words',  -->
<!--                              # input =  nome da coluna do dataframe -->
<!--                              input = texto) %>% -->
<!--      dplyr::count(ID, word, sort = TRUE) %>% -->
<!--      tidytext::bind_tf_idf(word, ID, n) -->
<!--  ``` -->
<pre><code>## Document-feature matrix of: 3 documents, 6 features (38.89% sparse) and 0 docvars.
##        features
## docs    eu quero   abacaxi       açaí     manga         ou
##   text1  0     0 0.1590404 0          0         0         
##   text2  0     0 0         0.05869709 0         0         
##   text3  0     0 0         0.01956570 0.1590404 0.05301347</code></pre>
<ul>
<li>“eu” e “quero” ocorrem em todos os docs e possuem TF-IDF de 0 em todos os casos.</li>
<li>“abacaxi” aparece somente na primeira frase e tem TF-IDF de 0.1590404</li>
<li>“açaí” ocorre uma vez em dois documentos possui TF-IDF em um doc com menos palavras no total.</li>
<li>“ou” e “manga” só aparecem na frase 3, e manga aparece 3 vezes e tem TF-IDF maior que a palavra “ou”, que só aparece uma vez.</li>
<li>No doc3, “ou” (que só aparece uma vez em um doc) possui TF-IDF maior que “açaí”, que aparece em mais de um doc.
<!-- - "manga" aparece várias vezes em um documento e possui TF-IDF maior que "ou" que  -->
<!-- somente possui o mesmo IDF de palavras que aparecem apenas uma vez em um documento, como abacaxi, e banana. --></li>
</ul>
<p>Podemos realizar o TF-IDF no R calculando manualmente, como neste <a href="https://www.youtube.com/watch?v=az7yf0IfWPM">exemplo em video</a> ou <a href="http://ethen8181.github.io/machine-learning/clustering_old/tf_idf/tf_idf.html">neste tutorial</a>, ou podemos usar alguns dos vários pacotes que tem já implementadas a função, como o Tidytext, Quanteda e TM, que veremos a seguir.
Vale atentar que cálculos feitos com diferentes pacotes podem não bater entre si. Se for este o caso, atente para se usam frequência absoluta ou relativa, e qual a base do Logaritmo utilizado (se de base 2 ou 10).</p>
<p>Em um <strong>exemplo</strong> real de uso de tf-idf, <a href="http://uc-r.github.io/tf-idf_analysis">este tutorial</a> usou tf-idf entre diferentes livros do Harry Potter:</p>
<p><img src="http://uc-r.github.io/public/images/analytics/descriptives/tf_idf5.png" width="60%" /></p>
<p>Fonte: <a href="https://afit-r.github.io/tf-idf_analysis">Text Mining: Term vs. Document Frequency</a> do AFIT Data Science Lab R Programming Guide</p>
<!-- ![](http://uc-r.github.io/public/images/analytics/descriptives/tf_idf5.png) -->
</div>
<div id="tf-idf-no-r-tidyverse" class="section level4" number="8.8.1.4">
<h4><span class="header-section-number">8.8.1.4</span> TF-IDF no R: Tidyverse</h4>
<p>Podemos realizar o TF-IDF no R com o tidytext com a função <a href="https://rdrr.io/cran/tidytext/man/bind_tf_idf.html">tidytext::bind_tf_idf</a>.</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="análise-textual-text-mining.html#cb34-1" aria-hidden="true" tabindex="-1"></a>doc1 <span class="ot">&lt;-</span> <span class="st">&quot;Eu quero abacaxi&quot;</span></span>
<span id="cb34-2"><a href="análise-textual-text-mining.html#cb34-2" aria-hidden="true" tabindex="-1"></a>doc2 <span class="ot">&lt;-</span> <span class="st">&quot;Eu? Eu quero banana&quot;</span></span>
<span id="cb34-3"><a href="análise-textual-text-mining.html#cb34-3" aria-hidden="true" tabindex="-1"></a><span class="co"># criando o data frame, onde cada linha é um documento.</span></span>
<span id="cb34-4"><a href="análise-textual-text-mining.html#cb34-4" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="st">&quot;texto&quot;</span> <span class="ot">=</span> <span class="fu">c</span>(doc1,doc2), </span>
<span id="cb34-5"><a href="análise-textual-text-mining.html#cb34-5" aria-hidden="true" tabindex="-1"></a>                 <span class="co"># ID de &quot;identificação&quot;</span></span>
<span id="cb34-6"><a href="análise-textual-text-mining.html#cb34-6" aria-hidden="true" tabindex="-1"></a>                 <span class="st">&quot;ID&quot;</span> <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), </span>
<span id="cb34-7"><a href="análise-textual-text-mining.html#cb34-7" aria-hidden="true" tabindex="-1"></a>                 <span class="at">stringsAsFactors =</span> F)</span>
<span id="cb34-8"><a href="análise-textual-text-mining.html#cb34-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-9"><a href="análise-textual-text-mining.html#cb34-9" aria-hidden="true" tabindex="-1"></a>df <span class="sc">%&gt;%</span> </span>
<span id="cb34-10"><a href="análise-textual-text-mining.html#cb34-10" aria-hidden="true" tabindex="-1"></a>  <span class="co"># quebrando o texto em tokens</span></span>
<span id="cb34-11"><a href="análise-textual-text-mining.html#cb34-11" aria-hidden="true" tabindex="-1"></a>     tidytext<span class="sc">::</span><span class="fu">unnest_tokens</span>(<span class="at">output =</span> <span class="st">&#39;word&#39;</span>, <span class="at">token =</span> <span class="st">&#39;words&#39;</span>, </span>
<span id="cb34-12"><a href="análise-textual-text-mining.html#cb34-12" aria-hidden="true" tabindex="-1"></a>                             <span class="co"># input =  nome da coluna do dataframe</span></span>
<span id="cb34-13"><a href="análise-textual-text-mining.html#cb34-13" aria-hidden="true" tabindex="-1"></a>                             <span class="at">input =</span> texto) <span class="sc">%&gt;%</span></span>
<span id="cb34-14"><a href="análise-textual-text-mining.html#cb34-14" aria-hidden="true" tabindex="-1"></a>              <span class="co"># contando os termos</span></span>
<span id="cb34-15"><a href="análise-textual-text-mining.html#cb34-15" aria-hidden="true" tabindex="-1"></a>              dplyr<span class="sc">::</span><span class="fu">count</span>(ID, word, <span class="at">sort =</span> <span class="cn">TRUE</span>) <span class="sc">%&gt;%</span></span>
<span id="cb34-16"><a href="análise-textual-text-mining.html#cb34-16" aria-hidden="true" tabindex="-1"></a>              <span class="co"># TF-IDF</span></span>
<span id="cb34-17"><a href="análise-textual-text-mining.html#cb34-17" aria-hidden="true" tabindex="-1"></a>            tidytext<span class="sc">::</span><span class="fu">bind_tf_idf</span>(word, ID, n)</span>
<span id="cb34-18"><a href="análise-textual-text-mining.html#cb34-18" aria-hidden="true" tabindex="-1"></a><span class="do">##   ID    word n        tf       idf    tf_idf</span></span>
<span id="cb34-19"><a href="análise-textual-text-mining.html#cb34-19" aria-hidden="true" tabindex="-1"></a><span class="do">## 1  2      eu 2 0.5000000 0.0000000 0.0000000</span></span>
<span id="cb34-20"><a href="análise-textual-text-mining.html#cb34-20" aria-hidden="true" tabindex="-1"></a><span class="do">## 2  1 abacaxi 1 0.3333333 0.6931472 0.2310491</span></span>
<span id="cb34-21"><a href="análise-textual-text-mining.html#cb34-21" aria-hidden="true" tabindex="-1"></a><span class="do">## 3  1      eu 1 0.3333333 0.0000000 0.0000000</span></span>
<span id="cb34-22"><a href="análise-textual-text-mining.html#cb34-22" aria-hidden="true" tabindex="-1"></a><span class="do">## 4  1   quero 1 0.3333333 0.0000000 0.0000000</span></span>
<span id="cb34-23"><a href="análise-textual-text-mining.html#cb34-23" aria-hidden="true" tabindex="-1"></a><span class="do">## 5  2  banana 1 0.2500000 0.6931472 0.1732868</span></span>
<span id="cb34-24"><a href="análise-textual-text-mining.html#cb34-24" aria-hidden="true" tabindex="-1"></a><span class="do">## 6  2   quero 1 0.2500000 0.0000000 0.0000000</span></span></code></pre></div>
<!-- retirada de stopwords -->
<!-- anti_join(stopwords(pt)) %>% -->
<p>Em <code>bind_tf_idf</code> sendo: <code>word</code> a coluna contendo termos, <code>ID</code> a coluna contendo os IDs dos docs, <code>n</code> a contagem de palavras produzido por <code>count()</code>.</p>
<div class="infobox note">
<p><strong>Dicas</strong></p>
<p>Exemplo/tutorial de <a href="https://cran.r-project.org/web/packages/tidytext/vignettes/tf_idf.html">TF-IDF com o tidyverse</a> de Julia Silge e David Robinson.</p>
</div>
</div>
<div id="tf-idf-no-r-quanteda" class="section level4" number="8.8.1.5">
<h4><span class="header-section-number">8.8.1.5</span> TF-IDF no R: Quanteda</h4>
<p>TF-IDF com o pacote Quanteda é usado com a função <a href="https://quanteda.io/reference/dfm_tfidf.html"><code>quanteda::dfm_tfidf</code></a></p>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="análise-textual-text-mining.html#cb35-1" aria-hidden="true" tabindex="-1"></a>doc1 <span class="ot">&lt;-</span> <span class="st">&quot;Eu quero Elias&quot;</span></span>
<span id="cb35-2"><a href="análise-textual-text-mining.html#cb35-2" aria-hidden="true" tabindex="-1"></a>doc2 <span class="ot">&lt;-</span> <span class="st">&quot;Eu? Eu quero Durkheim&quot;</span></span>
<span id="cb35-3"><a href="análise-textual-text-mining.html#cb35-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-4"><a href="análise-textual-text-mining.html#cb35-4" aria-hidden="true" tabindex="-1"></a><span class="co"># criando um vetor com documentos para transformar em um corpus no quanteda</span></span>
<span id="cb35-5"><a href="análise-textual-text-mining.html#cb35-5" aria-hidden="true" tabindex="-1"></a>meuvetor <span class="ot">&lt;-</span> <span class="fu">c</span>(doc1,doc2)</span>
<span id="cb35-6"><a href="análise-textual-text-mining.html#cb35-6" aria-hidden="true" tabindex="-1"></a><span class="co"># criando um objeto tipo corpus a partir do vetor</span></span>
<span id="cb35-7"><a href="análise-textual-text-mining.html#cb35-7" aria-hidden="true" tabindex="-1"></a>meucorpus <span class="ot">&lt;-</span> quanteda<span class="sc">::</span><span class="fu">corpus</span>(meuvetor)</span>
<span id="cb35-8"><a href="análise-textual-text-mining.html#cb35-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-9"><a href="análise-textual-text-mining.html#cb35-9" aria-hidden="true" tabindex="-1"></a><span class="co"># criando uma matriz de frequência</span></span>
<span id="cb35-10"><a href="análise-textual-text-mining.html#cb35-10" aria-hidden="true" tabindex="-1"></a>meudfm <span class="ot">&lt;-</span> meucorpus <span class="sc">%&gt;%</span> </span>
<span id="cb35-11"><a href="análise-textual-text-mining.html#cb35-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># quebrando em tokens</span></span>
<span id="cb35-12"><a href="análise-textual-text-mining.html#cb35-12" aria-hidden="true" tabindex="-1"></a>    quanteda<span class="sc">::</span><span class="fu">tokens</span>(</span>
<span id="cb35-13"><a href="análise-textual-text-mining.html#cb35-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># removendo a pontuação</span></span>
<span id="cb35-14"><a href="análise-textual-text-mining.html#cb35-14" aria-hidden="true" tabindex="-1"></a>     <span class="at">remove_punct =</span> <span class="cn">TRUE</span>) <span class="sc">%&gt;%</span></span>
<span id="cb35-15"><a href="análise-textual-text-mining.html#cb35-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># transformando em um document frame matrix</span></span>
<span id="cb35-16"><a href="análise-textual-text-mining.html#cb35-16" aria-hidden="true" tabindex="-1"></a>    quanteda<span class="sc">::</span><span class="fu">dfm</span>()</span>
<span id="cb35-17"><a href="análise-textual-text-mining.html#cb35-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-18"><a href="análise-textual-text-mining.html#cb35-18" aria-hidden="true" tabindex="-1"></a>meudfm</span>
<span id="cb35-19"><a href="análise-textual-text-mining.html#cb35-19" aria-hidden="true" tabindex="-1"></a><span class="do">## Document-feature matrix of: 2 documents, 4 features (25.00% sparse) and 0 docvars.</span></span>
<span id="cb35-20"><a href="análise-textual-text-mining.html#cb35-20" aria-hidden="true" tabindex="-1"></a><span class="do">##        features</span></span>
<span id="cb35-21"><a href="análise-textual-text-mining.html#cb35-21" aria-hidden="true" tabindex="-1"></a><span class="do">## docs    eu quero elias durkheim</span></span>
<span id="cb35-22"><a href="análise-textual-text-mining.html#cb35-22" aria-hidden="true" tabindex="-1"></a><span class="do">##   text1  1     1     1        0</span></span>
<span id="cb35-23"><a href="análise-textual-text-mining.html#cb35-23" aria-hidden="true" tabindex="-1"></a><span class="do">##   text2  2     1     0        1</span></span>
<span id="cb35-24"><a href="análise-textual-text-mining.html#cb35-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-25"><a href="análise-textual-text-mining.html#cb35-25" aria-hidden="true" tabindex="-1"></a><span class="co"># gerando o tf-idf (frequencia absoluta)</span></span>
<span id="cb35-26"><a href="análise-textual-text-mining.html#cb35-26" aria-hidden="true" tabindex="-1"></a>quanteda<span class="sc">::</span><span class="fu">dfm_tfidf</span>(meudfm)</span>
<span id="cb35-27"><a href="análise-textual-text-mining.html#cb35-27" aria-hidden="true" tabindex="-1"></a><span class="do">## Document-feature matrix of: 2 documents, 4 features (25.00% sparse) and 0 docvars.</span></span>
<span id="cb35-28"><a href="análise-textual-text-mining.html#cb35-28" aria-hidden="true" tabindex="-1"></a><span class="do">##        features</span></span>
<span id="cb35-29"><a href="análise-textual-text-mining.html#cb35-29" aria-hidden="true" tabindex="-1"></a><span class="do">## docs    eu quero   elias durkheim</span></span>
<span id="cb35-30"><a href="análise-textual-text-mining.html#cb35-30" aria-hidden="true" tabindex="-1"></a><span class="do">##   text1  0     0 0.30103  0      </span></span>
<span id="cb35-31"><a href="análise-textual-text-mining.html#cb35-31" aria-hidden="true" tabindex="-1"></a><span class="do">##   text2  0     0 0        0.30103</span></span>
<span id="cb35-32"><a href="análise-textual-text-mining.html#cb35-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-33"><a href="análise-textual-text-mining.html#cb35-33" aria-hidden="true" tabindex="-1"></a><span class="co"># TF-IDF usando frequência relativa, proporcional</span></span>
<span id="cb35-34"><a href="análise-textual-text-mining.html#cb35-34" aria-hidden="true" tabindex="-1"></a>quanteda<span class="sc">::</span><span class="fu">dfm_tfidf</span>(meudfm, <span class="at">scheme_tf =</span> <span class="st">&quot;prop&quot;</span>)</span>
<span id="cb35-35"><a href="análise-textual-text-mining.html#cb35-35" aria-hidden="true" tabindex="-1"></a><span class="do">## Document-feature matrix of: 2 documents, 4 features (25.00% sparse) and 0 docvars.</span></span>
<span id="cb35-36"><a href="análise-textual-text-mining.html#cb35-36" aria-hidden="true" tabindex="-1"></a><span class="do">##        features</span></span>
<span id="cb35-37"><a href="análise-textual-text-mining.html#cb35-37" aria-hidden="true" tabindex="-1"></a><span class="do">## docs    eu quero     elias  durkheim</span></span>
<span id="cb35-38"><a href="análise-textual-text-mining.html#cb35-38" aria-hidden="true" tabindex="-1"></a><span class="do">##   text1  0     0 0.1003433 0        </span></span>
<span id="cb35-39"><a href="análise-textual-text-mining.html#cb35-39" aria-hidden="true" tabindex="-1"></a><span class="do">##   text2  0     0 0         0.0752575</span></span></code></pre></div>
<blockquote>
<p>quanteda::dfm_tfidf(x, scheme_tf = “count”, scheme_df = “inverse”, base = 2)</p>
</blockquote>
<table>
<colgroup>
<col width="50%" />
<col width="50%" />
</colgroup>
<thead>
<tr class="header">
<th>Parâmetro</th>
<th>Descrição</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>x</td>
<td>objeto de entrada, devendo ser um document-feature matrix</td>
</tr>
<tr class="even">
<td>scheme_tf</td>
<td>esquema para dfm_weight(); sendo o padrão “count”. Para usar a frequência relativa, usa-se o “prop”</td>
</tr>
<tr class="odd">
<td>scheme_df</td>
<td>esquema para docfreq(); sendo o padrão “inverse”.</td>
</tr>
<tr class="even">
<td>base</td>
<td>A base para logaritmo no dfm_weight() e docfreq(), sendo 10 o valor padrão. Outro valor comum é 2</td>
</tr>
</tbody>
</table>
<!-- |force|logical; if TRUE, apply weighting scheme even if the dfm has been weighted before. This can result in invalid weights, such as as weighting by "prop" after applying "logcount", or after having grouped a dfm using dfm_group().| -->
</div>
<div id="tf-idf-no-r-tm" class="section level4" number="8.8.1.6">
<h4><span class="header-section-number">8.8.1.6</span> TF-IDF no R: TM</h4>
<p>Vamos usar agora o <a href="https://cran.r-project.org/web/packages/tm/">pacote TM</a>.</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="análise-textual-text-mining.html#cb36-1" aria-hidden="true" tabindex="-1"></a>doc1 <span class="ot">&lt;-</span> <span class="st">&quot;Eu quero Durkheim&quot;</span></span>
<span id="cb36-2"><a href="análise-textual-text-mining.html#cb36-2" aria-hidden="true" tabindex="-1"></a>doc2 <span class="ot">&lt;-</span> <span class="st">&quot;Elias! Eu quero Elias&quot;</span></span>
<span id="cb36-3"><a href="análise-textual-text-mining.html#cb36-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-4"><a href="análise-textual-text-mining.html#cb36-4" aria-hidden="true" tabindex="-1"></a>vetor_vetores <span class="ot">&lt;-</span> <span class="fu">c</span>(doc1,doc2)</span>
<span id="cb36-5"><a href="análise-textual-text-mining.html#cb36-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-6"><a href="análise-textual-text-mining.html#cb36-6" aria-hidden="true" tabindex="-1"></a><span class="co"># criando o objeto tipo corpus para o TM</span></span>
<span id="cb36-7"><a href="análise-textual-text-mining.html#cb36-7" aria-hidden="true" tabindex="-1"></a>meu_corpus <span class="ot">&lt;-</span> tm<span class="sc">::</span><span class="fu">Corpus</span>(tm<span class="sc">::</span><span class="fu">VectorSource</span>(vetor_vetores))</span>
<span id="cb36-8"><a href="análise-textual-text-mining.html#cb36-8" aria-hidden="true" tabindex="-1"></a><span class="co"># observando a estrutura do objeto criado, que é uma lista</span></span>
<span id="cb36-9"><a href="análise-textual-text-mining.html#cb36-9" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(meu_corpus)</span>
<span id="cb36-10"><a href="análise-textual-text-mining.html#cb36-10" aria-hidden="true" tabindex="-1"></a><span class="do">## Classes &#39;SimpleCorpus&#39;, &#39;Corpus&#39;  hidden list of 3</span></span>
<span id="cb36-11"><a href="análise-textual-text-mining.html#cb36-11" aria-hidden="true" tabindex="-1"></a><span class="do">##  $ content: chr [1:2] &quot;Eu quero Durkheim&quot; &quot;Elias! Eu quero Elias&quot;</span></span>
<span id="cb36-12"><a href="análise-textual-text-mining.html#cb36-12" aria-hidden="true" tabindex="-1"></a><span class="do">##  $ meta   :List of 1</span></span>
<span id="cb36-13"><a href="análise-textual-text-mining.html#cb36-13" aria-hidden="true" tabindex="-1"></a><span class="do">##   ..$ language: chr &quot;en&quot;</span></span>
<span id="cb36-14"><a href="análise-textual-text-mining.html#cb36-14" aria-hidden="true" tabindex="-1"></a><span class="do">##   ..- attr(*, &quot;class&quot;)= chr &quot;CorpusMeta&quot;</span></span>
<span id="cb36-15"><a href="análise-textual-text-mining.html#cb36-15" aria-hidden="true" tabindex="-1"></a><span class="do">##  $ dmeta  :&#39;data.frame&#39;: 2 obs. of  0 variables</span></span></code></pre></div>
<p>Vamos a um pré-processamento do pacote <code>tm</code> com a função <code>tm_map()</code> e <a href="https://rdrr.io/rforge/tm/man/removePunctuation.html">tm::removePunctuation</a>.</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="análise-textual-text-mining.html#cb37-1" aria-hidden="true" tabindex="-1"></a>meu_corpus2 <span class="ot">&lt;-</span> </span>
<span id="cb37-2"><a href="análise-textual-text-mining.html#cb37-2" aria-hidden="true" tabindex="-1"></a>  <span class="co"># passando tudo para minúsculo</span></span>
<span id="cb37-3"><a href="análise-textual-text-mining.html#cb37-3" aria-hidden="true" tabindex="-1"></a>  tm<span class="sc">::</span><span class="fu">tm_map</span>(meu_corpus, tolower) <span class="sc">%&gt;%</span></span>
<span id="cb37-4"><a href="análise-textual-text-mining.html#cb37-4" aria-hidden="true" tabindex="-1"></a>  <span class="co"># removendo pontuações</span></span>
<span id="cb37-5"><a href="análise-textual-text-mining.html#cb37-5" aria-hidden="true" tabindex="-1"></a>  tm<span class="sc">::</span><span class="fu">tm_map</span>(., tm<span class="sc">::</span>removePunctuation) </span>
<span id="cb37-6"><a href="análise-textual-text-mining.html#cb37-6" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning in tm_map.SimpleCorpus(meu_corpus, tolower): transformation drops</span></span>
<span id="cb37-7"><a href="análise-textual-text-mining.html#cb37-7" aria-hidden="true" tabindex="-1"></a><span class="do">## documents</span></span>
<span id="cb37-8"><a href="análise-textual-text-mining.html#cb37-8" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning in tm_map.SimpleCorpus(., tm::removePunctuation): transformation drops</span></span>
<span id="cb37-9"><a href="análise-textual-text-mining.html#cb37-9" aria-hidden="true" tabindex="-1"></a><span class="do">## documents</span></span>
<span id="cb37-10"><a href="análise-textual-text-mining.html#cb37-10" aria-hidden="true" tabindex="-1"></a>meu_corpus2</span>
<span id="cb37-11"><a href="análise-textual-text-mining.html#cb37-11" aria-hidden="true" tabindex="-1"></a><span class="do">## &lt;&lt;SimpleCorpus&gt;&gt;</span></span>
<span id="cb37-12"><a href="análise-textual-text-mining.html#cb37-12" aria-hidden="true" tabindex="-1"></a><span class="do">## Metadata:  corpus specific: 1, document level (indexed): 0</span></span>
<span id="cb37-13"><a href="análise-textual-text-mining.html#cb37-13" aria-hidden="true" tabindex="-1"></a><span class="do">## Content:  documents: 2</span></span></code></pre></div>
<p>A matriz de termo por documento (document-term-matrix) computa quantas vezes um termo aparece por documento, que no nosso caso foi uma frase simples. “Durkheim” aparece uma vez no documento 1, “quero” aparece uma vez em cada documento e “Elias” aparece duas vezes no docuemnto 2.</p>
<!-- control = list(weighting = tm::weightTfIdf(normalize = T) )) -->
<p>Opção 1, mais simples</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="análise-textual-text-mining.html#cb38-1" aria-hidden="true" tabindex="-1"></a>dtm.tfidf <span class="ot">&lt;-</span> tm<span class="sc">::</span><span class="fu">DocumentTermMatrix</span>(meu_corpus2,</span>
<span id="cb38-2"><a href="análise-textual-text-mining.html#cb38-2" aria-hidden="true" tabindex="-1"></a>           <span class="at">control =</span> <span class="fu">list</span>(<span class="at">weighting =</span> tm<span class="sc">::</span>weightTfIdf))</span>
<span id="cb38-3"><a href="análise-textual-text-mining.html#cb38-3" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning in TermDocumentMatrix.SimpleCorpus(x, control): custom functions are</span></span>
<span id="cb38-4"><a href="análise-textual-text-mining.html#cb38-4" aria-hidden="true" tabindex="-1"></a><span class="do">## ignored</span></span>
<span id="cb38-5"><a href="análise-textual-text-mining.html#cb38-5" aria-hidden="true" tabindex="-1"></a><span class="co"># vendo a estrutura</span></span>
<span id="cb38-6"><a href="análise-textual-text-mining.html#cb38-6" aria-hidden="true" tabindex="-1"></a>dtm.tfidf</span>
<span id="cb38-7"><a href="análise-textual-text-mining.html#cb38-7" aria-hidden="true" tabindex="-1"></a><span class="do">## &lt;&lt;DocumentTermMatrix (documents: 2, terms: 3)&gt;&gt;</span></span>
<span id="cb38-8"><a href="análise-textual-text-mining.html#cb38-8" aria-hidden="true" tabindex="-1"></a><span class="do">## Non-/sparse entries: 2/4</span></span>
<span id="cb38-9"><a href="análise-textual-text-mining.html#cb38-9" aria-hidden="true" tabindex="-1"></a><span class="do">## Sparsity           : 67%</span></span>
<span id="cb38-10"><a href="análise-textual-text-mining.html#cb38-10" aria-hidden="true" tabindex="-1"></a><span class="do">## Maximal term length: 8</span></span>
<span id="cb38-11"><a href="análise-textual-text-mining.html#cb38-11" aria-hidden="true" tabindex="-1"></a><span class="do">## Weighting          : term frequency - inverse document frequency (normalized) (tf-idf)</span></span>
<span id="cb38-12"><a href="análise-textual-text-mining.html#cb38-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Para visualizar, transformamos nosso objeto em matriz</span></span>
<span id="cb38-13"><a href="análise-textual-text-mining.html#cb38-13" aria-hidden="true" tabindex="-1"></a><span class="fu">as.matrix</span>(dtm.tfidf)</span>
<span id="cb38-14"><a href="análise-textual-text-mining.html#cb38-14" aria-hidden="true" tabindex="-1"></a><span class="do">##     Terms</span></span>
<span id="cb38-15"><a href="análise-textual-text-mining.html#cb38-15" aria-hidden="true" tabindex="-1"></a><span class="do">## Docs durkheim quero     elias</span></span>
<span id="cb38-16"><a href="análise-textual-text-mining.html#cb38-16" aria-hidden="true" tabindex="-1"></a><span class="do">##    1      0.5     0 0.0000000</span></span>
<span id="cb38-17"><a href="análise-textual-text-mining.html#cb38-17" aria-hidden="true" tabindex="-1"></a><span class="do">##    2      0.0     0 0.6666667</span></span></code></pre></div>
<!-- # criando uma lista com parâmetros para nossa matriz -->
<!-- control_list <- list(removePunctuation = TRUE, stopwords = TRUE, tolower = TRUE) -->
<p>Opção 2: com normalização e retirada de stopwords</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="análise-textual-text-mining.html#cb39-1" aria-hidden="true" tabindex="-1"></a>doc1 <span class="ot">&lt;-</span> <span class="st">&quot;Eu quero Durkheim&quot;</span></span>
<span id="cb39-2"><a href="análise-textual-text-mining.html#cb39-2" aria-hidden="true" tabindex="-1"></a>doc2 <span class="ot">&lt;-</span> <span class="st">&quot;Elias! Eu quero Elias&quot;</span></span>
<span id="cb39-3"><a href="análise-textual-text-mining.html#cb39-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-4"><a href="análise-textual-text-mining.html#cb39-4" aria-hidden="true" tabindex="-1"></a>vetor.docs <span class="ot">&lt;-</span> <span class="fu">c</span>(doc1,doc2)</span>
<span id="cb39-5"><a href="análise-textual-text-mining.html#cb39-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-6"><a href="análise-textual-text-mining.html#cb39-6" aria-hidden="true" tabindex="-1"></a><span class="co"># criando o objeto tipo corpus para o TM</span></span>
<span id="cb39-7"><a href="análise-textual-text-mining.html#cb39-7" aria-hidden="true" tabindex="-1"></a><span class="co"># como nossa fonte são vetores, usamos VectorSource</span></span>
<span id="cb39-8"><a href="análise-textual-text-mining.html#cb39-8" aria-hidden="true" tabindex="-1"></a>meu_corpus <span class="ot">&lt;-</span> tm<span class="sc">::</span><span class="fu">Corpus</span>(tm<span class="sc">::</span><span class="fu">VectorSource</span>(vetor.docs))</span>
<span id="cb39-9"><a href="análise-textual-text-mining.html#cb39-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-10"><a href="análise-textual-text-mining.html#cb39-10" aria-hidden="true" tabindex="-1"></a>tm<span class="sc">::</span><span class="fu">DocumentTermMatrix</span>(meu_corpus,</span>
<span id="cb39-11"><a href="análise-textual-text-mining.html#cb39-11" aria-hidden="true" tabindex="-1"></a><span class="co"># para concatenar várias transformacoes, vamos usar function</span></span>
<span id="cb39-12"><a href="análise-textual-text-mining.html#cb39-12" aria-hidden="true" tabindex="-1"></a>           <span class="at">control =</span> <span class="fu">list</span>(<span class="at">weighting =</span> <span class="cf">function</span>(x) </span>
<span id="cb39-13"><a href="análise-textual-text-mining.html#cb39-13" aria-hidden="true" tabindex="-1"></a>             tm<span class="sc">::</span><span class="fu">weightTfIdf</span>(x, <span class="at">normalize =</span> T),</span>
<span id="cb39-14"><a href="análise-textual-text-mining.html#cb39-14" aria-hidden="true" tabindex="-1"></a>             <span class="at">removePunctuation =</span> <span class="cn">TRUE</span>,</span>
<span id="cb39-15"><a href="análise-textual-text-mining.html#cb39-15" aria-hidden="true" tabindex="-1"></a>             <span class="at">stopwords =</span> <span class="cn">TRUE</span>)) <span class="sc">%&gt;%</span> as.matrix</span>
<span id="cb39-16"><a href="análise-textual-text-mining.html#cb39-16" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning in TermDocumentMatrix.SimpleCorpus(x, control): custom functions are</span></span>
<span id="cb39-17"><a href="análise-textual-text-mining.html#cb39-17" aria-hidden="true" tabindex="-1"></a><span class="do">## ignored</span></span>
<span id="cb39-18"><a href="análise-textual-text-mining.html#cb39-18" aria-hidden="true" tabindex="-1"></a><span class="do">##     Terms</span></span>
<span id="cb39-19"><a href="análise-textual-text-mining.html#cb39-19" aria-hidden="true" tabindex="-1"></a><span class="do">## Docs durkheim quero     elias</span></span>
<span id="cb39-20"><a href="análise-textual-text-mining.html#cb39-20" aria-hidden="true" tabindex="-1"></a><span class="do">##    1      0.5     0 0.0000000</span></span>
<span id="cb39-21"><a href="análise-textual-text-mining.html#cb39-21" aria-hidden="true" tabindex="-1"></a><span class="do">##    2      0.0     0 0.6666667</span></span></code></pre></div>
<div class="infobox note">
<p><strong>Dicas TF-IDF</strong></p>
<!-- O artigo que pensou o IDF é -->
<ul>
<li>JONES, Karen Spärck. <a href="https://www.cl.cam.ac.uk/archive/ksj21/ksjdigipapers/jdoc72.pdf">A statistical interpretation of term specificity and its application in retrieval</a>. Journal of Documentation. (1972)</li>
<li>Cap. <a href="https://web.stanford.edu/~jurafsky/slp3/6.pdf">6.5 TF-IDF: Weighing terms in the vector</a> in JURAFSKI,D; MARTIN,J. Speech and Language Processing.</li>
<li>Gerard Salton and Christopher Buckley (1988). <a href="https://www.marilia.unesp.br/Home/Instituicao/Docentes/EdbertoFerneda/MRI%2004%20-%20Salton,%20G;%20Buckley,%20C%20-%201988.pdf">Term-weighting approaches in automatic text retrieval</a>. <em>Information Processing and Management</em>, <em>24</em>/5, 513-523.</li>
</ul>
<p>Tutorial</p>
<ul>
<li>vignette (exemplo) de <a href="https://cran.r-project.org/web/packages/tidytext/vignettes/tf_idf.html">TF-IDF com o tidytext</a></li>
<li>Análise tf-idf com livros do <a href="https://afit-r.github.io/tf-idf_analysis">Harry Potter</a> usando o Tidyverse.</li>
</ul>
<p>Vídeos:</p>
<ul>
<li>Video em português <a href="https://www.youtube.com/watch?v=udrXmqdbGvQ">Aula 5.4: Problema com Matrizes de Frequência e TF-IDF | Processamento de Língua Natural</a>.
do curso de “Processamento de Língua Natural” (LIG948B), ministrado na Faculdade de Letras da Universidade Federal de Minas Gerais (FALE-UFMG).</li>
<li>Video tutorial de tf-idf no R (em inglês) <a href="https://www.youtube.com/watch?v=az7yf0IfWPM&amp;list=PL8eNk_zTBST8olxIRFoo0YeXxEOkYdoxi&amp;index=5">“TF-IDF | Introduction to Text Analytics with R Part 5”</a> do Data Science Dojo, fazendo o cálculo sem pacotes.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="visualização-de-dados.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="text-mining-semantic-parsing.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
