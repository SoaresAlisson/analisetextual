[["objetivos-deste-manual.html", "Introdução à Análise Textual aplicada à Sociologia Objetivos deste manual Plano do livro", " Introdução à Análise Textual aplicada à Sociologia Alisson Soares Primeira versão em 22 de abril de 2021. Última atualização em 10 abril de 2022 Objetivos deste manual Sou Alisson Soares, sociólogo, e comecei no campo das humanidades digitais e ciências sociais computacionais. Achei por bem montar este manual como uma forma de compartilhar o que venho aprendendo. Algumas ferramentas, softwares serão de modo gráfico, mas muitas vezes iremos recorrer à programação. A linguagem aqui será o R, uma linguagem de programação gratuita, livre e de código aberto, bastante utilizada no mundo acadêmico. O objetivo deste manual é: Ser um livro em progresso constante. (Confira a data de atualização para saber se há material novo) Ser introdutório, mas também sempre indicar bons materiais para maior aprofundamento dos temas tratados. Sempre que possível, oferecer material em português, apesar de nem sempre isto ser possível. Oferecer uma introdução às ferramentas computacionais utilizadas em pesquisa das ciências sociais. Usar preferencialmente ferramentas gratuitas e de código aberto. Sempre que possível, apresentar exemplos de pesquisa e ciência social utilizando estas ferramentas. Ao final de cada capítulo sessão apresentamos dicas de links externos. Há também um capítulo dedicado a links de temas correlatos, que podem ajudar a vida dos humanistas digitais. Caso encontre algum erro ou imprecisão, caso tenha algum elogio ou crítica, meu contato é alissonmsoares@gmail.com. Plano do livro Por se tratar de um livro em elaboração há ainda muitos pontos ainda a serem trabalhaos. Há vários temas a serem incorporados futuramente e já estão em elaboração, como por exemplo: dendogramas Correlação, tipos de distâncias/semelhança extração de palavras chave (keyword extraction) Introdução à análise de redes Inteligência Artificial: clusterização; aprendizado supervisionado e não supervisionado (como topic modeling) Análise de sentimentos. "],["intro.html", "Introdução O termo “humanidade digitais” Fluxo de trabalho", " Introdução “the best digital theory-building of the past decade stems from social and computational origins. As such, it is increasingly apparent that digital sociologists need to develop a computational as well as a sociological imagination.” (Neil Selwyn) Social researchers of the future will need to write code, wrangle data, and think computationally as well as sociologically. (EVANS &amp; FOSTER) O termo “humanidade digitais” Segundo um estudo do LinkedIn em 15 países, prevendo 150 milhões de vagas nos próximos 5 anos, das áreas de trabalhos digitais em alta e 2021, duas se relacionam a Humanidades Digitais: Big data Analytics (segundo lugar) e “Text, image and voice processing” (6º lugar). Profissionalmente, pode ser interessante entrar nesta área. Existem diversos termos correlatos a “Humanidades digitais” (“Digital humanities”), como “E-humanities,”Cultural Analytics”, “ciências sociais computacionais”, “sociologia digital”, “história digital”, “etnografia digital”, “etnografia quantitativa”, “Análise cultural quantitativa” (quantitative cultural analysis) “cultural analytics”, “humanities data science”, “humanities data analysis” “humanities computing”, “computational social science”, “distant reading”, “text as data”, “text analytics” etc. Embora estes termos não sejam todos sinônimos entre si, há diversos pontos de contato. Em quase todos eles há a junção de algo de humanidades e algo de digital, demonstrando seu caráter transdisciplinar. A área possui contribuições de diversas áreas, como das ciências da informação, linguística, ciências da computação, história, sociologia, comunicação, etc. O termo é controverso mesmo entre os participantes, uma vez que é amplo demais. Uma definição ampla define o termo como intersecção entre humanidades e computação. Porém, uma busca no Google por um texto já configura uso de ferramenta digital. Outra definição mais restrita envolveria aprender a pensar como o computador e a partir disto extrair diversas novas possibilidades. Uma introdução aos diferentes significados do termo pode ser vista no artigo “Humanidades digitais” do grupo de pesquisas da USP. Em termos mais práticos, Humanidades digitais inclui a análise de: sons/música, imagens. textos. Nosso objetivo aqui Há todo um repertório de ferramentas comuns utilizados tanto por cientistas de dados como por humanistas digitais, com diferentes fins. Nosso foco será aprender diversas destas ferramentas de uso comum, mas focando em seu uso na ciência social computacional. Fluxo de trabalho O fluxo de trabalho “workflow” básico consiste em: &lt;!– A[1.Adquirir dados] – &gt;B[2.Pré tratar dados]; –&gt; "],["história-da-análise-textual.html", "1 História da Análise Textual 1.1 Linha do tempo da história da Análise Textual", " 1 História da Análise Textual “May we hope that when things come to such a crisis, human labor of the literary sort may be in part superseded by machinery? Machinery has done wonders, and when we think of what literature is becoming, it is certainly to be wished that we could read it by machinery, and by machinery digest it” (Andrew Stauffer In London’s Daily News. 15 de Setembro de 1869 apud Catherine DeRose.) A análise textual abarca campos do conhecimento bem variados, como psicologia, ciências da computação, ciências da informação, linguística, ciência política, sociologia, etc. Apresentamos aqui uma linha do tempo com alguns dos principais eventos relacionados à análise textual, bem como ao seu uso com computadores. De modo resumido, podemos pensar nos primeiros desenvolvimentos ao final do século XIX, a introdução do computador e mais recentemente, a introdução da inteligência artificial como pontos marcantes nesta cronologia. Fizemos aqui uma breve cronologia, que não pretende ser extensiva, com todos eventos importantes, mas apenas demarcar alguns pontos interessantes, para ajudar a dar alguma ideia àqueles que iniciam no campo das humanidades digitais e na sociologia digital. 1.1 Linha do tempo da história da Análise Textual Séc. XVII - Igreja Católica analisa a proporção de textos impressos de conteúdo não religioso 1887 Medenhall. Analisa o comprimento de palavras: MENDENHALL, T. C. . The characteristic curves of composition. Science.Vol ns-9, Issue 214S. 11 March 1887. baixar pdf 1888 Benjamin Bourdon (1860-1943, psicólogo e professor da Université de Rennes): Ao pesquisar sobre a expressão de emoções através de palavras, analisou o livro “Exodus” da Bíblia e calculou frequências, classificou e eliminou as stopwords. “In 1888, in a research on the expression of emotions through words, Benjamin Bourdon analysed the Exodus of the Bible and calculated the frequencies by rearranging and classifying them, eliminating the stop words” fonte, link para o livro online. 1888 Friedrich Kaeding (1855 - 1929), cria índices de frequência para estruturação de sistemas estenográficos (sistema de escrita por abreviações para que a escrita seja tão rápida como a fala). Wincenty Lutoslawski, criador do termo “estilometria”, lança sua análise de palavras raras na obra de Platão. LUTOSLAWSKI, W. Origin and Growth of Plato’s Logic. with an account of Plato’s style and of the chronology of his writings. New York: Longsmans, Green. 1897. p. 613. link. 1934 Harold Laswell (1902-1978, cientista político) produz a primeira contagem de palavras chave. O linguista norteamericano George Kingsley Zipf (1902–1950) publica “The psycho-biology of language” onde sugere o “principle of relative frequency”, que ficou conhecido posteriormente como “Zipf’s Law”. 1934 Vygostky produz a primeira análise quantitativa de narrativa 1949 Robert Busa (padre jesuíta) junto à IBM com o projeto Index Thomisticus, que levou 34 anos, envolveu cerca de 70 pessoas, sobre as obras de São Tomás de Aquino, que envolveu indexação e lematização de palavras e frequência de termos. Técnicas ali desenvolvidas foram usadas posteriormente nos manuscritos do Mar Morto, para tentar preencher partes faltantes do texto. “The IBM… considered this first enterprise of using a computer for linguistic and lexicographic goals as a pilot-project” fonte, indexando mais de 10 milhões de palavras. Busa, R. (1980). “The Annals of Humanities Computing: The Index Thomisticus”. Computers and the Humanities. 14 (2): 83–90. doi:10.1007/BF02403798. ISSN 0010-4817. ROCKWELL, Geoffrey; PASSAROTTI, Marco (2019-05-27). “The Index Thomisticus as a Big Data Project”. Umanistica Digitale (5). doi:10.6092/issn.2532-8816/8575. “The Index Thomisticus, itself, is divided into two parts - the indexes and the concordances. The index alphabetically notes each word along with a reference to its distribution and frequency. Besides a general index for the entire study, there is also one for each work. The concordances, on the other hand , list alphabetically all the words and cite every passage in which a word app ears.”. “Jesuit Father Uses Computer to Analyze Works of St.Thomas Aquinas”. Modern Data, 1973. pp.41-2 1950 Gottschalk usa Content Analysis para rastrear temas freudianos. GOTTSCHALK, Louis A. The Measurement of Psychological States Through the Content Analysis of Verbal Behavior. University of California Press. 1969. 317p. Gottschalk-Gleser Content Analysis Method of Measuring the Magnitude of Psychological Dimensions 1950 Alan Turing aplica Inteligência Artificial a textos. 1952 Bereleson publica o primeiro manual de análise de conteúdo. BERELSON, B. (1952). Content analysis in communication research. New York: Hafner. 1954 Primeira tradução automática de texto (Georgetown–IBM experiment) do russo para o inglês. HUTCHINS, John. The first public demonstration of machine translation: the Georgetown-IBM system, 7th January 1954. 2006. Press Release da IBM 1963 Mosteller e Wallace analisam a autoria dos Federalist Papers. MOSTELLER, F., WALLACE, D. L.. 1963. Inference in an authorship problem. Journal of the American Statistical Association 58:275–309. 1965 Tomashevsky formaliza análise quantitativa de narrativa. TOMASHEVSKY, B. (1965). Thematics. In L T. Lemon &amp; M. I. Reis (Eds. &amp; Trans.), Russian formalist criticism: Four essays (pp. 61-95). Lincoln: University of Nebraska Press. (Original de 1925) 1966 Stones e Bales usam computador para medir propriedades psicométricas de textos na RAND. 1980 Declínio do formalismo chomskyano; nascimento do Processamento de Linguagem Natural (PLN). 1980 Aplicação de Aprendizado de máquinas (Machine Learning) ao Processamento de Linguagem Natural 1981 Walter Weintraub e a contagem de parts-of-speech. WEINTRAUB, Walter. Verbal Behavior: adaptation and psychopathology. Springer:NY. 1981. SOBEL, Dava. Language patterns reveal problems in personality. NYT. Oct. 27,1981. 1985 Schrodt introduz codificação automática de eventos (Automated Event Coding). SCHRODT, Philip A. Automated Coding Of International Event Data Using Sparse Parsing Techniques. 2000. 1986 James W. Pennebaker desenvolve LIWC (Linguistic Inquiry and Word Count). 1989 Roberto Franzosi (perfil no Research Gate) (sociólogo) traz a análise quantitativa de narrativa (quantitative Narrative Analysis) para as Ciências Sociais. 1998 Primeiro desenvolvimento de Topic Models. 1998 John W Mohr conduz a primeira análise quantitativa de visões de mundo. 1999 Peter Bearman (sociólogo) et al. aplicam métodos de rede a narrativas “Narrative network”. 2001 David M. Blei et al desenvolvem a LDA (Latent Dirichlet Allocation). David M. Blei, Andrew Y. Ng, Michael I. Jordan. Latent Dirichlet Allocation. Journal of Machine Learning Research 3 (2003) 993-1022. Github da Blei Lab. 2003 MALLET (MAchine Learning for LanguagE Toolkit), um dos primeiros sistemas de topic models, é criado. “MALLET is a Java-based package for statistical natural language processing, document classification, clustering, topic modeling, information extraction, and other machine learning applications to text. MALLET includes sophisticated tools for document classification: efficient routines for converting text to”features”, a wide variety of algorithms (including Naïve Bayes, Maximum Entropy, and Decision Trees), and code for evaluating classifier performance using several commonly used metrics.” 2005 Quin et al analisam discursos políticos usando topic models. Kevin M Quinn, Burt L Monroe, Michael Colaresi,Michael H Crespin, and Dragomir R Radev. 2010. How to analyze political attention with minimal assumptions and costs. American Journal of Political Science54(1):209–228 2010 Gary King e Daniel Hopkins trazem Topic Models ao mainstream. Hopkins, Daniel, and Gary King. 2010. “A Method of Auto-mated Nonparametric Content Analysis for Social Science.”American Journal of Political Science54(1): 229–47. 2014 Margaret Roberts, et al. desenvolvem “Structural Topic Models”. 2014 - Primeiro Workshop sobre Argument mining ou “argumentation mining” Proceedings das edições anteriores aqui e aqui (na Sessão “Past Workshops” é possível acessar papers de edições anteriores - desde 2014 - do evento). Fonte: Versão ampliada, baseado parcialmente em: “SICSS 2018 - History of Quantitative Text Analysis” slides, video e BROWN, Taylor W. Workshop on automated text analysis no Summer Institute in Computational Social Science na Universidade de Oxford em 2019. Em inglês, sem legendas. Parte 1. Pretende-se posteriormente expandir esta seção, explicando em mais detalhes alguns dos exemplos acima "],["exemplos-de-pesquisas-em-humanidades-digitais.html", "2 Exemplos de Pesquisas em Humanidades Digitais 2.1 Bibliometria / cientometria / cienciometria 2.2 Exemplo: Google Trends como Proxy para epidemias 2.3 Exemplo: Como as fake news sobre a pandemia de Covid-19 se assemelham/divergem entre os países? 2.4 Exemplo: Mudança de significado de palavras 2.5 Exemplo: Análise de complexidade musical 2.6 Exemplo: Polarização 2.7 Exemplo de integração quali-quanti: Complementando dados qualitativos 2.8 Exemplo de integração quali-quanti: Depurando dados quantitativos 2.9 Exemplo: Processo Civilizador 2.10 Ex.: Determinantes sociais do florescimento da cultura Incel", " 2 Exemplos de Pesquisas em Humanidades Digitais Para entender os potenciais das humanidades digitais para pesquisa, nada melhor que observarmos exemplos de pesquisas. Aqui seguem alguns de exemplos, selecionados pelo potencial de integração entre humanidades e métodos digitais, mais que quanto ao possível mérito/demérito científico. 2.1 Bibliometria / cientometria / cienciometria O estudo das citações, das rede de citações em artigos científicos foi talvez um dos pioneiros no uso de algumas das técnicas aqui descritas, existindo já há décadas. Chamada de “bibliometria”, “cientometria” ou “cienciometria”, ela conta citações de determinados autores em artigos científicos e tenta avaliar o quão influentes estes são. 2.1.1 Exemplo: Filósofos da ciência na Sociologia Por exemplo, HEDSTRÖM et al (1998), buscando saber a influência dos principais filósofos da ciência (Hempel, Kuhn, Popper e Wittgenstein) na sociologia em diferentes países e regiões (países nórdicos, EUA, Grã Bretanha, Alemanha e França), analisou o número de artigos nas principais revistas sociológicas que os citaram. (Fonte: HEDSTRÖM et al. 1998. p. 343) Pelos dados ali apresentados, Popper seria o filósofo mais influente na Europa, principalmente nos países de língua alemã, ao passo que Kuhn seria mais dominante nos EUA. HEDSTRÖM, Peter; SWEDBERG; and UDÉHN, Lars. Popper’s Situational Analysis and Contemporary Sociology. Philosophy of the Social Sciences 1998; 28; 339-64] 2.1.2 Exemplo: A teoria dos sistemas sociais de Niklas Luhmann Stephen Roth analisou a chamada diferenciação funcional dos subsistemas da sociedade mundial, isto é, como os subssitemas como política, economia, religião, ciência, direito, meios de comunicação de massa, etc. se autonomizam em relação aos outros, entre os anos de 1800 e 2000, e para tal utilizou dados do Google Ngram viewer, que por sua vez se baseia no Google Books (mais detalhes sobre estas ferramentes na seção sobre frequência de palavras). Ele encontrou, por exemplo, declínio da presença relativa (isto é, proporcional a cada ano) da palavra “Deus” (god) nos livros em inglês ao longo do tempo. Fonte: Roth (2014, p.46). E se examinarmos os termos relacionados aos Meios de Comunicação de Massa, podemos ver a importância relativa do termo “imprensa” (press) aumentando ao longo do tempo. Fonte: Roth(2014, p.47). Roth, Steffen. 2014. “Fashionable Functions: A Google Ngram View of Trends in Functional Differentiation (1800-2000)” International Journal of Technology and Human Interaction, 34–58. Uma versão posterior, um pouco mais elaborada em: Steffen Roth, Carlton Clark, Nikolay Trofimov, Artur Mkrtichyan, Markus Heidingsfelder, Laura Appignanesi, Miguel Pérez-Valls, Jan Berkel, Jari Kaivo-oja. Futures of a distributed memory. A global brain wave measurement (1800–2000). Technological Forecasting &amp; Social Change 118 (2017) 307–323 Dicas Há o pacote no Python Get Ngrams e o R possui o pacote ngramr que pega os dados no site Google Ngram, os coloca no formato de dataframe do R, bem como plota o gráfico no R usando o pacote ggplot Veja a sessão dedicada ao pacote ngramr neste manual 2.1.3 Exemplo: Tendência de termos chave da Sociologia Além de contar citação nas referências, pode-se contar as palavras mais frequentes no corpo do texto e compará-las. Bernau (2018), por exemplo, coletou dados do JSTOR’s Data for Research e plotou um gráfico longitudinal (ao longo do tempo) de frequência de palavas com termos chaves da sociologia, como “classe”, “raça” e “gênero” da revista American Sociological Review. Ele também disponibilizou o script em R que desenvolveu para esta análise. BERNAU, John A. Text Analysis with JSTOR Archives. November 12, 2018. https://doi.org/10.1177/2378023118809264 2.1.4 Exemplo: Tendências das correntes na filosofia Inspirado neste trabalho, Brian Weatherson usou também o pacote jstor_dfr, baixou dados da filosofia, e os clusterizou através de topic modeling. Podemos ver as tendências gerais de vários ramos da filosofia ao longo do tempo: Tendencias na história da filosofia O resultado e mais informações estão em seu livro online: WEATHERSON, Brian . A History of Philosophy Journals. Volume 1: Evidence from Topic Modeling, 1876-2013) 2.2 Exemplo: Google Trends como Proxy para epidemias A busca no Google por certos sintomas de doenças, ou melhor, a variação na busca por certas doenças e sintomas correlatos pode indicar que variação real da doença. Isso acontece, por exemplo, com sintomas de gripe. Um pico no aumento das buscas pelos sintomas indica um prenúncio do aumento das infecções, a ser checado/validado posteriormente. No artigo Google Trends: A Web-Based Tool for Real-Time Surveillance of Disease Outbreaks., os autores explicam que a ferramenta lançada em 2018: &gt; “Google Flu Trends can detect regional outbreaks of influenza 7–10 days before conventional Centers for Disease Control and Prevention surveillance systems” Para funcionar, há certas pré-condições sociais. Vale para gripe, e a ferramenta também prevê aumentos da Covid-19. Na reportagem da Piaui “No carnaval, buscas por “sintomas covid” voltaram a subir; sete dias depois, número de novos casos bateu recorde” de 09 de março de 2021 compara as buscas no google com casos reais. Gráfico: buscas por “sintomas Covid no Google” versus casos reais Ver também “Sintomas Covid” en Google trends:.Un indicador alternativo para el seguimiento de la incidencia de casos. com exemplos da Espanha, México, Chile e Argentina. No entanto, a ferramenta que parecia promissora falhou em prever o pico de gripe de 2013, sobrestimando por 140%. A empresa achou melhor terminar o projeto, conforme um artigo da Wired de 2015. Mais detalhes podem lidos no artigo The Parable of Google Flu: Traps in Big Data Analysis. O Instituto de Ciências Cognitvas de Osnabrück leva a ideia adiante, com modelo mais complexo, utilizando dados de redes sociais como Twitter e através do Watson da IBM.(site do projeto). O R possui o pacote gtrendsR que pega dados do Google Trends para trabalhar 2.3 Exemplo: Como as fake news sobre a pandemia de Covid-19 se assemelham/divergem entre os países? O relatório de 23/11/2020 sobre isolamento científico, intitulado “scientific [self] isolation” do Laut, Centro de Análise da Liberdade e do Autoritarismo, cruzou as checagens de fake news de 129 países diferentes (há uma plataforma que traduz as reportagens de fact checking de todo mundo para o inglês) e investigou a distribuição de notícias falsas sobre os tratamentos da Covid19. Os pesquisadores procederam então uma distribuição num plano das discussões nos países conforme sua semelhança. Quanto mais próximos, mais semelhantes os debates ao redor do tema. Encontraram então que o Brasil é o país mais isolado em sua discussão envolvendo certos medicamentos, no canto superior direito. Gráfico feito com o Iramuteq 2.4 Exemplo: Mudança de significado de palavras Kulkarni et al (2015) mostraram como através de ferramentas computacionais é possível identificar a mudança de significado de termos, seja ao longo de um século (com dados do Google NGram), seja em dinâmicas mais rápidas, como no twitter. Um dos termos analisado foi o “gay”: Linguistic Change da palavra “gay” Várias outras palavras foram analisadas, como “tape” que significava “fita adesiva”, mas passou a significar também “fita cassete” nos anos 1970; ou “apple” e “windows” que ganharam novo significado com a indústria da computação. KULKARNI, V., Al-Rfou, R; PEROZZI, B e SKIENA, S. Statistically Significant Detection of Linguistic Change. WWW 2015, May 18–22, 2015. http://dx.doi.org/10.1145/2736277.2741627 . 2.5 Exemplo: Análise de complexidade musical A reportagem da Folha de São Paulo Música brasileira foi simplificada ao longo das décadas, diz pesquisa cita o trabalho do cientista de dados Leonardo Sales (blog do autor), que analisou os acordes e vocabulário das letras, com base em 44 mil cifras e 102 mil letras raspadas de sites como cifras.com.br e letras.com.br em uma série de postagens: parte 1, parte 2, parte 3 sobre as letras, parte 4. Os códigos para raspagem de dados destes sites estão disponíveis em Python. grafico Como quase toda notação, há vantagens e desvantagens. Uma desvantagem, que levantou críticas, é que a análise se baseia em cifra, muito utilizada em músicas mais populares, mas inadequada para estilos mais complexos, como jazz. 2.6 Exemplo: Polarização Uma boa parte de pesquisas em política com métodos digitais se dedicou a analisar o fenômeno da polarização política. Christopher A. Bail, Lisa P. Argyle, Taylor W. Brown, John P. Bumpus, Haohan Chen, M. B. Fallin Hunzaker, Jaemin Lee, Marcus Mann, Friedolin Merhout, and Alexander Volfovsky. 2018. Exposure to opposing views on social media can increase political polarization. Proceedings of the National Academy of Sciences 115, 37 (Sept. 2018), 9216–9221. https://doi.org/10.1073/pnas.1804840115 Publisher: National Academy of Sciences Section: Social Sciences. Parte do trabalho de Franzosi descrevemos na seção sobre dados estruturados. Roberto P. Franzosi. Sociology, narrative, and the quality versus quantity debate (Goethe versus Newton): Can computer-assisted story grammars help us understand the rise of Italian fascism (1919–1922)? . Theor Soc (2010) 39:593–629 DOI 10.1007/s11186-010-9131-3 2.7 Exemplo de integração quali-quanti: Complementando dados qualitativos Uma dica de integração quali-quanti (qualitativo e quantitativo) usando análise textual vem do PEW Research. Aqui explicam como a partir de uma análise de grupos focais feita em 2019 com grupos dos EUA e da Grã Bretanha sobre atitudes frente a globalização/nacionalismo, complementaram com pesquisa quantitativa de análise textual, analisando as diferenças entre os grupos de cada país. Usaram técnicas como frequência de palavras, correlação de palavras e Topic modelling. Através destas análises, encontraram tópicos que se mostraram relevantes a serem incorporados em surveys futuros. DEVLIN, Kat.“How quantitative methods can supplement a qualitative approach when working with focus groups”. medium. Dec 18, 2020. 2.8 Exemplo de integração quali-quanti: Depurando dados quantitativos Nem sempre uma tabela de dados estruturados tem tudo estruturado, do modo que a sua pergunta de pesquisa necessite. Dentro de um campo específico de uma tabela pode-se precisar de desmembrar ainda mais os dados. Eis aqui um exemplo. Os pesquisadores do Dadoscope queriam investigar se houve aumento na abertura de igrejas evangélicas durante os anos Lula e Dilma. Os pesquisadores baixaram dados da Receita Federal referente ao Cadastro Nacional de Pessoa Jurídica e filtraram por “94.91–0–00 — Atividades de organizações religiosas ou filosóficas” no campo “Classificação Nacional de Atividades Econômicas”. O problema é que isto agrega não só igrejas evangélicas, como também católicas e de outras religiões e até agremiações filosóficas e institutos de psicanálise. Aqui entra a integração: Para tentarmos realizar a classificação das 150 mil igrejas evangélicas de maneira semi-supervisionada nós usamos Snorkel, uma biblioteca escrita em Python… foi preciso treinar um algoritmo de classificação usando uma amostra dos dados. De forma sucinta, os dados são separados em amostras que são usadas para treino, teste e validação da classificação. Para classificar os mais de 150 mil nomes únicos presentes na amostra de treino, criamos funções que classificam de forma grosseira as igrejas (e.g., se a palavra “assembleia” estiver presente, classificar a igreja como “evangélica”). Depois de escrever dezenas dessas funções, comparamos sua acurácia com uma amostra de teste de 5% dos nomes únicos, manualmente classificados por dois pesquisadores. Feito isso, usamos uma rede neural que combina em camadas estas funções e voilá: 91.8% de acurácia. Sabemos que este resultado não é perfeito, mas ele torna o trabalho de classificação viável. O artigo completo “Exclusivo: Igrejas evangélicas pentecostais tiveram boom de crescimento nos governos Lula e Dilma” pode ser lido aqui: artigo na Forum e o mesmo artigo na Medium. Caderno de notas no dadoscope para entender melhor como o processo foi realizado. Sobre a ferramenta utilizada, a Snorkel, ver a página do Github, introdução (em inglês) ao Snorkel. Por fim, outra dica para pensar a integração de dados quantitativos e qualitativos é a palestra de Dr. Christof Schöch: The Convergence of Quantitative and Qualitative Approaches, ocorrida no 1st Summerschool of Digital Humanities: Distant Reading - Potentials and Applications, em inglês. 2.9 Exemplo: Processo Civilizador O processo civilizador é uma tese consagrada pelo sociólogo Norbert Elias, de que, ao longo dos muitos anos, séculos, haveria um longo e lento processo de diminuição da violência e da demonstração de brutalidade cotidiana, no trato do dia à dia, do aumento do sentimento de vergonha e de intimidade. Três pesquisadores tentaram ver este processo com base nos arquivos de um tribunal, analisando 11.485 julgamentos, entre 1760 e 1913. Klingenstein S, Hitchcock T, DeDeo S. The civilizing process in London’s Old Bailey. Proc Natl Acad Sci U S A. 2014 Jul 1;111(26):9419-24. doi: 10.1073/pnas.1405984111. Com base nisto conseguiram observar uma tendência de longo prazo de progressiva distinção entre semântica de atos violentos e não violentos. 2.10 Ex.: Determinantes sociais do florescimento da cultura Incel Os celibatários involuntários ou Incels, são jovens, geralmente do sexo masculino, que não tem acesso aos meios sexuais, por isso “involuntários”. De um database de nada menos que 4 bilhões de tweets (entre 2012-2018), pegaram os dados de geolocalização de 321 milhões. Filtraram 3649 tweets que usaram linguagem peculiar aos incels e 3.745 sobre incels. Com estas informações em mãos, os pesquisadores descobriram informações importantes sobre os condicionantes sociais em que floresce a cultura incel. Brooks RC, Russo-Batterham D, Blake KR. Incel Activity on Social Media Linked to Local Mating Ecology. Psychological Science. January 2022. doi:10.1177/09567976211036065 https://txtlab.org/2015/11/how-i-predicted-the-giller-prize/ "],["estrutura-de-dados-e-tipos-de-formatos.html", "3 Estrutura de dados e tipos de formatos 3.1 Dados estruturados 3.2 Dados não estruturados 3.3 Dados semi-estruturados 3.4 Observações finais", " 3 Estrutura de dados e tipos de formatos Objetivos do capítulo: Apresentar a distinção entre dados estruturados, dados não estruturados e dados semi estruturados Apresentar alguns formatos de arquivos frequentes na análise textual e humanidades digitais, como csv e tsv, Json, markdown, yaml, LaTex, BibTex, xml e html. Podemos pensar a organização de dados quanto à sua estrutura de três formas: dados estruturados, dados semi estruturados e dados não estruturados. 3.1 Dados estruturados Formatos de arquivos estruturados são csv,xml, json, xls, xlsx, etc. Muitos destes possuem formato de tabela, o que torna bastante fácil encontrar a informação buscada. 3.1.1 Os formatos csv (comma separeted values) e tsv. O formato csv (comma separeted values ou “valores separados por vírgula”) é um dos mais simples, consiste de arquivo de texto simples, com valores separados por um caractere (ou conjunto de caracteres) que separam os valores em cada linha, sendo geralmente vírgula ou ponto e vírgula ou tabulação (tecla tab). Qualquer caractere ou conjunto de caracteres pode ser usado como separador de campos. Na imensa maioria dos casos cada linha é separada pela quebra de linha. Por exemplo, a seguinte tabela: Estado sigla capital região Acre AC Rio Branco Norte Alagoas AL Maceió Nordeste Amapá AP Macapá Norte Amazonas AM Manaus Norte Bahia BA Salvador Nordeste Ceará CE Fortaleza Nordeste Em abrirmos o csv no bloco de notas (notepad): Estado;sigla;capital;região; Acre;AC;Rio Branco;Norte; Alagoas;AL;Maceió;Nordeste; Amapá;AP;Macapá;Norte; Amazonas;AM;Manaus;Norte; Bahia;BA;Salvador;Nordeste; Ceará;CE;Fortaleza;Nordeste; O separador de campo neste arquivo CSV é o ponto e vírgula ;. Ao pedirmos ao computador para localizar qual a designação da sigla “AP”, ele saberá buscar facilmente esta informação. No caso ali, a vírgula é o separador de campos, mas qualquer outro caractere pode ser usado como separador. O formato .tsv, por exemplo, é separado por tabulação - ou o símbolo \\t. Mas é possível encontrar arquivo csv, porém com separador tipo “ ou”;“. 3.1.2 O formato Json O Json (“JavaScript Object Notation”, isto é “Notação de Objetos JavaScript”), é organizado no esquema de pares nome/valor. Por exemplo, ao separarmos primeiro nome firstName de sobrenome lastName no Json: {&quot;employees&quot;:[ { &quot;firstName&quot;:&quot;João&quot;, &quot;lastName&quot;:&quot;da Silva&quot; }, { &quot;firstName&quot;:&quot;Ana&quot;, &quot;lastName&quot;:&quot;Maria&quot; }, { &quot;firstName&quot;:&quot;Joaquim&quot;, &quot;lastName&quot;:&quot;Xavier&quot; } ]} O arquivo json inicia e termina com colchetes [] Todo Json é delimitado por chaves {}, Os dados são representados no esquema nome/valor `\"nome\": \"valor\". Estes são separados por vírgula. O Json tem sido muito usado nas ciência de dados como um modo leve e fácil de armazenamento de dados. É possível que ao requisitar dados em um site, ele venha em Json. DICA: Caso queira mais detalhes sobre o formato Json: Video introdutório sobre o formato Json do canal Código Fonte TV JSON // Dicionário do Programador. Video introdutório, porém mais prático, focado na estrutura do mesmo: JSON em 6 minutos do canal “Canal TI”. Para ver as regras de sintaxe do Json. 3.2 Dados não estruturados Os dados não estruturados são a forma como encontramos em livros impressos, artigos, jornais, revistas, etc. São a forma de texto que nós humanos lemos normalmente. Por exemplo: “Algum tempo hesitei se devia abrir estas memorias pelo principio ou pelo fim, isto é, se poria em primeiro logar o meu nascimento ou a minha morte. Supposto o uso vulgar seja começar pelo nascimento, duas considerações me levaram a adoptar differente methodo: a primeira é que eu não sou propriamente um autor defunto, mas um defunto autor, para quem a campa foi outro berço; a segunda é que o escripto ficaria assim mais galante e mais novo. Moysés, que tambem contou a sua morte, não a poz no introito, mas no cabo: differença radical entre este livro e o Pentateuco….” Este tipo de texto, não estruturado, é alvo do Processamento de linguagem natural (PLN)/ Natural Language Process (NLP). 3.3 Dados semi-estruturados Dados semi-estruturados são um meio termo entre os estruturados e os semi estruturados. Por vezes são chamados de “auto-descritivos”. Vejamos exemplos destes. 3.3.1 Exemplos de dados semi-estruturados 3.3.1.1 Markup Códigos especiais, ou linguagem “markup” é uma notação de documento que tem duas apresentações, uma simplificada como texto normal para humanos, e outra com os “markup” para que o computador entenda. 3.3.2 O formato Markdown Um exemplo bem simples de markup é o Mardown, usado na escrita rápida de textos. Exemplo de markdown 3.3.3 O formato YAML O YAML (“YAML Ain’t Markup Language”) é um padrão de serialização de dados que prima por ser “human friendly”, isto é, de fácil leittura também para humanos. Em arquivos markdown tem-se usado o yaml como cabeçalho, com informações para a renderização do pdf, como título, subtítulo, resumo, palavras chave, etc. Ao converter markdown para o formato final, o computador irá interpretar estas informações. Um exemplo de yaml no arquivo markdown: --- title: &quot;Título do meu pdf&quot; subtitle: subtitulo qualquer author: Fulano de Tal # comentário qualquer fontsize: 12pt urlcolor: blue geometry: margin=2.5cm abstract: &gt; meu resumo bla bla bla bla --- # Titulo Texto texto texto texto texto texto texto ## Subtitulo Texto texto texto texto texto texto texto O cabeçalho em yaml é delimitado no seu início e fim por três traços consecutivos ---. Repare que o símbolo tralha # dentro do yml é interepretado como comentário, já no markdown, indica capítulo. DICA: Um modo prático de trabalhar na elaboração de textos - principalmente acadêmicos - com markdown e yaml é renderizá-lo com o pandoc, que é um canivete suíço na transformação de formatos de texto. Com ele, pode-se criar pdfs, html, doc, docs, odt, etc. a partir de seu arquivo markdown. Pandoc funciona via linha de comando. 3.3.4 O Formato LaTex O LaTex é uma linguagem usada na confecção, principalmente de textos (livros, artigos) acadêmicos, bem como apresentações. O formato LaTex permite grande flexibilidade, e é muito usado para escrever fórmulas matemáticas e gerar as referências bibliográficas automaticamente. Por isso, o LaTex é muito usado no contexto acadêmico. O seu formato mínimo pode ser visto assim: \\documentclass{article} \\begin{document} Olá Mundo \\end{document} Exemplo simples de texto em LaTex e sua renderização Ou em um exemplo um pouco mais elaborado: Exemplo de LaTex com o software Gummi no Linux Perceba que antes de \\begin{document}, isto é, no cabeçalho do documento temos várias informações, entre elas o título do artigo na linha 5 em title{}, e em \\author{}, nas linhas de 6 a 8, temos os autores. Temos também delimitados os capítulos ou seções, no caso ali em section{}. DICA: Para renderizar textos .tex em pdfs deve-se usar um interpretador. O pandoc é uma opção. Embora seja possível usar apenas o interpretador/conversor e um bloco de notas, o mais comum em Tex e LaTex é usar algum programa focado. O TeXstudio é uma boa opção. Caso use Linux e queria a renderização à medida que edita o texto, olhe o Gummi. Caso queira fazer os documentos em LaTex sem ter de “programar”, dê uma olhada no LyX. Há também editores de LaTex online, como o overleaf, que possibilita trabalhar em equipe, observando as alterações feitas por cada pessoa 3.3.5 O formato BibTex Um formato “irmão” do LaTex e markdown é o BibTex, um formato estruturado, com dados bibliográficos usado como fonte para gerar automaticamente a bibliografia ao final do texto renderizado em formatos como Tex, LaTex e markdown. As referências nesse formato ficam salvos num grande arquivo .bib. Um exemplo de citação dentro do bib: @book{Coleman:IntroMathSociology, address = {New York}, pages = {570}, publisher = {The Free Press of Glencoe Collie, Macmillan Limited}, title = {Introduction to Mathematical Sociology}, year = {1964} } O @book indica o tipo, podendo ser também, por exemplo, @article para artigos, @inbook para parte de um livro, @phdthesis para tese de phd (há mais opções). Para uma lista completa, ver The 14 BibTeX entry types. O Coleman:IntroMathSociology é o ID, a identificação única, que é também usado na citação do LaTex (Por exemplo, usando \\cite{Coleman:IntroMathSociology} dentro do Tex) ou do Markdown (usando [@IntroMathSociology] dentro do texto) para que o compilador saiba qual texto está sendo citado no texto. Podemos usar o texto que quisermos ali, desde que sem espaço. Exemplo de citação usando bibtex no LaTex Este arquivo bib que contém as referências bibliográficas, como é texto puro, pode ser editado num editor de texto comum, como o notepad, Gedit, etc. Mas o mais indicado é usar um software gestor de bibliografia, como o JabRef ou o KBibTex. O KBibTex possui menos recursos que o JabRef mas dá plenamente conta do recado, sendo inclusive o gerenciador que utilizo. Além de ser usado para gerar pdfs com as referências, o formato também pode ser usado em pesquisas bibliométricas. 3.3.6 Os formatos xml e html HTML, ou “Hyper Text Markup Language” é a linguagem padrão das páginas web No caso, nome seria “FirstName” e seu valor seria “João”, nome seria “lastName” e seu valor “da Silva” E esses mesmos dados no formato xml: &lt;employees&gt; &lt;employee&gt; &lt;firstName&gt;João&lt;/firstName&gt; &lt;lastName&gt;da Silva&lt;/lastName&gt; &lt;/employee&gt; &lt;employee&gt; &lt;firstName&gt;Ana&lt;/firstName&gt; &lt;lastName&gt;Maria&lt;/lastName&gt; &lt;/employee&gt; &lt;employee&gt; &lt;firstName&gt;Joaquim&lt;/firstName&gt; &lt;lastName&gt;Xavier&lt;/lastName&gt; &lt;/employee&gt; &lt;/employees&gt; Algumas linguagens usadas em texto são chamadas de markup, onde o que é mostrado na tela, para humanos lerem, difere do que o computador “entende”. Exemplo é o xml acima, o html ou ainda linguagens como markdown e LaTex. O html tem por base o xml. O html possui basicamente a seguinte estrutura &lt;!doctype html&gt; &lt;html&gt; &lt;head&gt; &lt;title&gt;Titulo da pagina&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;Título do capítulo&lt;/h1&gt; &lt;p&gt;Texto texto texto&lt;/p&gt; &lt;/body&gt; &lt;/html&gt; Se você copiar o conteúdo acima e salvar num arquivo com o nome, digamos teste.html e abrí-lo com seu navegador de internet (Firefox, Chrome, Opera, etc.), verá como funciona esta ideia de markup. No caso do html, os valores são delimitados por tags, como: &lt;ALGO&gt;conteúdo&lt;/ALGO&gt;, onde &lt;/ indica que estamos fechando a tag. Assim, em &lt;h1&gt;Título do capítulo&lt;/h1&gt;, o texto “Título do capítulo” está entre a tag “h1”. Os arquivos html, assim como o LaTex, possui duas partes principais. O cabeçalho (head) e o corpo (body). Figure 3.1: Tatuagem head/body. Autor desconhecido Entre &lt;head&gt; e seu fechamento, &lt;/head&gt; ficam os metadados, como título, data, etc. Entre &lt;body&gt; e &lt;/body&gt; fica o conteúdo da página que aparece dentro do navegador. Um outro exemplo: &lt;name&gt;Joaquim José da Silva Xavier&lt;/name&gt;, o Tiradentes (&lt;local&gt;Fazenda do Pombal&lt;/local&gt;, batizado em &lt;data&gt;12 de novembro de 1746&lt;/data&gt; — &lt;local&gt;Rio de Janeiro&lt;/local&gt;, &lt;data&gt;21 de abril de 1792&lt;/data&gt;), foi um &lt;profissao&gt;dentista&lt;/profissao&gt;, &lt;profissao&gt;tropeiro&lt;/profissao&gt;, &lt;profissao&gt;minerador&lt;/profissao&gt;, &lt;profissao&gt;comerciante&lt;/profissao&gt;, &lt;profissao&gt;militar&lt;/profissao&gt; e &lt;profissao&gt;ativista político&lt;/profissao&gt; &lt;gentilico&gt;brasileiro&lt;/gentilico&gt;, que atuou nas capitanias de &lt;local&gt;Minas Gerais&lt;/local&gt; e &lt;local&gt;Rio de Janeiro&lt;/local&gt;. Onde podemos ver tags como &lt;name&gt;, &lt;local&gt;, &lt;data&gt;, etc. ao redor de certas informações, o que torna possível ao computador encontrar estas informações. Para tutorial gratuito (em inglês) sobre html, ver W3 School. 3.3.7 Formatos mais raros Há ainda a possibilidade de uso de estruturação de texto não muito comuns e com fins bem específicos. Por exemplo, Franzosi (2010) ao fazer análise da narrativa de jornais italianos da época de ascensão do Fascismo, passou textos não estruturados como este: Republicans plunged in Bissone di S. Cristina around 10pm of this month at the pub Prati. A guy, who went by the name of “captain,” took out a list of names and did the roll call loudly. Para o seguinte formato: [Semantic triplet 1: [Participant: [Actor: republicans]] [[Process: [[Verb: plunge] [Circumstances: [Space: [City: Bissone di S. Cristina] [[Location: pub] [Name: Prati]]]] [[Time: [Date: 05/07/1921] [Hour: 10pm]]]]] [Semantic triplet 2: [Participant: [Actor: captain]] [Process: [[Verb: does roll call] [Circumstances: [Type of action: loudly] [Instrument: list]]] [Participant: [Actor: workers]] Para tal, Franzosi desenvolveu um software para análise de narrativas textuais, o PC-ACE (Program for Computer-Assisted Coding of Events) e pôde ter uma noção melhor da violência cotidiana na época, gerado tabelas como esta: Lista da ocorrências diárias de triplets de violência, obtidas no jornal Avanti! (FRANZOSI, p.607) Frequência da distribuição dos triplets de violência no jornal Avanti! (FRANZOSI, p.607) E ainda fez um “mapa de calor” (“heat map”) com a localização da violência fascista na Itália Mapa de calor de ações fascistas de violência e localização de suas sedes insittucionais (FRANZOSI, p.609) Referência: FRANZOSI, Roberto P.. Sociology, narrative, and the quality versus quantity debate (Goethe versus Newton): Can computer-assisted story grammars help us understand the rise of Italian fascism (1919–1922)?. Theor Soc (2010) 39:593–629. DOI 10.1007/s11186-010-9131-3 3.4 Observações finais Os dados semi-estruturados não tem, portanto, formato de tabela, mas contêm indicações de informações mais abstratas, através de tags ou outras marcações. Com base nestas informações que faremos análises de texto de modo computacional. Este processo de transformação de dados não estruturados em estruturados é chamado de “datificação”. Os formatos como Json, csv, tsv, xml são importantes pois ao solicitar dados em diversos sites, muitos APIs retornam dados nestes formatos. "],["noções-básicas-de-programação-em-r.html", "4 Noções básicas de programação em R 4.1 Sequências de scaping 4.2 Variável e atribuição 4.3 Funções no R 4.4 Condicionais: se/então, If/else 4.5 Operadores 4.6 Loops, repetições", " 4 Noções básicas de programação em R EM CONSTRUÇÃO Objetivos deste capítulo: Apresentar uma breve introdução aos principais comandos usados em programação 4.1 Sequências de scaping Há alguns caracteres especiais que não podem ser usados diretamente numa string, pois possuem um significado especial. As aspas são um caso. Assim, por exemplo: variavel &lt;- 'moinho d'agua' retorna erro. Para poder utilizar as aspas, temos de dizer ao programa para “escapar”. Isto é feito de modo geral com o caractere \\. Assim, para funcionar, nosso exemplo fica: variavel &lt;- 'moinho d\\'agua'. No caso de aspas simples ' ou duplas \", é possível escapar estes caracteres colocando um dentro do outro. Por exemplo: variavel &lt;- \"moinho d'agua\" ou variavel &lt;- 'O conto \"Trio em Lá Menor\" de Machado de Assis foi publicado em 1896.'. Outros caracteres que levam escape são: 4.1.1 Comentando o código Nas linguagens de programação é possível acrescentar comentários para orientar os humanos e que não serão lidos pelo computador. Cada linguagem tem o seu próprio padrão. No R, assim como em muitas linguagens de programação, os comentários no código são feito com a tralha # ou hashtag, jogo da velha, etc. Tudo que vier depois deste símbolo é então ignorado. print(&quot;Olá mundo!&quot;) ## [1] &quot;Olá mundo!&quot; print(&quot;Olá mundo R!&quot;) # comentário que o computador ignora ## [1] &quot;Olá mundo R!&quot; Se retirarmos o símbolo # temos então mensagem de erro. print(&quot;Olá mundo! Olá R&quot;) comentários que dará erro ## Error: &lt;text&gt;:1:28: unexpected symbol ## 1: print(&quot;Olá mundo! Olá R&quot;) comentários ## ^ 4.2 Variável e atribuição Em programação, no processo de automatização de tarefas, o uso de variáveis é essencial. Ele permite que reutilizemos as coisas, através de nomes mais simplificados. Normamente, usa-se o símbolo de igual =para atribuir algo a uma variável, no seguinte modo: Noma_da_variavel = valores O R também usa este símbolo, mas também usa outro que lhe é prório, o &lt;- que lembra uma seta. nome1 = &quot;Fulano&quot; nome2 &lt;- &quot;Ciclano&quot; message(&quot;Um nome é &quot;, nome1, &quot;, o outro é &quot;, nome2) ## Um nome é Fulano, o outro é Ciclano Pode-se usar na direção contrária também &quot;Beltrano&quot; -&gt; nome3 nome3 ## [1] &quot;Beltrano&quot; Há algumas regras para criar variáveis. Não conter espaço no nome é uma delas. Ao invés disso, pode-se usar o underscore (Ex.: bla_ble) ou ponto (bla.ble). Há alguns caracteres especiais que não podem ser usados diretamente numa string, pois possuem um significado especial. As aspas são um caso. Assim, por exemplo: variavel &lt;- 'moinho d'agua' retorna erro. Para poder utilizar as aspas, temos de dizer ao programa para “escapar”. Isto é feito de modo geral com o caractere \\. Assim, para funcionar, nosso exemplo fica: variavel &lt;- 'moinho d\\'agua'. No caso de aspas simples ' ou duplas \", é possível escapar estes caracteres colocando um dentro do outro. Por exemplo: variavel &lt;- \"moinho d'agua\" ou variavel &lt;- 'O conto \"Trio em Lá Menor\" de Machado de Assis'. 4.3 Funções no R Funções são úteis para evitar retrabalho. Possuem a seguinte sintaxe: # criando uma função no R nome_da_funcao &lt;- function(argumento_1, argumento_2, ...) { fazendo_algo_com(argumento_1) fazendo_algo_mais_com(argumento_2) } # rodando a função nome_da_funcao(argumento_1,sargumento_2) arg_1, arg_2 são os parâmetros de entrada na função, que serão processados Ao chamar uma função, passa-se argumentos para esta processar. Argumentos também podem conter valores padrão, caso a informação não lhe seja repassada. Em um exemplo simples de função: x &lt;- function(){ print(&#39;Olá Mundo&#39;) } x() ## [1] &quot;Olá Mundo&quot; Ou um outro exemplo, com a função tendo argumentos de entrada: # Criando função com valores padrão: minhafuncao &lt;- function(a = 2, b = 3) { resultado &lt;- a + b print(resultado) } # chamando a função sem nenhum argumento. minhafuncao() ## [1] 5 # chamando a função repassando argumentos. minhafuncao(10,4) ## [1] 14 # chamando a função repassando parte dos argumentos. minhafuncao(,4) ## [1] 6 4.4 Condicionais: se/então, If/else Se uma condição, então faça algo. Se outra condição, então faça outra coisa. else: Se nenhuma das condições anteriores for satisfeita, então faça o seguinte. Em sua versão mais simples if (condição) { fazer_algo() } Se certa condição for satisfeita, for verdadeira, então algo especificado será feito. Se certa condição não for satisfeita, for falsa, então nada será feito. Perceba que nossa função apenas retorna algo se o argumento de entrada for maior que 5. Caso contrário - como foi com o valor 3 - ela nada faz. if(3 &gt; 5){ print(&quot;X é maior que 5&quot;) } if(14 &gt; 5){ print(&quot;X é maior que 5&quot;) } ## [1] &quot;X é maior que 5&quot; 4.4.1 Else Uma versão mais elaborada da condicional envolve a condição else if (condição) { fazer_algo() } else { fazer_outra_coisa() } Se certa condição for satisfeita, for verdadeira, então algo especificado - a função fazer_algo() - será realizada. Se certa condição não for satisfeita, for falsa, então outra coisa será feita. Ex.: minhafuncao &lt;- function(arg1){ if(arg1 &gt; 5){ message(arg1, &quot; é maior que 5&quot;) } else { message(arg1, &#39; não é maior que 5&#39;) } } minhafuncao(3) ## 3 não é maior que 5 minhafuncao(13) ## 13 é maior que 5 4.4.2 else if Podemos colocar mais condições intermediárias, quantas quisermos, com else if comes &lt;- function(arg1){ if (arg1 == &quot;laranja&quot;){ print(&quot;Prefiro tamarindo&quot;) } else if (arg1 == &quot;rucula&quot;){ print(&quot;bleaaaargh&quot;) } else if (arg1 == &quot;sanduiche&quot;){ print(&quot;Com suco de tamarindo!&quot;) } else { print(&quot;Só sei com laranjas&quot;) } } # chamando a função acima comes(&quot;laranja&quot;) ## [1] &quot;Prefiro tamarindo&quot; comes(&quot;rucula&quot;) ## [1] &quot;bleaaaargh&quot; comes(&quot;sanduiche&quot;) ## [1] &quot;Com suco de tamarindo!&quot; comes(&quot;abacaxi&quot;) ## [1] &quot;Só sei com laranjas&quot; comes(&quot;morango&quot;) ## [1] &quot;Só sei com laranjas&quot; Combinando função e If/Else verifica &lt;- function(arg_entrada1, arg_entrada2){ if (arg_entrada1 &gt; arg_entrada2) { message(arg_entrada1, &#39; é maior que &#39;, arg_entrada2) } else { message(arg_entrada1, &#39; não é maior que &#39;, arg_entrada2) } } Chamando a função verifica(1,5) ## 1 não é maior que 5 verifica(7,2) ## 7 é maior que 2 4.5 Operadores Usamos operadores para realizar transformações ou comparações entre valores ou variáveis (que por sua vez, contém valores). 4.5.1 Operadores de atribuição (assignment) Os operadores de atribuição são aqueles que vimos na sessão “variável”, que são =, &lt;-, &lt;&lt;-, -&gt; e -&gt;&gt;. 4.5.2 Operadores Aritiméticos Operador Descrição + adição - subtração * multiplicação / divisão ^ ou ** exponencial Há ainda os operadores %% (modulus) e %/% (divisão integral). 5+7 ## [1] 12 15/3 ## [1] 5 4.5.3 Operadores relacionais Operador Descrição &lt; menor que &lt;= menor ou igual a &gt; maior que &gt;= maior ou igual que == exatamente igual a != diferente de 5&gt;6 ## [1] FALSE 7&lt;=6 ## [1] FALSE variavel &lt;- &quot;teste&quot; variavel == &quot;abacate&quot; ## [1] FALSE variavel != &quot;TESTE&quot; ## [1] TRUE 4.5.4 Operadores booleanos E OU NÃO AND OR NOT Símbolos &amp; | ! No R também temos &amp;&amp; || ! Operador Descrição != não igual a !x não x x | y x ou y x &amp; y x E y isTRUE(x) teste se X é TRUE https://stat.ethz.ch/R-manual/R-devel/library/base/html/Logic.html txt &lt;- c(&quot;bla bla&quot;, &quot;bla ble&quot;, &quot;bla bli&quot;, &quot;bla non&quot;) grep(&#39;bla (bla|ble)&#39;, txt, value =T) ## [1] &quot;bla bla&quot; &quot;bla ble&quot; y &lt;- c(&quot;bla&quot;, &quot;ble&quot;, &quot;bli&quot;) y==&quot;bla&quot; ## [1] TRUE FALSE FALSE y!=&quot;bla&quot; ## [1] FALSE TRUE TRUE Algumas buscas na internet disponibilizam alguns operadores. No portal da Cãmara dos deputados, pode-se buscar discursos dos parlamentares no banco de discursos utilizando “and” e “or” (link aqui). Na busca do Google, é possível excluir termos da busca (no caso, o operador “NOT”), utilizando o sinal de menos antes do termo. 4.5.5 Outros operadores Operador Descrição : Cria uma sequência de números em uma sequência %in% Se um elemento pertence/está contido em um vetor de elementos %*% Multiplicação de matrizes # geranto automaticamente uma sequencia de 5 a 10 x &lt;- 5:10 x ## [1] 5 6 7 8 9 10 # checando se alguns numeros estão contidos no vetor x 2 %in% x ## [1] FALSE 7 %in% x ## [1] TRUE # Num outro exemplo, vamos usar o operador para checar intesecção entre dois vetores v1 &lt;- c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, 1, 2, 67, 53, 73) v2 &lt;- c(&quot;x&quot;, &quot;y&quot;, &quot;z&quot;, &quot;2&quot;, &quot;h&quot;, &quot;j&quot;, &quot;c&quot;) # obtendo um vetor com booleanos (TRUE e FALSE) de todos os elementos v1 %in% v2 ## [1] FALSE FALSE TRUE FALSE TRUE FALSE FALSE FALSE # observando apenas os elementos que tem intersecção entre os vetores v1[v1 %in% v2] ## [1] &quot;c&quot; &quot;2&quot; Num exemplo prático, o comando colors() lista as cores que possuem nome no R. Vamos usá-lo para exemplificar o operador %in%. Ele nos dirá se um nome de cor está presente no vetor de cores que o comando colors() retorna. &quot;darkred&quot; %in% colors() ## [1] TRUE 4.6 Loops, repetições 4.6.1 For Loops Quando necessita de fazer uma mesma operação, repetida, em vários itens de uma lista, usamos os loops. Com loops iteramos, aplicamos uma operação a cada item de uma série de itens. for (item in variavel_com_varios_itens){ faça algo com cada item n da variável } Por exemplo: x &lt;- c(1, 3, 5) # o loop abaixo pegará os elementos 1,3 e 5 # e adicionará 1 a cada um deles. for (i in x){ print(i+1) } ## [1] 2 ## [1] 4 ## [1] 6 Também podemos aplicar loops a strings: x &lt;- c(&#39;bla&#39;, &#39;ble&#39;) for (i in x){ print(paste(&#39;Alguém disse: &#39;, i)) } ## [1] &quot;Alguém disse: bla&quot; ## [1] &quot;Alguém disse: ble&quot; nomes &lt;- c(&quot;Fulano&quot;, &quot;Beltrano&quot;, &quot;Maria&quot;, &quot;Karen&quot;) for(i in nomes) { # o comando nchar() conta quantos caracteres há no item print(paste(&quot;O nome&quot;, i, &quot;contém&quot;, nchar(i), &quot;caracteres.&quot;)) } ## [1] &quot;O nome Fulano contém 6 caracteres.&quot; ## [1] &quot;O nome Beltrano contém 8 caracteres.&quot; ## [1] &quot;O nome Maria contém 5 caracteres.&quot; ## [1] &quot;O nome Karen contém 5 caracteres.&quot; 4.6.2 While loop O for loops é usado quando temos uma lista que sabemos quantos elementos temos. Para o caso de não sabermos ao certo quantos e quais elementos temos, há ainda um outro tipo de loop em programação, o while loop, que diz enquanto uma condição for verdadeira, ela continuará rodando, e irá parar assim que for falsa. # criando a variável &quot;i&quot; de valor 1 i &lt;- 1 # Enquanto a condição i for menor que 7, continue while (i &lt; 7) { # imprime a mensagem message(i, &quot; é menor que 7&quot;) # adiciona 1 ao valor de i i &lt;- i + 1 # volta ao início } ## 1 é menor que 7 ## 2 é menor que 7 ## 3 é menor que 7 ## 4 é menor que 7 ## 5 é menor que 7 ## 6 é menor que 7 No exemplo acima, criamos a variável “i” que tem valor 1, e dentro do loop há a operação de acrescentar +1 a cada “rodada” do loop, que começa com o valor “1”. A cada rodada, o loop avalia se a condição i &lt; 7 é verdadeira. Se sim, imprime o valor atual da variável i e adiciona +1 ao valor de i. O loop continua rodando para o próximo item. Assim que chega em 7, o loop pára, já que “7 &lt; 7” é falso. 4.6.3 apply (lapply, sapply, tapply e mapply) Além de for loop e while loop, no R temos a família apply (lapply, sapply, tapply e mapply), que funciona como um for loop normal, mas que pode simplificar um pouco a repetição, além de ser mais rápido que o for loop. Entretanto, o apply funciona aplicando uma função já pré definida anteriormente. Assim, no nosso exemplo com o vetor nomes &lt;- c(&quot;Fulano&quot;, &quot;Beltrano&quot;, &quot;Maria&quot;, &quot;Karen&quot;) Em que aplicamos o for loop for(i in nomes) { # o comando nchar() conta quantos caracteres há no item print(nchar(i)) } ## [1] 6 ## [1] 8 ## [1] 5 ## [1] 5 Podemos fazer algo parecido com o apply sapply(nomes, nchar) ## Fulano Beltrano Maria Karen ## 6 8 5 5 Além de forloops e da família apply, o R conta também com: família de funções map_ do pacote purrr do tidyverse pacote foreach, que possibilita forloops com processamento paralelo, isto é, mais rápidos. As funções do purrr também podem ser paralelizadas para ficarem mais rápidas através do pacote furrr. "],["introdução-ao-r.html", "5 Introdução ao R 5.1 Obtendo Ajuda no R 5.2 R em modo gráfico: RKWard e RCommander 5.3 Tipos de Dados no R (data types) 5.4 Estrutura de dados no R (Data Structures) 5.5 Instalando pacotes no R 5.6 A suíte de pacotes tidyverse 5.7 Manipulando data e hora", " 5 Introdução ao R Objetivos do capítulo: Apresentar como obter ajuda no R Apresentar os tipos de dados e as estruturas de dados no R Apresentar a suíte de pacotes do tidyverse Supondo que já tenha o R e o RStudio instalados (há diversos tutoriais de instalação no Youtube), vamos aos primeiros passos. É possível também rodar o R de modo online, de modo gratuito, sem instalar nada em seu computador, com o One Compiler e o Snippets, tendo mais de 19 mil pacotes instalados. O lado negativo é que não é um modo prático e tão rápido como rodar em seu computador, mas pode servir para pequenos testes. Snippets: um site para rodar R online Outro modo de rodar o R online é criar uma conta no RStudio Cloud, que possui também modalidade de conta gratuita, com algumas limitações: 15 horas de uso mensais, 1 Gb de Ram (pouco, mas funciona). Vantagem do Rstudio Cloud: a instalação de pacotes ocorre sem maiores problemas. Desvantagem: be mais lento que o RStudio Desktop. RStudio Cloud: rodando o RStudio nas nuvens através de navegador de internet HISTÓRIA A linguagem R foi criada no ano de 1993 por Ross Ihaka e Robert Gentleman do Departamento de Estatística da Universidade de Auckland, da Nova Zelândia, se baseando na linguagem S (por sua vez, criada em 1976). O anúncio oficial de lançamento do R ocorreu em 23 de abril de 1997. IHAKA, Ross; GENTLEMAN, Robert. “R: A Language for Data Analysis and Graphics”. Journal of Computational and Graphical Statistics. 5 (3): 299. set.1996 doi:10.2307/1390807. ISSN 1061-8600. JSTOR 1390807. R é uma linguagem aberta e gratuita, mutiplataforma (roda em Linux, Windows e Mac), publicada sob a licença General Public License (GNU). O R é criado por estatísticos e é bem popular no mundo acadêmico. O R vem com diversos pacotes e funções nativamente. Só para ter uma ideia desta quantidade: Pacote Número de funções base 1244 datasets 104 graphics 87 grDevices 112 methods 203 utils 215 stats 449 Dificilmente vamos dominar estes pacotes e mais as funções dos pacotes específicos que iremos instalar 5.1 Obtendo Ajuda no R A primeira coisa a se aprender é como conseguir ajuda, como conseguir a informação que precisamos. A busca por ajuda é uma constante, mesmo entre os mais experiente. Obtendo ajuda no RStudio Comando Descrição Exemplo de uso help.start() para abrir o sistema de ajuda em HTML no seu navegador help.start() help(\"função\") ou ?funcao() Acesso à documentação de funções, data sets e outros. No Rstudio, a ajuda é aberta na aba “Help”. Caso rode direto no console, sem o RStudio, uma vez dentro da página de ajuda, digite / para realizar busca e q para sair ?getwd ou help(getwd) help(função, package=\"NOME_PACOTE\") para obter ajudar de um pacote que não foi cerregado help(rlm, package=\"MASS\") Ajuda para a função rlm() do pacote MASS help(package = 'NOME_PACOTE') Mostra um índice de páginas de ajuda para o pacote help(package = 'dplyr' example() Mostra exemplos de uso da função example(grep) help.search() ou ??busca Para busca mais vaga. Caso não se lembre do nome exato da função, ou caso busque uma função que faça determinada tarefa ??regression mostra diversas funções de diversos pacotes que contém a palavra “regression” RSiteSearch() Busca no seu navegador (browser) padrão em sites especializados em R RSiteSearch(\"text analysis\") args() Mostra os argumentos que uma função pode receber. args(grep) apropos() Busca pelo nome de uma função. Útil quando não lembramos exatamente o nome de uma função apropos(\"grep\") demo() Lista todas as demonstrações de todos os seus pacotes demo() demo(package=\"package-name\") lista as demonstrações de um pacote particular demo(package=\"stats\") lsf.str(\"package:nome_do_pacote\") Mostra as funções do pacote (que precisa já ter sido carregado) lsf.str(\"package:dplyr\") ls(\"package:nome_do_pacote\") Mostra os objetos do pacote (que precisa já ter sido carregado) ls(\"package:dplyr\") search() Lista os pacotes já carregados search() Fonte: Versão expandida de Getting Help with R. # Buscando por funções que contenham &quot;grep&quot; apropos(&quot;grep&quot;) ## [1] &quot;agrep&quot; &quot;agrepl&quot; &quot;grep&quot; &quot;grepl&quot; &quot;grepRaw&quot; # Mostrando os argumentos que uma função pode receber args(gsub) ## function (pattern, replacement, x, ignore.case = FALSE, perl = FALSE, ## fixed = FALSE, useBytes = FALSE) ## NULL Outra dica é buscar a documentação do pacote no site do cran ou buscar por problemas específicos no o site Stack Overflow. 5.2 R em modo gráfico: RKWard e RCommander Caso deseje rodar análises estatísticas tradicionais, - não para análise textual - há pelo menos dois modos de rodar o R em modo gráfico (GUI), usando cliques de mouse. Um é através do RKWard que funciona como um SPSS/PSPP, porém, tendo o R como linguagem base. A segunda alternativa é o Jamovi, também livre e aberto. Uma terceira alternativa é o Rcmdr ou R Commander. Ao carregar este pacote dentro do R, uma janela aparece onde escolhemos o tipo de operação, e ele mostra o código para tal. O Rcmdr ensina como importar dados (SPSS, Excell, Stata, ruls, etc.), como realizar diversas operações estatísticas, como plotar gráficos. Ao rodar o Rcmdr pela primeira vez, pacotes adicionais serão instalados, como na imagem abaixo. Instalação do R Commander. Instalando pacotes adicionais Após a instalação de pacotes adicionais, O R Commander abre uma janela com os comandos. R Commander em ação Caso feche a janela do RCommander, rodar library(Rcmdr) novamente não abrirá a janela, uma vez que o pacote já está carregado. A solução é rodar então Commander() para ter a janela novamente. Caso queira fechar este pacote, basta digitar no Console detach(\"package:Rcmdr\", unload=TRUE) ou apenas feche o R. Para trabalhar com análise textual com estes acima: Há um plugin do RCmd para análise textual, o RcmdrPlugin.temis (porém, última atualização em 2018). No caso do RKward, o pacote koRpus oferece plugin GUI, com funcionalidades para a língua portuguesa. Dicas: R Commander LAURETTO, Marcelo. Introdução ao R Commander. (Pequeno tutorial do RCommander, em PDF e em português.) The R Commander: A Basic-Statistics GUI for R FOX, John. Getting Started With the R Commander. (Artigo do criador do RCommander) Video tutorial do R Commander em ação e em português: Aprendendo Estatística com o R Commander do Departamento de Estatística UFLA 5.2.1 NVIM-R Por fim, para os usuários mais avançados quem não tem medo do terminal e gosta de usar o editor Vim ou o Neovim, uma dica é usar o plugin Nvim-R que traz diversas facilidades para usar o Nvim em conjunto com o R. Trata-se de uma alternativa leve e rápida ao Rstudio. (O autor do pacote é um professor brasileiro do departamento de Sociologia da UFC). 5.3 Tipos de Dados no R (data types) “Tudo que existe no R é um objeto” (John Chambers, apud WICKHAM) Tipos de dados se referem à forma mais simples de objetos, ou tipos de dados atômicos do R (R atomic data types) Os seis tipos de dados básicos são: Tipo de dado no R Exemplo de uso 1 character ou “string” (texto) “a”, “bla”, “Fulano de tal” 2 numeric (real ou decimal) -2, 43, 3,333333 3 integer (integral) 3L (O “L” é o modo que o R entende que é um integral) 4 logical (lógico) TRUE ou FALSE 5 complex (complexo) 1-4i (números complexos com partes reais e imaginárias) 6 raw (bytes, para arquivos com dados binários) O raw é de uso raro. &gt; charToRaw('olá') resulta em: 6f 6c c3 a1 Integrais ou “integer” são um tipo de dado sem frações, ou números inteiros, podendo ser positivos ou negativos. Tipos reais, ou float são números que possuem fração. Estes nomes tem a ver com o modo com o computador salva esta informação. O float possui tamanho de 4 bytes, e se o número possuir mais de 7 dígitos, o valor é arredondado para 7. Já o “double” possui 8 bytes, o “dobro” do float, podendo chegar a 15 dígitos de acurácia. o que lhe confere maior acurácia, mas também ocupa mais espaço e requer mais processamento computacional. Se quiser saber melhor sobre float e double, veja este artigo “Float vs Double”). Algumas linguagens possuem até o tipo “long double” ou big decimal, que possuem acurácia maior que o double. Portanto, “double” tem recebe este nome pelo modo como é salvo no computador. Uma vez criados os dados, para examinar as características dos objetos há algumas funções no R Função no R para examinar tipos de dados Descrição Exemplo class() Que tipo de objeto é? class(3), class(\"bla\") length() Qual o tamanho do vetore? Quantos itens possui? | ` length(c(“bla”,“ble”))` attributes() Possui metadados? # Criando um texto (character). Tem de ser delimitado entre aspas minha_variavel_texto &lt;- &quot;bla&quot; minha_variavel_texto ## [1] &quot;bla&quot; class(minha_variavel_texto) ## [1] &quot;character&quot; # Criando uma variável numérica. Não pode ser delimitado por aspas. minha_variavel_numerica &lt;- 2 minha_variavel_numerica ## [1] 2 class(minha_variavel_numerica) ## [1] &quot;numeric&quot; # Criando um integral: minha_variavel_integral &lt;- 5L minha_variavel_integral ## [1] 5 class(minha_variavel_integral) ## [1] &quot;integer&quot; # Criando um variável lógica. Também sem aspas. ## 5 é maior que 3? minha_variavel_logica &lt;- 5 &gt; 3 minha_variavel_logica ## [1] TRUE class(minha_variavel_logica) ## [1] &quot;logical&quot; ## 5 é menor que 3? minha_variavel_logica2 &lt;- 5 &lt; 3 minha_variavel_logica2 ## [1] FALSE minha_variavel_logica3 &lt;- TRUE # É possível atribuir minha_variavel_logica3 ## [1] TRUE minha_variavel_logica4 &lt;- F # Também é possível usar abreviaturas &quot;T&quot; e &quot;F&quot; minha_variavel_logica4 ## [1] FALSE # Criando um número complexo: numero_complexo &lt;- 3 + 2i numero_complexo ## [1] 3+2i class(numero_complexo) ## [1] &quot;complex&quot; # Convertendo para raw ## convertendo character para raw meuraw &lt;- charToRaw(&#39;teste&#39;) meuraw ## [1] 74 65 73 74 65 class(meuraw) ## [1] &quot;raw&quot; Na criação de tipos de dados, pode-se usar de coerção (coercion) através das funções as. Função Coerção para as.numeric Numeric as.integer Integer as.double Double as.character Character as.logical Boolean as.raw Raw EM CONSTRUÇÃO 5.4 Estrutura de dados no R (Data Structures) EM CONSTRUÇÃO Vimos os tipos de dados. Estes podem ser organizados de distintos modos, e a depender desta organização, temos diferentes estruturas de dados. O R possui diversas estruturas de dados, como: vetores numéricos e atômicos lista (list) fatores (factors) matriz (matrix) data frame 5.4.1 Vetor (vector) Como dito no manual, “Pode-se conceber vetores como células contíguas contendo dados” (Vectors can be thought of as contiguous cells containing data”), ou uma série de valores do mesmo tipo de dado. Vetor é a estrutura de dados mais comum no R, os tipos básicos de vetores atômicos são aqueles seis mencionados anteriormente. Criamos vetores com a função c() de “concatenate” ou “combine”. No caso de strings (character), deve-se colocar os valores dentro de aspas: meu_vetor &lt;- c(&quot;bla&quot;, &quot;ble&quot;, &quot;bli&quot;, &quot;blo&quot;, &quot;blu&quot;) # criando o vetor com strings meu_vetor # imprimindo na tela o vetor que acabamos de criar ## [1] &quot;bla&quot; &quot;ble&quot; &quot;bli&quot; &quot;blo&quot; &quot;blu&quot; class(meu_vetor) ## [1] &quot;character&quot; length(meu_vetor) # observando quantos itens possui nosso vetor ## [1] 5 meu_vetor[3] # acessando o item do 3 de nosso vetor ## [1] &quot;bli&quot; # Criando um vetor de valores booleanos # Não se usa aspas nesse caso vetor_logico &lt;- c(TRUE, FALSE, FALSE) # criando um vetor de valores booleanos class(vetor_logico) ## [1] &quot;logical&quot; # Criando um vetor com diferentes tipo de dados vetor_pan &lt;- c(&quot;bla&quot;, 3, TRUE, 5L) vetor_pan ## [1] &quot;bla&quot; &quot;3&quot; &quot;TRUE&quot; &quot;5&quot; # criando uma sequência numérica de 2 a 8. Desta vez não iremos salvar em uma variável c(2:8) ## [1] 2 3 4 5 6 7 8 Tanto números simples (ex.: 2.5) como strings (ex.: “Olá mundo R!”) tem comprimento (length) 1. Já, por exemplo, c('Olá', 'mundo', 'R') possui comprimento 3. length(&#39;Olá mundo R&#39;) ## [1] 1 length(c(&#39;Olá&#39;, &#39;mundo&#39;, &#39;R&#39;)) ## [1] 3 Vetores podem ser de dois tipos: 1) atômicos, ou 2) listas. Mas o mais frequênte é encontrarmos “vetor” como sinônimo de “vetor atômico”, e listas serem consideradas como algo à parte. Para examinarmos os vetores, podemos usar as funções: class(), para saber o tipo, length(), para saber quantos elementos possui e str(), bastante útil ao lidarmo com dataframes, o comando mostra a estrutura básica: quantos elementos, quantas colunas (se houver), uma amostra dos elementos. Há ainda o comando typeof(), mas recomendamos usar o class() para evitar confusão. É ainda possível também atribuir nomes aos elementos de um vetor usando a função names() valores &lt;- c(12, 34, 13) # Criando um vetor nomes &lt;- c(&quot;banana&quot;, &quot;uva&quot;, &quot;abacate&quot;) # Criando vetor com os nomes names(valores) &lt;- nomes # atribuindo o vetor &quot;nomes&quot; como titulo do vetor &quot;valores&quot; valores # imprimindo o vetor com nomes e valores ## banana uva abacate ## 12 34 13 names(valores) # imprimindo apenas os nomes ## [1] &quot;banana&quot; &quot;uva&quot; &quot;abacate&quot; class(valores) ## [1] &quot;numeric&quot; 5.4.2 Fator (Factor) Considere a seguinte tabela fictícia: Nome Altura(cm) Região do país Fulano 175 NE Ciclano 134 SE Beltrano 166 S João 187 S Maria 173 NE José 159 CO Joaquim 161 SE Se em uma coluna certos valores se repetem, podemos considerá-los como “fatores”. No caso, a coluna “Nome” possui valores únicos, a coluta “Altura” também, mas a coluna “Região” possui uma quantidade limitada de valores que se repetirão: N,S,NO,SE,CO. Podemos então considerar os valores desta coluna como “fatores”. Fatores podem ser tanto strings, como no caso acima, como integrais, como no caso da idade de estudantes de uma mesma turma. Um exemplo prático: # Criando um vetor de caracteres com siglas de aeroportos brasileiros aeroportos &lt;- c(&quot;BSB&quot;, &quot;CON&quot;, &quot;BSB&quot;, &quot;VIC&quot;, &quot;GUA&quot;, &quot;FOR&quot;, &quot;MAO&quot;,&quot;GUA&quot;, &quot;CON&quot;, &quot;CON&quot;, &quot;REC&quot;, &quot;UDI&quot;, &quot;VIC&quot;, &quot;GUA&quot;) table(aeroportos) ## aeroportos ## BSB CON FOR GUA MAO REC UDI VIC ## 2 3 1 3 1 1 1 2 # Se tento criar um barplot com os valores, dá erro: barplot(table(aeroportos)) # Temos de transformar os dados em um fator, que vamos chamar de &quot;aeroportos.factor&quot; aeroportos.fator &lt;- factor(aeroportos) # Perceba que &quot;Levels&quot; mostra os valores sem repetição aeroportos.fator ## [1] BSB CON BSB VIC GUA FOR MAO GUA CON CON REC UDI VIC GUA ## Levels: BSB CON FOR GUA MAO REC UDI VIC # Mostrando a frequência de cada termo com a função &#39;summary()&#39; summary(aeroportos.fator) ## BSB CON FOR GUA MAO REC UDI VIC ## 2 3 1 3 1 1 1 2 # Agora é possível gerar o gráfico de barras (barplot) barplot(summary(aeroportos.fator)) Fatores são comuns em tabelas, mas são raros em análise textual. Assim, ao trabalhar com análise textual, convém mudar as opções globais de strings, para não serem consideradas fatores: options(stringsAsFactors = FALSE) # ou podemos transformar informações em fatores através do comando aeroportos.fator &lt;- as.factor(aeroportos) aeroportos.fator ## [1] BSB CON BSB VIC GUA FOR MAO GUA CON CON REC UDI VIC GUA ## Levels: BSB CON FOR GUA MAO REC UDI VIC Fator é um tipo de dado usado para campos com valores pré-definidos, valores finitos, como em dados categóricos. Assim, por exemplo, raça, ou status matrimonial contém um número finito de valores (solteira(o), amasiada(o), casada(o), divorciada(o), viúva(o)). No caso dos aeroportos, podemos ver os valores únicos com o comando levels() levels(aeroportos.fator) ## [1] &quot;BSB&quot; &quot;CON&quot; &quot;FOR&quot; &quot;GUA&quot; &quot;MAO&quot; &quot;REC&quot; &quot;UDI&quot; &quot;VIC&quot; 5.4.3 Matriz (Matrix) Vejamos as matrizes. Podemos pensar em matrizes como tabelas contendo dados do mesmo tipo. Vamos gerar uma matriz para termos contato com uma. # 1:12=Os elementos da nossa matriz, 1 a 12 # 4=linhas no eixo vertical 3=linhas no eixo horizontal minha.matriz &lt;- matrix(1:12, 4, 3) minha.matriz ## [,1] [,2] [,3] ## [1,] 1 5 9 ## [2,] 2 6 10 ## [3,] 3 7 11 ## [4,] 4 8 12 # Acessando itens, linha 2, coluna 3 minha.matriz[2, 3] ## [1] 10 # Acessando uma linha inteira minha.matriz[2, ] ## [1] 2 6 10 Matrizes também são bastante usadas na análise textual, como nas Document-Term-Matrix e nas Term Document Matrix, que são um passo intermediário de diversas análises textuais, como preparação para Topic Modeling, por exemplo. Veremos em mais detalhes posteriormente, mas apenas para um primeiro contato, o DTM Dadas as frases “O rato roeu a roupa do rei”, “O rei riu do rato”, “A roupa do rato é de rei”, consideraremos cada linha como um documento (documento, neste caso, é cada uma das frases). Ao criar uma matriz tipo DTM os documentos são as linhas e as colunas são as palavras e os números são a frequência de cada termo em cada frase: Table 5.1: Um exemplo de DTM rato rei riu roeu roupa 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 Se esta é a primeira vez com estrutura de dados, matriz, o que vimos de matriz pode já ser o suficiente por agora e você poderá pular para a próxima estrutura de dados, a lista. Mais para frente, quando a análise e o pacote necessitarem, você será reencaminhado para esta seção, de como fazer um Document-Term_Matrix (DTM) e um Term-Document-Matrix (TDM). Os Document-Term-Matrix e o Term-Document-Matrix são usados em análise textual e PLN como passo intermediário para outras análises. Matriz é bem útil ao transformar texto em um formato que o computador consegue entender e processar. Vejamos alguns modos de gerar matrizes com diferentes pacotes. 5.4.4 Gerando um DTM com o pacote TM library(tm) frases &lt;- c(&quot;O rato roeu a roupa do rei&quot;, &quot;O rei riu do rato&quot;, &quot;A roupa do rato é de rei&quot;) myCorpus &lt;- data.frame(frases) corpus &lt;- Corpus(VectorSource(myCorpus$frases)) x &lt;- inspect(DocumentTermMatrix(corpus)) ## &lt;&lt;DocumentTermMatrix (documents: 3, terms: 5)&gt;&gt; ## Non-/sparse entries: 10/5 ## Sparsity : 33% ## Maximal term length: 5 ## Weighting : term frequency (tf) ## Sample : ## Terms ## Docs rato rei riu roeu roupa ## 1 1 1 0 1 1 ## 2 1 1 1 0 0 ## 3 1 1 0 0 1 5.4.5 Gerando DTM com o pacote Tidytext No pacote Tidytext, para gerar o DTM, 1) precisamos tokenizar usamos a função cast_dtm(coluna_documentos, coluna_termos, contagem_palavras). Para a contagem de palavras requerida, podemos usar a função count() previamente. frases &lt;- c(&quot;O rato roeu a roupa do rei&quot;, &quot;O rei riu do rato&quot;, &quot;A roupa do rato é de rei&quot;) frases_df &lt;- dplyr::tibble(id_doc = 1:3, frases = frases) # tokenizando o tibble frasesR &lt;- tidytext::unnest_tokens(frases_df, palavras, frases) # Criando o DTM frasesR %&gt;% # contando termos com &#39;count&#39;, que gera nova coluna &#39;n&#39; dplyr::count(palavras, id_doc) %&gt;% tidytext::cast_dtm(id_doc, palavras, n) ## &lt;&lt;DocumentTermMatrix (documents: 3, terms: 10)&gt;&gt; ## Non-/sparse entries: 19/11 ## Sparsity : 37% ## Maximal term length: 5 ## Weighting : term frequency (tf) O que nos retorna: - A indicação de que se trata de um Document Term Matrix - A frequência de termos e de documentos -“Non-/sparse entries” refere-se aos não zeros - “sparsity” refere-se à proporção de zeros na matriz: - Caso não exista nenhum zero em nossa matriz, o sparsity será 0%. Por exemplo, quando temos um DTM com apenas um documento. - Tivemos um valor alto de sparsity, mas por que temos poucas frases e bem parecidas - É comum termos valores altos de sparsity como 100%, principalmente quando temos muitos documentos e matrizes bem maiores que esta. Se quisermos visualizar a matriz, precisamos ampliar nosso código com as.matrix() frasesR %&gt;% # contando termos com &#39;count&#39;, que gera nova coluna &#39;n&#39; dplyr::count(palavras, id_doc) %&gt;% tidytext::cast_dtm(id_doc, palavras, n) %&gt;% as.matrix() ## Terms ## Docs a de do é o rato rei riu roeu roupa ## 1 1 0 1 0 1 1 1 0 1 1 ## 3 1 1 1 1 0 1 1 0 0 1 ## 2 0 0 1 0 1 1 1 1 0 0 5.4.6 Listas (list) Listas (ou “vetores genéricos”) são conjuntos de vetores mais gerais no R. Podemos colocar tipos diferentes de objetos em uma lista (por exemplo, uma matriz , vetores, dataframes, etc.) Para criar uma lista, usamos o comando list() minha_lista = list(c(T,T,F, F, T, T, F), c(&quot;Joaquim&quot;, &quot;José&quot;, &quot;Silva&quot;), c(3,6,3,67,22) ) minha_lista ## [[1]] ## [1] TRUE TRUE FALSE FALSE TRUE TRUE FALSE ## ## [[2]] ## [1] &quot;Joaquim&quot; &quot;José&quot; &quot;Silva&quot; ## ## [[3]] ## [1] 3 6 3 67 22 # Acessando o vetor 3 de nossa lista. No caso de listas, usamos o duplo colchete minha_lista[[3]] ## [1] 3 6 3 67 22 # Acessando o vetor 2 de nossa lista, item 3 minha_lista[[2]][3] ## [1] &quot;Silva&quot; É possível também “quebrar” um texto em vetores, através do comando strsplt() texto = &quot;Bla bla bla. Ble ble ble ble. Bli bli. Blo. Blu blu blu&quot; class(texto) ## [1] &quot;character&quot; strsplit(texto, &quot;\\\\.&quot;) ## [[1]] ## [1] &quot;Bla bla bla&quot; &quot; Ble ble ble ble&quot; &quot; Bli bli&quot; &quot; Blo&quot; ## [5] &quot; Blu blu blu&quot; No exemplo acima, o primeiro argumento em strplit() é a variável, o segundo argumento é o critério a ser usado para quebrar o texto. Alguns caracteres são considerados especiais e precisam ser indicados que queremos seu significado literal. É o caso de ponto final. Para conseguirmos usá-lo como ponto final, ao invés de usarmos \".\", usamos \\\\. . Note que ficaram espaços no início dos elementos dos vetores. Podemos melhorar nosso código acrescentando um espaço em branco após o ponto final: strsplit(texto, &quot;\\\\. &quot;) ## [[1]] ## [1] &quot;Bla bla bla&quot; &quot;Ble ble ble ble&quot; &quot;Bli bli&quot; &quot;Blo&quot; ## [5] &quot;Blu blu blu&quot; Se examinarmos o tipo de arquivo que temos, veremos que se trata de uma lista: texto2 &lt;- strsplit(texto, &quot;\\\\. &quot;) class(texto2) ## [1] &quot;list&quot; Se quisermos que este seja um vetor simples, e não lista: class(texto2) ## [1] &quot;list&quot; # usar o comando unlist() unlist(texto2) ## [1] &quot;Bla bla bla&quot; &quot;Ble ble ble ble&quot; &quot;Bli bli&quot; &quot;Blo&quot; ## [5] &quot;Blu blu blu&quot; class(unlist(texto2)) ## [1] &quot;character&quot; # Ou ainda, acessando o item 1 da lista strsplit(texto, &quot;\\\\. &quot;)[[1]] ## [1] &quot;Bla bla bla&quot; &quot;Ble ble ble ble&quot; &quot;Bli bli&quot; &quot;Blo&quot; ## [5] &quot;Blu blu blu&quot; É possível fazer uma lista nomeada: minha.lista &lt;- list(nome1 = c(&quot;Joaquim&quot;, &quot;José&quot;, &quot;Silva&quot;), letras = letters[1:6], minha_matriz = matrix(1:8, nrow = 2) ) # vendo a lista criada minha.lista ## $nome1 ## [1] &quot;Joaquim&quot; &quot;José&quot; &quot;Silva&quot; ## ## $letras ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;d&quot; &quot;e&quot; &quot;f&quot; ## ## $minha_matriz ## [,1] [,2] [,3] [,4] ## [1,] 1 3 5 7 ## [2,] 2 4 6 8 # Acessando os itens da lista: minha.lista[[2]][3] ## [1] &quot;c&quot; # ou ainda, no caso de lista nomeada minha.lista$letras[3] ## [1] &quot;c&quot; 5.4.7 Data Frames Uma vantagem de se trabalhar com data frame é que as colunas tem nome e não apenas índice, e isto facilita nosso trabalho na hora de procurar as informações que queremos, pois buscar a coluna pelo seu número pode nos causar confusão. A manipulação de dataframes foi facilitada com os tibbles e os pacotes do tidyverse (ver mais abaixo), mas antes vejamos os dataframes tradicionais. # Criando 3 vetores com valores aleatórios idade &lt;- as.integer(c(12,23,35)) genero &lt;- as.character(c(&quot;fem&quot;, &quot;mas&quot;, &quot;fem&quot;)) raça &lt;- as.character(c(&quot;pret&quot;, &quot;branc&quot;, &quot;pard&quot;)) # Jogando estes vetores no nosso dataframe, que vamos nomear de &quot;df&quot; df &lt;- data.frame(idade, genero, raça) df # vendo nosso dataframe no console ## idade genero raça ## 1 12 fem pret ## 2 23 mas branc ## 3 35 fem pard # ver o dataframe em uma nova janela pop-up View(df) class(df) # Qual a classe de nosso objeto, caso tenhamos esquecido? ## [1] &quot;data.frame&quot; names(df) # retornando apenas o nome das colunas ## [1] &quot;idade&quot; &quot;genero&quot; &quot;raça&quot; # Ver o número de linhas e colunas através do comando # dim() de &quot;dimensions&quot; dim(df) ## [1] 3 3 # mostra a estrutura do dataframe, como # quantidade de linhas (obs.) e colunas (variables) # nomes das colunas, tipo de dado nesta coluna, primeiros valores str(df) ## &#39;data.frame&#39;: 3 obs. of 3 variables: ## $ idade : int 12 23 35 ## $ genero: chr &quot;fem&quot; &quot;mas&quot; &quot;fem&quot; ## $ raça : chr &quot;pret&quot; &quot;branc&quot; &quot;pard&quot; df$genero # Filtrando o dataframe &quot;df&quot; pela coluna &quot;genero&quot; ## [1] &quot;fem&quot; &quot;mas&quot; &quot;fem&quot; df[2] # Filtrando o dataframe pela coluna 2: df[numero] ## genero ## 1 fem ## 2 mas ## 3 fem df[,2] # Filtrando o dataframe pela coluna 2: ## [1] &quot;fem&quot; &quot;mas&quot; &quot;fem&quot; # Filtrando o dataframe pelo número da linha: df[número_da_Linha,] . # Repare na necessidade da vírgula. df[1,] # imprimindo a linha 1 ## idade genero raça ## 1 12 fem pret df[3,] # imprimindo a linha 3 ## idade genero raça ## 3 35 fem pard df[1:2,] # retornando as linhas de 1 a 2 ## idade genero raça ## 1 12 fem pret ## 2 23 mas branc # Para o caso de excluir as primeiras linhas # exclui as linhas de 1 a 2 df[-(1:2),] ## idade genero raça ## 3 35 fem pard # media da coluna &quot;idade&quot; mean(df$idade) ## [1] 23.33333 summary(df) # Obtendo uma visão estatística ampla da tabela ## idade genero raça ## Min. :12.00 Length:3 Length:3 ## 1st Qu.:17.50 Class :character Class :character ## Median :23.00 Mode :character Mode :character ## Mean :23.33 ## 3rd Qu.:29.00 ## Max. :35.00 summary(df$genero) # sumário da coluna &quot;gênero&quot; do dataset &quot;df&quot; ## Length Class Mode ## 3 character character summary(df$idade) # sumário da coluna &quot;idade&quot; do dataset &quot;df&quot; ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 12.00 17.50 23.00 23.33 29.00 35.00 # testando se valores da coluna &quot;genero&quot; são &quot;fem&quot; df$genero==&quot;fem&quot; ## [1] TRUE FALSE TRUE # Filtrando apenas as linhas onde a coluna &quot;genero&quot; for &quot;fem&quot;. # Explicando de outro modo: quando &quot;genero&quot; igual a &quot;fem&quot; for verdadeiro, imprima df[df$genero==&quot;fem&quot;,] ## idade genero raça ## 1 12 fem pret ## 3 35 fem pard # Filtrando apenas as linhas onde a escolaridade for maior que 12. df[df$idade &gt; 12,] ## idade genero raça ## 2 23 mas branc ## 3 35 fem pard Outro modo de criar dataframe é com a função read.table(), muito usada para carregar tabelas em texto puro meuDataFrame &lt;- read.table( # Se header (cabeçalho) = True, então a primeira linha será considerada cabeçalho header=TRUE, text=&#39; Letra Valor A 9 B 14 C 11 D 12&#39;) meuDataFrame ## Letra Valor ## 1 A 9 ## 2 B 14 ## 3 C 11 ## 4 D 12 # Vendo a estrutura do dataframe criado str(meuDataFrame) ## &#39;data.frame&#39;: 4 obs. of 2 variables: ## $ Letra: chr &quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;D&quot; ## $ Valor: int 9 14 11 12 5.4.7.1 Manipulando/Editando o data frame # adicionando (append) nova linha ao data.frame # Modo1: através do &#39;nrow&#39; df[nrow(df)+1,]=c(23, &quot;mas&quot;, &quot;branc&quot;) df ## idade genero raça ## 1 12 fem pret ## 2 23 mas branc ## 3 35 fem pard ## 4 23 mas branc # Modo 2: rbind() df &lt;- rbind(df, c(20,&quot;fem&quot;, &quot;pret&quot;)) df ## idade genero raça ## 1 12 fem pret ## 2 23 mas branc ## 3 35 fem pard ## 4 23 mas branc ## 5 20 fem pret # mudando um valor, em uma célula # data.frame[número_da_linha, número_da_coluna] = new_value df[4,1] = 14 df ## idade genero raça ## 1 12 fem pret ## 2 23 mas branc ## 3 35 fem pard ## 4 14 mas branc ## 5 20 fem pret # mudando um valor usando o nome da coluna df[4,&quot;raça&quot;] = &quot;pret&quot; df ## idade genero raça ## 1 12 fem pret ## 2 23 mas branc ## 3 35 fem pard ## 4 14 mas pret ## 5 20 fem pret # mudando valores com condicionais # onde coluna raça for &quot;branc&quot;, mudar na coluna &quot;raça&quot; para &quot;branco&quot; # se o segundo parâmetro não for inserido, todas células ganharão valor &quot;branco&quot; df[df$raça==&quot;branc&quot;, &quot;raça&quot;] = &quot;branco&quot; df ## idade genero raça ## 1 12 fem pret ## 2 23 mas branco ## 3 35 fem pard ## 4 14 mas pret ## 5 20 fem pret # deletando linhas # com base no numero da linha df[-c(1),] # deleta a linha 1 ## idade genero raça ## 2 23 mas branco ## 3 35 fem pard ## 4 14 mas pret ## 5 20 fem pret df &lt;- df[-c(1),] # para tornar a mudança permanente # com base no valor df = df[!df$a==&quot;bla&quot;,] 5.4.8 Considerações finais sobre estrutura de dados Estes não são os únicos tipos de estrutura de dados no R. Alguns pacotes podem criar o seu próprio tipo e não convém tentar cobrir todos. Apesar de considerar tipos diferentes, podemos considerar os diferentes tipos como subcategorias de outras. Data frames são um tipo restrito de listas. Listas, por sua vez, são um tipo de vetor. Veremos a seguir a suíte de pacotes do tidyverse que possui formato próprio de dados. 5.5 Instalando pacotes no R No R não carregamos tudo de uma vez, mas carregamos os pacotes ou bibliotecas que vamos usar. Assim salvamos mais memória para o processamento no computador. Um modo de instalar pacotes é via linha de comando 5.5.1 Modo 1: instalando via linha de comando install.packages(&quot;Nome_do_pacote&quot;) Para checar os pacotes instalados: rownames(installed.packages()) 5.5.2 Modo 2: Modo gráfico Outro modo é ir na aba packages / install Após isso, digite o nome do pacote na caixa, deixando marcado o “install dependencies” e depois em “install”. É muito comum os pacotes precisarem de outros pacotes, e com esta opção marcada, o R instala tudo. 5.6 A suíte de pacotes tidyverse O tidyverse é uma suíte de pacotes bastante úteis e de uso mais fácil que os pacotes tradicionais do R. Dicas O artigo do Hadley Wickham, o criador da ideia, explicando a “filosofia” dos dados “tidy”. &gt; Hadley Wickham. Tidy Data. Journal of Statistical Software Para instalar a suíte de pacotes tidyverse install.packages(tidyverse) O tidyverse conta com diversos pacotes e estão sempre aumentando. library(tidyverse) # vendo os pacotes disponíveis no tidyverse: tidyverse_packages() ## [1] &quot;broom&quot; &quot;cli&quot; &quot;crayon&quot; &quot;dbplyr&quot; ## [5] &quot;dplyr&quot; &quot;dtplyr&quot; &quot;forcats&quot; &quot;googledrive&quot; ## [9] &quot;googlesheets4&quot; &quot;ggplot2&quot; &quot;haven&quot; &quot;hms&quot; ## [13] &quot;httr&quot; &quot;jsonlite&quot; &quot;lubridate&quot; &quot;magrittr&quot; ## [17] &quot;modelr&quot; &quot;pillar&quot; &quot;purrr&quot; &quot;readr&quot; ## [21] &quot;readxl&quot; &quot;reprex&quot; &quot;rlang&quot; &quot;rstudioapi&quot; ## [25] &quot;rvest&quot; &quot;stringr&quot; &quot;tibble&quot; &quot;tidyr&quot; ## [29] &quot;xml2&quot; &quot;tidyverse&quot; O ecossistema tidyverse Tidyverse ecosystem picture (author: Silvia Canelón, PhD. Original link) Para nós, destes pacotes, os mais interessantes são: Pacote tidyverse descrição readr Lê dados retangulares (de tabelas) como csv, tsv e fwf rvest usado para minerar dados na web de modo fácil tibble Para trabalharmos com tibble, um tipo de data frame ggplot2 Famoso pacote de geração de gráficos dplyr Para manipulação facilitada de dados stringr Usado na manipução de strings libridate Para lidar com data e hora de modo fácil purrr Usado em programação funcional, torna a construção de loops mais limpa e fácil magrittr Para usar pipes (%&gt;%). Parte dele é carregado ao carregar outros pacotes da suíte forcats Usado para trabalharmos com fatores, ao lidar com dados categóricos 5.6.1 Pipes Quando aplicamos uma série de funções em série, o modo tradicional é de fazê-lo é colocando funções dentro de outras funções, as “nested functions”, por exemplo: função3(função2(função1))) Representação metafórica de funções dentro de outras funções Repare que a ordem das funções é invertida, o que pode tornar bem trabalhosa a tarefa de descobrir a ordem das funções. Mas podemos fazer o mesmo de um modo mais fácil e bem mais inteligível, usando pipes do pacote magritrr do tidyverse. Para carregá-lo, basta carregar qualquer um dos pacotes do tidyverse, como stringr ou dplyr. Com ele, ao invés das funções dentro de funções do exemplo anterior, é possível ordenar os comandos intercalados com pipes de um modo mais intuitivo função1() %&gt;% função2() %&gt;% função3() Caso não haja parâmetros dentro dos parênteses, pode-se retirar os parênteses. função1 %&gt;% função2 %&gt;% função3 Caso, a função exija mais de um parâmetro, deve-se indicar o local onde o nome do dataframe/vetor, etc com um ponto final. função1() %&gt;% função2(., parametroQualquer = ValorDoParametroQualquer) ou se a função for diferente (ao olhar os argumentos da função, o x diz onde o ponto de ir) função1() %&gt;% função3(parametroQualquer, OutroParametroQualquer, .) Há ainda outros pipes, mas neste caso, o pacote magrittr deve ser carregado explicitamente. como o %$%. data.frame %$% coluna que equivale a data.frame$coluna. Em maio de 2021 foi introduzido no R versão 4.1.0 um novo pipe, nativo, vindo por padrão no R, o |&gt;, que tem suas peculiaridades. Talvez o mais prudente é aguardar um pouco mais para usá-lo. Até lá, indica-se usar o pipe do tidyverse. 5.6.2 Tibbles O “Tibble” é um modo de chamar objetos da classe “tbl_df”, um tipo de dataframe, mas que possui algumas vantagens. O tibble, ao ser chamado, mostra apenas as 10 primeiras linhas, ao invés do dataframe inteiro, o que é bem útil quando temos tabelas que não sejam minúsculas. O Tibble, ao contrário do dataframe, também mostra os tipos de dados das variáveis, e tenta se adequar ao tamanho da tela. Além disso, um tibble não força caracteres para fatores, que é o modo como lidamos com strings ao fazermos a análise textual. O video “Qual a diferença entre dataframe e tibble?” do canal de Samuel Macedo explica as diferenças entre estes dois tipos. Vamos criar um tibble com os dados que usamos no exemplo anterior do dataframe. # criando vetores com valores idade &lt;- as.integer(c(12,23,35, 22, 73)) genero &lt;- as.character(c(&quot;fem&quot;, &quot;mas&quot;, &quot;fem&quot;, &quot;fem&quot;, &quot;mas&quot;)) raca &lt;- as.character(c(&quot;preto&quot;, &quot;branco&quot;, &quot;pardo&quot;, &quot;pardo&quot;, &quot;branco&quot;)) # cria-se tibble com a função &#39;tibble()&#39; a partir dos vetores anteriores MeuTibble &lt;- dplyr::tibble(idade, # Não esqueça de colocar vírgula ao final destas linhas genero, # a ultima liha não leva vírgula raca) MeuTibble ## # A tibble: 5 × 3 ## idade genero raca ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 12 fem preto ## 2 23 mas branco ## 3 35 fem pardo ## 4 22 fem pardo ## 5 73 mas branco # mostrando apenas uma colunar} MeuTibble$genero ## [1] &quot;fem&quot; &quot;mas&quot; &quot;fem&quot; &quot;fem&quot; &quot;mas&quot; Também é possível alterar o nome da coluna/variável ao criar o tibble, usando o formato nome_da_coluna_no_tibble = nome_da_variável, MeuTibble2 &lt;- dplyr::tibble(idade_amostra = idade, genero_amostra = genero, raca_amostra = raca) MeuTibble2 ## # A tibble: 5 × 3 ## idade_amostra genero_amostra raca_amostra ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 12 fem preto ## 2 23 mas branco ## 3 35 fem pardo ## 4 22 fem pardo ## 5 73 mas branco 5.6.3 Dplyr: Verbos (ou comandos) O pacote Dplyr possui vários “verbos” ou comandos, para manipulação de dados: Manipulando linhas: filter() filtra linhas com base nos valores das colunas. slice() escolhe linhas com base na localização. arrange() reordena as linhas com base na ordem de uma ou mais colunas. Pode ser combinada com desc() para inverter a ordem. Por exemplo, em um dataframe, podemos reordená-la com bbase na ordem alfabética dos nomes, ou das datas ou de alguma outra coluna. Colunas: select() seleciona/filtra variáveis/colunas. Para inverter a seleção, usar select(!Variavel) rename() muda o nome das colunas. mutate() muda os valores de colunas e pode também criar novas colunas (útil para criar nova coluna com base em uma já existente). relocate() muda a ordem das colunas. Grupo de linhas: summarise() colapsa um grupo de linhas em uma linha única, sendo combinada com outros comandos group_by() junta linhas de mesmo valor (bom para usar com fatores). Deve ser usado em conjunto com outros comandos. (Esta é uma função genérica, isto é, provê implementação de outros pacotes) Fonte: Baseado parcialmente em Introduction to dplyr. Vejamos exemplos destes comandos. library(dplyr) # carregando o pacote caso não tenha sido carregado ## ## Attaching package: &#39;dplyr&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## filter, lag ## The following objects are masked from &#39;package:base&#39;: ## ## intersect, setdiff, setequal, union 5.6.3.0.1 dplyr::filter() Usamos o verbo filter para filtrar linhas com certos valores específicos # Filtrando um valor específico de uma coluna MeuTibble %&gt;% filter(genero == &quot;fem&quot;) ## # A tibble: 3 × 3 ## idade genero raca ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 12 fem preto ## 2 35 fem pardo ## 3 22 fem pardo # Filtrando por valores de duas colunas MeuTibble %&gt;% filter(genero == &quot;fem&quot; &amp; raca == &quot;pardo&quot;) ## # A tibble: 2 × 3 ## idade genero raca ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 35 fem pardo ## 2 22 fem pardo # Filtrando com termo aproximado # para tal, combinamos filter com grepl MeuTibble %&gt;% filter(grepl(&quot;p.*&quot;, raca)) ## # A tibble: 3 × 3 ## idade genero raca ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 12 fem preto ## 2 35 fem pardo ## 3 22 fem pardo 5.6.3.0.2 dplyr::arrange() # ordenando por valores da coluna &quot;idade&quot; arrange(MeuTibble, idade) ## # A tibble: 5 × 3 ## idade genero raca ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 12 fem preto ## 2 22 fem pardo ## 3 23 mas branco ## 4 35 fem pardo ## 5 73 mas branco # Invertendo a ordenção MeuTibble %&gt;% arrange(desc(idade)) ## # A tibble: 5 × 3 ## idade genero raca ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 73 mas branco ## 2 35 fem pardo ## 3 23 mas branco ## 4 22 fem pardo ## 5 12 fem preto 5.6.3.0.3 dplyr::select() Restringindo as colunas/variáveis. MeuTibble %&gt;% select(genero) ## # A tibble: 5 × 1 ## genero ## &lt;chr&gt; ## 1 fem ## 2 mas ## 3 fem ## 4 fem ## 5 mas # todas colunas, exceto a genero MeuTibble %&gt;% select(!genero) ## # A tibble: 5 × 2 ## idade raca ## &lt;int&gt; &lt;chr&gt; ## 1 12 preto ## 2 23 branco ## 3 35 pardo ## 4 22 pardo ## 5 73 branco # Selecionando a coluna pelo índice, e não pelo nome select(MeuTibble,1) ## # A tibble: 5 × 1 ## idade ## &lt;int&gt; ## 1 12 ## 2 23 ## 3 35 ## 4 22 ## 5 73 5.6.3.0.4 dplyr::rename() É posível renomear variáveis/colunas com o comando rename, que em o seguinte formato: rename(novo_nome = nome_antigos) MeuTibble %&gt;% dplyr::rename(genero_bin = genero) ## # A tibble: 5 × 3 ## idade genero_bin raca ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 12 fem preto ## 2 23 mas branco ## 3 35 fem pardo ## 4 22 fem pardo ## 5 73 mas branco 5.6.3.0.5 dplyr::mutate() mutate(NomeVariavel = função()) modifica e cria novas colunas/variáveis. Pode ser usado em conjunto com outros cálculos # criando variável expectativa de vida expectativa_vida = 70 MeuTibble %&gt;% select(genero, idade) %&gt;% # vamos ver quantos anos faltam para cada idade atingir a # expectativa de vida da região mutate(AnosParaExpecVida = expectativa_vida - idade) ## # A tibble: 5 × 3 ## genero idade AnosParaExpecVida ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 fem 12 58 ## 2 mas 23 47 ## 3 fem 35 35 ## 4 fem 22 48 ## 5 mas 73 -3 5.6.3.0.6 dplyr::summarise() A função summarise() ou summarize() (com “s” ou “z”, ambas funcionam), cria um novo data frame. Pode ser usado com funções como mean(), median(), ou para contar dados categóricos, dentre outras funções. Sua sintaxe é summarize(nome_nova_variavel = funcao) # verificando a média de idade MeuTibble %&gt;% summarise(mean(idade)) ## # A tibble: 1 × 1 ## `mean(idade)` ## &lt;dbl&gt; ## 1 33 5.6.3.0.7 dplyr::group_by() O comando summarise se torna mais útil em conjunto com o comando group_by(). # Media de idade por genero MeuTibble %&gt;% group_by(genero) %&gt;% summarise(media = mean(idade)) ## # A tibble: 2 × 2 ## genero media ## &lt;chr&gt; &lt;dbl&gt; ## 1 fem 23 ## 2 mas 48 Podemos usar o summarize também para contar dados categóricos, junto à função n() e ao group_by(). Por exemplo, vamos contar os itens na coluna “genero” MeuTibble %&gt;% group_by(genero) %&gt;% summarise(novo_nome_da_variável = n()) ## # A tibble: 2 × 2 ## genero novo_nome_da_variável ## &lt;chr&gt; &lt;int&gt; ## 1 fem 3 ## 2 mas 2 Um modo ainda mais simples de contar dados categóricos, é usando a função count(). A contagem aparece em uma nova coluna de nome “n” MeuTibble %&gt;% count(genero) ## # A tibble: 2 × 2 ## genero n ## &lt;chr&gt; &lt;int&gt; ## 1 fem 3 ## 2 mas 2 Caso prefira usar o índice da coluna ao invés de seu nome, use group_by_at(numero_da_coluna). Pode-se ainda acrescentar novas linhas ou juntar tibbles através dos comandos: comando descrição bind_rows() junta dois tibbles, permitindo linhas duplicadas union(df1,df2) Junta tibbles df1 e df2, mas acrescenta sem repetição. Pode-se retirar linhas com anti_join(). Este comando pode ser útil para retirar stopwords anti_join(stop_words) Dicas: Tibble Uma boa introdução aos tibbles (em inglês) temos no capítulo 10.Tibbles do livro “R for Data Science” de Wichham e Grolemund. 5.7 Manipulando data e hora Data e hora é algo simples, mas que pode dar dor de cabeça se não usar os pacotes já prontos. O R usa o seguinte formato \"ano-mês-dia hora:minuto:segundo\" ou, por exemplo, 2021-03-09 13:05:03. O mês vem antes de dia e ano vem antes de todos já que assim é possível organizar as datas facilmente usando a ordem alfabética/numérica. P.s: Cuidado! Para evitar confusão, não use data como nome para um objeto, já que data tem significado especial no R. Existe um padrão para datas usado em várias linguagens. Por exemplo, %d equivale a dia, %m equivale a mês em formato numérico, %b em formato por extenso. Para consultar a lista com este formato, consulte a ajuda ?strptime. Mas vale lembrar, esta conversão ficou mais fácil com o pacote lubridate, que veremos mais abaixo. # Dizendo ao R que nossa string &quot;12/05/1993 13:00:05&quot; é uma data minha_data = &quot;12/05/1993 13:00:05&quot; minha_data2 = strptime(minha_data, format = &quot;%d/%m/%Y %H:%M:%S&quot;) minha_data2 ## [1] &quot;1993-05-12 13:00:05 -03&quot; 5.7.1 Gerando uma sequencia de datas no R Em algum momento você pode precisar de uma sequência de datas, por exemplo, ao fazer a raspagem de dados de algum site que usa o formato de data (como é o caso de agendas de autoridades governamentais). Isto é bem fácil com o R. Vamos gerar datas entre “29 de novembro de 2020 (”2020-11-29”) e 02 de janeiro de 2021 (“2021-01-02”). seq(from=as.Date(&quot;2020-11-29&quot;), to=as.Date(&quot;2021-01-02&quot;), by=&quot;day&quot;) ## [1] &quot;2020-11-29&quot; &quot;2020-11-30&quot; &quot;2020-12-01&quot; &quot;2020-12-02&quot; &quot;2020-12-03&quot; ## [6] &quot;2020-12-04&quot; &quot;2020-12-05&quot; &quot;2020-12-06&quot; &quot;2020-12-07&quot; &quot;2020-12-08&quot; ## [11] &quot;2020-12-09&quot; &quot;2020-12-10&quot; &quot;2020-12-11&quot; &quot;2020-12-12&quot; &quot;2020-12-13&quot; ## [16] &quot;2020-12-14&quot; &quot;2020-12-15&quot; &quot;2020-12-16&quot; &quot;2020-12-17&quot; &quot;2020-12-18&quot; ## [21] &quot;2020-12-19&quot; &quot;2020-12-20&quot; &quot;2020-12-21&quot; &quot;2020-12-22&quot; &quot;2020-12-23&quot; ## [26] &quot;2020-12-24&quot; &quot;2020-12-25&quot; &quot;2020-12-26&quot; &quot;2020-12-27&quot; &quot;2020-12-28&quot; ## [31] &quot;2020-12-29&quot; &quot;2020-12-30&quot; &quot;2020-12-31&quot; &quot;2021-01-01&quot; &quot;2021-01-02&quot; O parâmetro by aceita ainda week e month. O R também calcula anos bissextos. Fazendo um teste, gerando datas entre 28 de fevereiro e 1 de março de diferentes anos: # criando uma função para testes FevMarc &lt;- function(ano) { # nome_da_funcao &lt;- function(input){ minhaDataInicial=paste0(ano, &quot;-02-28&quot;) MinhaDataFinal=paste0(ano, &quot;-03-01&quot;) seq(from=as.Date(minhaDataInicial), to=as.Date(MinhaDataFinal), by=&quot;day&quot;) } for ( ano in c(2015:2021) ) { x= FevMarc(ano) print(x) } ## [1] &quot;2015-02-28&quot; &quot;2015-03-01&quot; ## [1] &quot;2016-02-28&quot; &quot;2016-02-29&quot; &quot;2016-03-01&quot; ## [1] &quot;2017-02-28&quot; &quot;2017-03-01&quot; ## [1] &quot;2018-02-28&quot; &quot;2018-03-01&quot; ## [1] &quot;2019-02-28&quot; &quot;2019-03-01&quot; ## [1] &quot;2020-02-28&quot; &quot;2020-02-29&quot; &quot;2020-03-01&quot; ## [1] &quot;2021-02-28&quot; &quot;2021-03-01&quot; 5.7.2 Lubridate: facilitando manipulação de datas Com o Lubridate é mais fácil manipular data e hora, ou mesmo alterar fuso horário. No caso abaixo, não precisamos especificar o caractere separador, apenasa ordem. No caso abaixo, dia/mês/ano minha_data &lt;- &quot;12/05/2020&quot; lubridate::dmy(minha_data) ## [1] &quot;2020-05-12&quot; 5.7.3 Converter data em nome por extenso do mês Dado um vetor de meses, podemos gerar o mês não como número, mas com seu nome. vetor_meses = c(1,4,7,3,2,12,6) library(lubridate) # carregando o pacote lubridate ## ## Attaching package: &#39;lubridate&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## date, intersect, setdiff, union # o locale pode ser que funcione com o valor &#39;pt_BR&#39; Meses &lt;- month(as.numeric(vetor_meses), label = TRUE, # produz os meses locale = &quot;pt_BR.utf8&quot;) # lingua Meses ## [1] jan abr jul mar fev dez jun ## 12 Levels: jan &lt; fev &lt; mar &lt; abr &lt; mai &lt; jun &lt; jul &lt; ago &lt; set &lt; ... &lt; dez # De modo resumido lubridate::month(as.numeric(vetor_meses), label = TRUE, locale = &quot;pt_BR.utf8&quot;) ## [1] jan abr jul mar fev dez jun ## 12 Levels: jan &lt; fev &lt; mar &lt; abr &lt; mai &lt; jun &lt; jul &lt; ago &lt; set &lt; ... &lt; dez Fazendo o caminho inverso, supondo que tenhamos um vetor com nome dos meses e queiramos colocá-los em formato data dataPorExtenso &lt;- c(&#39;12 agosto 2020&#39;, &#39;17 dezembro 2021&#39;) as.Date(dataPorExtenso, format = &quot;%d %B %Y&quot;) ## [1] &quot;2020-08-12&quot; &quot;2021-12-17&quot; Dicas Tutorial do Lubridate em português do Curso-R Manipulação de Dados. Podemos trabalhar com outros formatos de datas Documentation Lubridate Video Youtube Como trabalhar com Data e Hora na linguagem R "],["normalização-de-texto-e-expressões-regulares.html", "6 Normalização de texto e Expressões Regulares 6.1 Expressões regulares (RegEx) 6.2 RegEx no R 6.3 Pacote stringr 6.4 Dicas/Sugestões: Regex no R", " 6 Normalização de texto e Expressões Regulares Objetivos deste capítulo: Apresentar as expressões regulares (regex) Apresentar comandos regex no R A normalização de texto consiste em converter texto para formatos mais padronizados, e expressões regulares, ou “regex” são uma ferramenta importante neste processo. A normalização de texto, a limpeza dos dados, sua reestruturação no formato necessário pode tomar a maior parte do tempo em um projeto. Vamos partir de um problema inicial. Quem quiser saber sobre uso de remédios como azitromicina, ivermectina e cloroquina em pacientes com “síndrome respiratória aguda grave”, podemos baixar a tabela csv do opendatasus e olhar a coluna “OUT_ANTIV”. Lá vemos que não há padronização, os dados estão bagunçados (ou “messy data”). Por exemplo, “azitromicina” foi escrita também como “azitronicina”,“az” “azt”, “azitro”, isto é, além de abreviações diferentes, há erros de ortografia. Em casos assim, expressões regulares podem ajudar a normalizar este campo, isto é, deixando tudo num mesmo padrão. Esta parte de limpeza, padronização, também chamada de cleaning e data wrangling (algo como “manipulação de dados”) consome boa parte do tempo “É dito, frequentemente, que 80% da análise de dados é gasto no processo de limpeza e preparação dos dados. A preparação dos dados é não só o primeiro passo, como deve ser repetido tantas vezes no curso da análise na medida que novos problemas aparecem ou novos dados são coletados.” It is often said that 80% of data analysis is spent on the process of cleaning and preparing the data (Dasu and Johnson 2003). Data preparation is not just a first step, but must be repeated many times over the course of analysis as new problems come to light or new datais collected. fonte: WICKHAM, Hadley. Tidy Data. Journal of Statistical Software. August 2014, Volume 59, Issue 10 Apesar desse número “80%” parecer ser ficcioso, ou que varie conforme as condições e destreza do pesquisador (veja aqui), não deixa de ser uma verdade que grande parte do tempo é gasto neste processo e processo de arrumar e rearrumar os dados. 6.1 Expressões regulares (RegEx) Certa vez Jamie Zawinski fez uma piada sobre regex que se tornou bastante conhecida ao se mencioar regex: Algumas pessoas, ao se defrontarem com um problema, pensam “Acho que vou usar expressões regulares”. Agora elas tem dois problemas. Talvez um pouco exagerada a piada, expressões regulares podem ser um pouco difíceis no início, mas depois que se aprende, fica difícil viver sem elas. Em editores de texto como Microsoft Word, OpenOffice, LibreOffice, GoogleDocs etc. é possível buscar por trechos de texto idênticos, é possível tornar a busca sensível a termos em maiúsculo e minúsculo. A busca utilizando regex permite isto e muito mais. Busca e subtituição com regex no Libre Office Calc Busca e subtituição com regex no Rstudio em Edit/Replace Find Regex trata-se de uma ferramenta coringa na hora de limpar ou transformar texto, estando presente nas mais diversas linguagens de programação, com sintaxe mais ou menos comum a todas elas. As expressões regulares (regular expressions), ou RegEx, RegExp, etc., mas mais conhecidas como regex, trata-se de busca e substituição avançada usando não só o texto exato, mas usando padrões de texto. Perguntas das expressões regulares: O quê? Números? Letras? Letras minúsculas ou maiúsculas? Palavras? Símbolos ou caracteres específicos? Quebras de linha? Tabulação? Quantas vezes? Um vez? Uma ou nenhuma? Uma ou várias vezes? Uma quantidade específica? Em regex chama-se isso de quantificadores. Onde? Antes ou de depois do quê? No início ou no fim da sentença? Em regex isso chama-se âncora. É possível delimitar a busca por letras específicas, por escopo de letras e/ou números, pode-se especificar a quantidade de caracteres, tirar ou acrescentar quebra de linha, acrescentar/retirar algo no início ou fim da linha. As regras do Regex são padronizadas em diversas linguagens de programação, apesar de algumas peculiaridades em cada uma, há uma gramática comum. Assim, aprendendo em uma linguagem, você aprendeu em outras.s Supondo que queira ter uma ferramenta simples de consulta do Qualis de revistas da área de sociologia. Baixando o relatório qualis capes de sociologia neste link é possível filtrar com base no nome ou na avaliação. Com regex podemos transformar uma tabela em csv Estado;sigla;capital;região; Acre;AC;Rio Branco;Norte; Alagoas;AL;Maceió;Nordeste; Amapá;AP;Macapá;Norte; Amazonas;AM;Manaus;Norte; Bahia;BA;Salvador;Nordeste; Ceará;CE;Fortaleza;Nordeste; para o formato de tabela em markdwon |Estado | sigla | capital| região| |------|----|-----|-----| |Acre |AC |Rio Branco |Norte| |Alagoas |AL |Maceió |Nordeste| |Amapá |AP |Macapá |Norte| |Amazonas |AM |Manaus |Norte| |Bahia |BA |Salvador |Nordeste| Com regex é possível fazer transformações, por exemplo, como pegar datas como “20/03/2020” ,“13/01/1990” ,“04/06/2001”, que estão no formado dd/mm/aaaa (dia/mês/ano) e mudá-las para outra disposição, como aaaa-mm-dd (ano/mês/dia), passando para “2020-03-20”, “1990-01-13”, “2001-06-04”. Há uma sessão nesse manual dedicada a manipulação de datas, com pacotes específicos. Vejamos os parâmetros que usamos com regex 6.1.1 Parâmetros das Regex 6.1.1.1 Metacaracteres especiais Alguns caracteres tem significado especial \\n usado para quebra de linha, ou “newline”. \\t caractere de tabulação. \\\\ para usar a própria barra \\r retorno de carro ou “carriage return”, que move o cursor para a próxima linha, mas sem aparecer em seu início. De uso no Windows. \\v tab vertical \\f form feed Destes, os mais comuns são o \\n, \\t, \\\\ e por vezes o \\r. 6.1.1.2 Âncoras símbolo descrição exemplo \\^a Início da string ^a busca “aaa aaa” a$ Fim da string a$ busca “aaaa aaa” \\b limite de palavra \\b[A-Za-z]\\b \\B NÃO limite de palavra \\\\&lt; Início de uma palavra \\\\&gt; Fim de uma palavra Exemplo de substituição com regex no Google Docs: acrescentou-se “Disse:” no início das células demarcadas 6.1.1.3 Operadores Descrição Exemplo . Pega um caractere único, qualquer um. Dado aba, abc, asa, a busca por ab. retorna aba, abc. A busca de a.. retorna aba, asa [..] Lista de caracteres, podendo usar a barra - para definir um escopo. Dado abcdefgh a busca por [a-d], retorna abcd [^..] Inversão do caso anterior. Pega todos os elementos, exceto os especificados ali Dado abcdefgh a busca por [^a-d], retorna efgh. | Operador booleano do tipo “ou”. Dado \"bananada, bananeira, bandolim\", a busca utilizando \"eira|dol\", retorna \"bananeira, bandolim\" (...) Agrupamento. É bastante usado com “backreference” Dado \"banana, bananada, bananeira\", a busca utilizando \"banan(ada|eira)\", retorna \"bananada, bananeira\" Podemos usar os colchetes [] para pegarmos um escopo. Se usamos [a-f], então nossa expressão pega qualquer coisa que contenha a,b,c,d,e, ou f, em minúscula. Assim, se quisermos pegar todas as letras minúsculas, usamos [a-z], se quisermos pegar todas as maiúsculas e minúsculas, usamos [A-Za-z]. Mas atenção, desta forma não detectamos caracteres acentuados, como “à”, “ç”, “ã”, etc. Para isso, acrescentamos à-ÿ que pega o escopo de caracteres acentuados. 6.1.1.4 Quantificadores Os quantificadores especificam quantas vezes o padrão anterior é repetido símbolo explicação exemplo * busca o item anterior zero ou mais vezes + busca o item anterior uma ou mais vezes ? o item anterior é opcional, e pode aparecer no máximo uma vez. O padrão bananas? encontra “banana” “bananas” “bananal” “bananada” {n} busca o item anterior exatamente n vezes {n,} busca o item anterior n vezes ou mais {n,m} busca o item anterior com no mínimo n vezes e com no máximo m vezes. (Faz sentido usálo com delimitadores como \\b) no_vec &lt;- c(\"no\", \"nono\", \"nonono\", \"nononono\", \"nonato\") grep(\"(no){2,3}\", no_vec, value=TRUE) [1] \"nono\" \"nonono\" \"nononono\" Os quantificadores podem ser combinados. Por exemplo: texto &lt;- &quot;O SR. PRESIDENTE (Omar Aziz. PSD - AM. Fala da Presidência.) – Os Srs. Senadores que as aprovam permaneçam como se encontram. (Pausa.)&quot; Possui dois textos entre parênteses. Assim se usarmos: stringr::str_extract(texto, &#39;\\\\(.*\\\\)&#39;) ## [1] &quot;(Omar Aziz. PSD - AM. Fala da Presidência.) – Os Srs. Senadores que as aprovam permaneçam como se encontram. (Pausa.)&quot; Pegamos o texto desde o primeiro parêntese até o último. Isto acontece por o símbolo de asterisco * ser “greedy” (voraz, guloso, segundo a terminologia de regex). Precisamos torná-lo “lazy” (preguiçoso) se quisermos pegar apenas o primeiro caso. O fazemos com a sequência de quantificadores *? stringr::str_extract(texto, &#39;\\\\(.*?\\\\)&#39;) ## [1] &quot;(Omar Aziz. PSD - AM. Fala da Presidência.)&quot; Exemplos: banana_vec &lt;- c(&quot;banana&quot;, &quot;bananas&quot;, &quot;bananal&quot;, &quot;bananada&quot;, &quot;bananeira&quot;, &quot;bandolim&quot;) grep(&quot;ban.*&quot;, banana_vec, value=T) ## [1] &quot;banana&quot; &quot;bananas&quot; &quot;bananal&quot; &quot;bananada&quot; &quot;bananeira&quot; &quot;bandolim&quot; grep(&quot;banan.*&quot;, banana_vec, value=T) ## [1] &quot;banana&quot; &quot;bananas&quot; &quot;bananal&quot; &quot;bananada&quot; &quot;bananeira&quot; grep(&quot;banana.*&quot;, banana_vec, value=T) ## [1] &quot;banana&quot; &quot;bananas&quot; &quot;bananal&quot; &quot;bananada&quot; grep(&quot;banana.?&quot;, banana_vec, value=TRUE) ## [1] &quot;banana&quot; &quot;bananas&quot; &quot;bananal&quot; &quot;bananada&quot; grep(&quot;banana.?$&quot;, banana_vec, value=TRUE) ## [1] &quot;banana&quot; &quot;bananas&quot; &quot;bananal&quot; # A sequência &quot;an&quot; pode aparecer uma ou mais vezes repetida, como &quot;ban&quot;, &quot;banan&quot;, &quot;bananan&quot;, &quot;banananan&quot;, etc. grep(&quot;b(an)+&quot;, banana_vec, value=T) ## [1] &quot;banana&quot; &quot;bananas&quot; &quot;bananal&quot; &quot;bananada&quot; &quot;bananeira&quot; &quot;bandolim&quot; grep(&quot;b[an]{2}&quot;, banana_vec, value=T) ## [1] &quot;banana&quot; &quot;bananas&quot; &quot;bananal&quot; &quot;bananada&quot; &quot;bananeira&quot; &quot;bandolim&quot; grep(&quot;b(an){2}&quot;, banana_vec, value=T) ## [1] &quot;banana&quot; &quot;bananas&quot; &quot;bananal&quot; &quot;bananada&quot; &quot;bananeira&quot; # se quiser delimitar a busca, restringindo a encontrar apenas o termo exato (exact match), deve-se usar o delimitador de palavra &quot;\\b&quot;. E para usá-lo aqui, deve-se acrescentar mais uma barra para o escape, ficando &quot;\\\\b&quot;. grep(&quot;\\\\bbanana\\\\b&quot;, banana_vec, value=T) ## [1] &quot;banana&quot; grep(&quot;\\\\bbanana.\\\\b&quot;, banana_vec, value=T) ## [1] &quot;bananas&quot; &quot;bananal&quot; A História do comando GREP: O comando grep exite graças à uma demanda da análise textual. Na década de 1960, um problema intrigava diversos pesquisadores. Quem são os autores de cada texto dos textos dos Federalistas? Os Federalist Papers foram 85 textos publicados de modo anônimo sob pseudônimo de “Publius”, podendo ser de autoria de James Madinson, Alexander Hamilton, John Jay em 1787 e 1788. Mas quem escreveu quais textos? Lee McMahon comentou deste problema com seus colegas. Ele queria buscar por certas palavras através de vários textos. Ken Thompson - personagem importante na história da programação - escutou aquilo e no dia seguinte voltou com o programa que veio a ser chamado grep: “g” de “Global”, procurar em vários documentos “re” de regular expressions “p” de print. Se achar o padrão de regex, então imprima na tela. Poderia ainda ser apagar, ou substituir também. O grep se tornou parte obrigatória do arcabouço computacional na programação em geral, principalmente nos sistemas baseados em Unix (Mac e Linux). Esta história foi contada em Where GREP Came From - Computerphile. Outros detalhes mais técnicos podem ser vistos aqui A identificação de autoria pelo padrão de escrita veio a ser chamado de “digitais linguísticas” (linguistic fingerprint). Posteriormente, um grupo de pesquisadores da Universidade de Aston usaram de técnica semelhante (porém mais avançada) para identificar a identidade real de Satoshi Nakamoto, criador do Bitcoin e da tecnologia de blockchain. 6.1.1.5 Escapando (escaping) Vimos que os símbolos [, ], (, ), {, }, os operadores *, +, ? ., |, - possuem um significado especial nas expressões regulares. E para usar estes mesmos símbolos literalmente? Para isto, usamos o “sescape”, usando uma barra \\ antes destes símbolos. Assim, se quisermos indicar o ponto final, usamos \\.. No caso do R, usamos barra dupla. O exemplo anterior ficaria \\\\.. 6.1.1.6 Classes POSIX POSIX Descrição Equivalente [:digit:] ou \\\\d Dígitos: 0 1 2 3 4 5 6 7 8 9. [0-9] [:lower:] letras em minúsculo (Lower-case) [a-z] [:upper:] Caracteres maiúsculos [A-Z] [:alpha:] Cracteres alfabéticos: [:lower:] and [:upper:]. [a-zA-Z] [:alnum:] ou \\w Caracteres alfanuméricos: [:alpha:] e [:digit:]. [a-zA-Z0-9] ou [A-z0-9] \\W Não palavra [^A-z0-9] [:blank:] Caracteres vazios, como espaço e tab. [:cntrl:] Caracteres de controle, como \\n, \\r, [\\x00-\\x1F\\x7F] [:graph:] Caracteres gráficos : [:alnum:] e [:punct:]. [:print:] Caracteres impimíveis: [:alnum:], [:punct:] and space. [:space:] Caracteres de espaço: tab \\t, nova linha \\n, tab vertical, form feed, carriage return \\r, espaço e outros similares [:xdigit:] Dígitos hexadecimais: 0 1 2 3 4 5 6 7 8 9 A B C D E F a b c d e f. \\s espaço em branco [ ] \\S (maiúsculo) tudo, exceto espaço em branco [^ ] [:punct:] Caracteres de pontuação: ! ” # $ % &amp; ’ ( ) * + , - . / : ; &lt; = &gt; ? @ [  ] ^ _ ` { } ~ . | Mas no R, para usar esta classe posix, deve-se reforçar as colchetes. Assim, para usarmos [:punct:] no R, devemos fazê-lo assim: [[:punct:]] 6.1.1.7 Backreference Podemos reaproveitar trechos através de backreference. Ao fazer substituições nos textos, um modo de delimitar ou reorganizar os elementos é feita com o uso de backreference. Indicamos o que queremos reutilizar com os parênteses, e reutilizamos através de numeração como ‘\\1’, ‘\\2’. nome &lt;- &quot;Fulano Silva&quot; gsub(&#39;(.*) (.*)&#39;, &#39;\\\\2,\\\\1.&#39;, nome) ## [1] &quot;Silva,Fulano.&quot; Onde \\\\0 indica toda a string, \\\\1 indica o primeiro caso, \\\\2 indica o segundo e assim por diante. 6.1.2 Dicas/Sugestões SICSS 2019 – Basic text analysis with grep. Video do YouTube do Summer Institute in Computational Social Science. https://www.rexegg.com/regex-quickstart.html 6.1.3 Indicação de leitura sobre Regex JURAFSKY, Dan.; MARTIN, James H.Regular Expressions, Text Normalization, Edit Distance in __ Speech and language processing: An introduction to speech recognition, computational linguistics and natural language processing. Upper Saddle River, NJ: Prentice Hall, 2020. Cap.2 p.2-28 FRIEDL, Jeffrey E. F. Mastering Regular Expressions, 3rd Edition. 2006. O’Reilly Media, Inc. ISBN: 9780596528126. Há opção free trial do livro. cheatsheet de expressões regulares (em inglês) Softwares Para lidar com dados bagunçados (“messy data”), uma sugestão é usar o OpenRefine. Antes “Google Refine”, mas após a Google abandonar o projeto, virou “Open Refine”, livre e de código aberto, ajuda a padronizar dados de tabelas, planilhas, limpando, corrigindo, filtrando (com regex), clusterizando ou transformando em outro formato. No site há tutoriais. Ele abre no seu navegador de internet, mas roda direto do seu computador. Usam esta ferramenta do OpenRefine, por exemplo, o Basômetro do Estadão Dados, que mede o apoio que o governo federal tem no legislativo e o ProPublica de jornalismo investigativo independente, No próprio site do OpenRefine há tutoriais e no ProPublica, ambos em inglês). 6.2 RegEx no R O uso de regex vem por padrão no R, no pacote base, mas há também uma expansão de regex com o pacote stringr usado para lidarmos com strings e tem uma sintaxe um pouco diferente. 6.2.1 Grep Como vimos, o grep serve para filtrar linhas que contenham algo que buscamos. Primeiro, vamos criar duas variáveis com texto. nosso_texto &lt;- &quot;Estamos aprendendo expressão regular no R. Bla bla bla no no no.&quot; poema &lt;- c(&quot;E agora, José?&quot;, &quot;A festa acabou,&quot; , &quot;a luz apagou,&quot;, &quot;o povo sumiu,&quot;, &quot;a noite esfriou&quot;, &quot;e agora, José?&quot;) Usaremos estas frases como exemplos a seguir: 6.2.1.1 grepl() Com o grepl(\"Termo\", Nome_variável) verificamos se uma expressão está presente em nosso texto e ele nos retorna booleanos TRUE(verdadeiro, termo encontrado) ou FALSE (falso, termo não encontrado). grepl(&quot;Estamos&quot;, nosso_texto) ## [1] TRUE grepl(&quot;paralelepípedo&quot;, nosso_texto) ## [1] FALSE grepl(&quot;festa&quot;, poema) ## [1] FALSE TRUE FALSE FALSE FALSE FALSE 6.2.1.2 grep(“padrão”, variável) Tendo várias linhas em um vetor, como por exemplo: grep(&quot;festa&quot;, poema) ## [1] 2 grep(&quot;José&quot;, poema) ## [1] 1 6 grep(&quot;josé&quot;, poema) ## integer(0) No primeiro e segundo exemplo, buscamos por “festa” e “José” e o R nos retornou o local do termo buscado no vetor. No terceiro exemplo, o termo “josé” - todo em minúsculo - não existia, e por isso o R retornou integer(0). Se quisermos ver as respectivas linhas, fazemos assim: poema[grep(&quot;José&quot;, poema)] ## [1] &quot;E agora, José?&quot; &quot;e agora, José?&quot; poema[grep(&quot;festa&quot;, poema)] ## [1] &quot;A festa acabou,&quot; Ou ainda, usando value = TRUE) para mostrar o texto encontrado, e não apenas o índice. grep(&quot;José&quot;, poema, value = TRUE) ## [1] &quot;E agora, José?&quot; &quot;e agora, José?&quot; grep(&quot;festa&quot;, poema, value = TRUE) ## [1] &quot;A festa acabou,&quot; O grep em sua versão completa no R, pode ter ainda as seguintes designações: &gt; grep(padrão, nome_variável, ignore.case = FALSE, perl = FALSE, value = FALSE, fixed = FALSE, useBytes = FALSE, invert = FALSE) Campo do grep Descrição padrão padrão regex a ser buscado nome_variável Nome da variável. Se o grep vier após um pipe (%&gt;%), é substituído por ponto . ignore.case = FALSE se ignore.case = TRUE , então a busca não distinguirá maiúscula de minúscula perl = FALSE usa o padrão Perl de regex value = FALSE Imprime os índices. Se TRUE, mostra os elementos. `| |fixed = FALSE| considera a busca como texto puro, sem nenhuma expressão regex| |useBytes = FALSE| seTRUEa busca é feita byte-a-byte ao invés de caractere a caractere| |invert = FALSE| Seinvert = TRUE`, então serão exibidas todas as linhas, exceto as que contenham o padrão buscado. https://stat.ethz.ch/R-manual/R-devel/library/base/html/grep.html 6.2.2 gsub() Se quisermos substituir trechos de nossa frase, usamos gsub(\"o que será retirado\", \"O que queremos colocar no lugar\", nome_variável) gsub(&quot;Bla&quot;, &quot;paralelepípedo&quot;, nosso_texto) ## [1] &quot;Estamos aprendendo expressão regular no R. paralelepípedo bla bla no no no.&quot; gsub(&quot;bla&quot;, &quot;paralelepípedo&quot;, nosso_texto) ## [1] &quot;Estamos aprendendo expressão regular no R. Bla paralelepípedo paralelepípedo no no no.&quot; Também podemos usar gsub para limpar nosso texto, colocando \"\" no campo intermediário da nossa função gsub. Por exemplo, se quisermos retirar os “no”: gsub(&quot;no&quot;, &quot;&quot;, nosso_texto) ## [1] &quot;Estamos aprendendo expressão regular R. Bla bla bla .&quot; Ou se quisermos retirar os “bla”: gsub(&quot;bla&quot;, &quot;&quot;, nosso_texto) ## [1] &quot;Estamos aprendendo expressão regular no R. Bla no no no.&quot; gsub(&quot;[bB]la&quot;, &quot;&quot;, nosso_texto) ## [1] &quot;Estamos aprendendo expressão regular no R. no no no.&quot; gsub(&quot;?&quot;, &quot;&quot;, poema) ## [1] &quot;E agora, José?&quot; &quot;A festa acabou,&quot; &quot;a luz apagou,&quot; &quot;o povo sumiu,&quot; ## [5] &quot;a noite esfriou&quot; &quot;e agora, José?&quot; gsub(&quot;,&quot;, &quot;&quot;, poema) ## [1] &quot;E agora José?&quot; &quot;A festa acabou&quot; &quot;a luz apagou&quot; &quot;o povo sumiu&quot; ## [5] &quot;a noite esfriou&quot; &quot;e agora José?&quot; A retirada da vírgula ocorreu normalmente. Já a interrogação continuou, uma vez que é um caractere usado com significado específico no regex. Devemos então indicar que se trata de uma interrogação comum. gsub(&quot;\\\\?&quot;, &quot;&quot;, poema) ## [1] &quot;E agora, José&quot; &quot;A festa acabou,&quot; &quot;a luz apagou,&quot; &quot;o povo sumiu,&quot; ## [5] &quot;a noite esfriou&quot; &quot;e agora, José&quot; E retirando também a vírgula: gsub(&quot;[\\\\?,]&quot;, &quot;&quot;, poema) ## [1] &quot;E agora José&quot; &quot;A festa acabou&quot; &quot;a luz apagou&quot; &quot;o povo sumiu&quot; ## [5] &quot;a noite esfriou&quot; &quot;e agora José&quot; 6.2.3 Exercício: Qual o Qualis de certas revistas? Quais revistas possuem certo Qualis? Vamos montar um script de busca dos Qualis de revistas de sociologia. Vasculhando a internet, encontrei uma lista com os Qualis das revistas de sociologia em pdf. Precisamos extrair a informação do pdf, precisamos dos pacotes pdftools e tidyverse. O comando pdf_text() do pacote pdf tools carrega tanto arquivos locais, em seu computador, como direto da internet. library(pdftools) ## Using poppler version 22.03.0 library(tidyverse) ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ── ## ✓ ggplot2 3.3.5 ✓ purrr 0.3.4 ## ✓ tibble 3.1.6 ✓ stringr 1.4.0 ## ✓ tidyr 1.2.0 ✓ forcats 0.5.1 ## ✓ readr 2.1.2 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## x lubridate::as.difftime() masks base::as.difftime() ## x lubridate::date() masks base::date() ## x dplyr::filter() masks stats::filter() ## x lubridate::intersect() masks base::intersect() ## x dplyr::lag() masks stats::lag() ## x lubridate::setdiff() masks base::setdiff() ## x lubridate::union() masks base::union() # O endereço de nosso pdf PDF.url = &quot;https://www2.ufjf.br/ppgcso/wp-content/uploads/sites/133/2015/04/1-Qualis-Sociologia-Atualizado.pdf&quot; # Carregando o conteúdo do pdf na mavriável &quot;meupdf&quot; meupdf &lt;- pdf_text(PDF.url) # Vamos checar se deu tudo certo, imprimindo apenas as primeiras linhas head(meupdf) ## [1] &quot; Consulta por Classificação / Área Avaliação\\nISSN TÍTULO ESTRATO ÁREA DE AVALIAÇÃO STATUS\\n0335-5322 Actes de la Recherche en Sciences Sociales A1 SOCIOLOGIA Atualizado\\n\\n0002-7294 American Anthropologist A1 SOCIOLOGIA Atualizado\\n\\n1042-0533 American Journal of Human Biology A1 SOCIOLOGIA Atualizado\\n\\n0003-2573 Análise Social A1 SOCIOLOGIA Atualizado\\n\\n1573-3416 An International Journal of Politics, Culture and Society (Dordrecht. Online) A1 SOCIOLOGIA Atualizado\\n\\n0004-0002 Archives of Sexual Behavior A1 SOCIOLOGIA Atualizado\\n\\n0261-3050 Bulletin of Latin American Research A1 SOCIOLOGIA Atualizado\\n\\n1983-8239 Caderno CRH (Online) A1 SOCIOLOGIA Atualizado\\n\\n0103-4979 Caderno CRH (UFBA. Impresso) A1 SOCIOLOGIA Atualizado\\n\\n0104-8333 Cadernos Pagu (UNICAMP. Impresso) A1 SOCIOLOGIA Atualizado\\n\\n0010-4159 Comparative Politics A1 SOCIOLOGIA Atualizado\\n\\n1351-0487 Constellations (Oxford. Print) A1 SOCIOLOGIA Atualizado\\n\\n0094-3061 Contemporary Sociology (Washington) A1 SOCIOLOGIA Atualizado\\n\\n1354-067X Culture &amp; Psychology A1 SOCIOLOGIA Atualizado\\n\\n0011-3204 Current Anthropology A1 SOCIOLOGIA Atualizado\\n\\n0011-3921 Current Sociology (Print) A1 SOCIOLOGIA Atualizado\\n\\n0011-5258 Dados (Rio de Janeiro. Impresso) A1 SOCIOLOGIA Atualizado\\n\\n1351-0347 Democratization (London) A1 SOCIOLOGIA Atualizado\\n\\n0101-7330 Educação &amp; Sociedade (Impresso) A1 SOCIOLOGIA Atualizado\\n\\n1044-3983 Epidemiology (Cambridge, Mass., Print) A1 SOCIOLOGIA Atualizado\\n\\n0185-4186 Estudios Sociológicos A1 SOCIOLOGIA Atualizado\\n\\n0141-9870 Ethnic and Racial Studies (Print) A1 SOCIOLOGIA Atualizado\\n\\n0873-6561 Etnográfica (Lisboa A1 SOCIOLOGIA Atualizado\\n\\n\\n\\n 1 Quarta-feira 04 Fevereiro 2015 18:33:10\\n&quot; ## [2] &quot;ISSN TÍTULO ESTRATO ÁREA DE AVALIAÇÃO STATUS\\n0014-2182 Etudes Rurales A1 SOCIOLOGIA Atualizado\\n\\n1368-4310 European Journal of Social Theory A1 SOCIOLOGIA Atualizado\\n\\n0104-5970 História, Ciências, Saúde-Manguinhos (Impresso) A1 SOCIOLOGIA Atualizado\\n\\n1678-4758 História, Ciências, Saúde-Manguinhos (Online) A1 SOCIOLOGIA Atualizado\\n\\n1806-9983 Horizontes Antropológicos (Online) A1 SOCIOLOGIA Atualizado\\n\\n0104-7183 Horizontes Antropológicos (UFRGS. Impresso) A1 SOCIOLOGIA Atualizado\\n\\n0539-0184 Information sur les Sciences Sociales (Paris) A1 SOCIOLOGIA Atualizado\\n\\n0891-4486 International Journal of Politics, Culture and Society A1 SOCIOLOGIA Atualizado\\n\\n2182-4096 International Journal on Working Conditions A1 SOCIOLOGIA Atualizado\\n\\n0192-5121 International Political Science Review A1 SOCIOLOGIA Atualizado\\n\\n0269-2171 International Review of Applied Economics A1 SOCIOLOGIA Atualizado\\n\\n0020-8701 International Social Science Journal (Print) A1 SOCIOLOGIA Atualizado\\n\\n0268-5809 International Sociology A1 SOCIOLOGIA Atualizado\\n\\n1468-795X Journal of Classical Sociology A1 SOCIOLOGIA Atualizado\\n\\n1467-6443 Journal of Historical Sociology (Online) A1 SOCIOLOGIA Atualizado\\n\\n0022-216X Journal of Latin American Studies (Print) A1 SOCIOLOGIA Atualizado\\n\\n0022-4537 Journal of Social Issues (Print) A1 SOCIOLOGIA Atualizado\\n\\n0094-582X Latin American Perspectives A1 SOCIOLOGIA Atualizado\\n\\n0023-8791 Latin American Research Review A1 SOCIOLOGIA Atualizado\\n\\n0102-6445 Lua Nova (Impresso) A1 SOCIOLOGIA Atualizado\\n\\n1678-4944 Mana (Rio de Janeiro. Online) A1 SOCIOLOGIA Atualizado\\n\\n0104-9313 Mana (UFRJ. Impresso) A1 SOCIOLOGIA Atualizado\\n\\n0101-3300 Novos Estudos CEBRAP (Impresso) A1 SOCIOLOGIA Atualizado\\n\\n0102-4469 Perspectiva Teológica (Belo Horizonte) A1 SOCIOLOGIA Atualizado\\n\\n\\n\\n 2 Quarta-feira 04 Fevereiro 2015 18:33:10\\n&quot; ## [3] &quot;ISSN TÍTULO ESTRATO ÁREA DE AVALIAÇÃO STATUS\\n0048-3931 Philosophy of the Social Sciences A1 SOCIOLOGIA Atualizado\\n\\n0191-4537 Philosophy &amp; Social Criticism A1 SOCIOLOGIA Atualizado\\n\\n0276-5624 Research in Social Stratification and Mobility A1 SOCIOLOGIA Atualizado\\n\\n0048-7333 Research Policy A1 SOCIOLOGIA Atualizado\\n\\n0102-6909 Revista Brasileira de Ciências Sociais (Impresso) A1 SOCIOLOGIA Atualizado\\n\\n0254-1106 Revista Crítica de Ciências Sociais A1 SOCIOLOGIA Atualizado\\n\\n0034-7701 Revista de Antropologia (USP. Impresso) A1 SOCIOLOGIA Atualizado\\n\\n0188-2503 Revista Mexicana de SociologÍa A1 SOCIOLOGIA Atualizado\\n\\n0390-6701 Revue Internationale de Sociologie A1 SOCIOLOGIA Atualizado\\n\\n0037-7686 Social Compass (Imprimé) A1 SOCIOLOGIA Atualizado\\n\\n0037-7732 Social Forces A1 SOCIOLOGIA Atualizado\\n\\n0303-8300 Social Indicators Research A1 SOCIOLOGIA Atualizado\\n\\n0277-9536 Social Science &amp; Medicine (1982) A1 SOCIOLOGIA Atualizado\\n\\n0102-6992 Sociedade e Estado (UnB. Impresso) A1 SOCIOLOGIA Atualizado\\n\\n0038-0199 Sociologia Ruralis (Print) A1 SOCIOLOGIA Atualizado\\n\\n1517-4522 Sociologias (UFRGS. Impresso) A1 SOCIOLOGIA Atualizado\\n\\n0735-2751 Sociological Theory A1 SOCIOLOGIA Atualizado\\n\\n0038-0296 Sociologie du Travail A1 SOCIOLOGIA Atualizado\\n\\n1069-4404 Sociology of Religion A1 SOCIOLOGIA Atualizado\\n\\n0340-918X Soziologie (Opladen) A1 SOCIOLOGIA Atualizado\\n\\n0103-2070 Tempo Social (USP. Impresso) A1 SOCIOLOGIA Atualizado\\n\\n0002-7162 The Annals of the American Academy of Political and Social Science A1 SOCIOLOGIA Atualizado\\n\\n0263-2764 Theory, Culture &amp; Society A1 SOCIOLOGIA Atualizado\\n\\n0725-5136 Thesis Eleven (Print) A1 SOCIOLOGIA Atualizado\\n\\n\\n\\n 3 Quarta-feira 04 Fevereiro 2015 18:33:10\\n&quot; ## [4] &quot;ISSN TÍTULO ESTRATO ÁREA DE AVALIAÇÃO STATUS\\n0730-8884 Work and Occupations A1 SOCIOLOGIA Atualizado\\n\\n0305-750X World Development A1 SOCIOLOGIA Atualizado\\n\\n0954-0121 Aids Care (Print) A2 SOCIOLOGIA Atualizado\\n\\n0889-2229 AIDS Research and Human Retroviruses A2 SOCIOLOGIA Atualizado\\n\\n1414-753X Ambiente e Sociedade (Campinas) A2 SOCIOLOGIA Atualizado\\n\\n1809-4422 Ambiente &amp; Sociedade (Online) A2 SOCIOLOGIA Atualizado\\n\\n0044-7447 Ambio (Oslo) A2 SOCIOLOGIA Atualizado\\n\\n1130-2887 América Latina Hoy A2 SOCIOLOGIA Atualizado\\n\\n0161-7761 Anthropology &amp; Education Quarterly A2 SOCIOLOGIA Atualizado\\n\\n0210-1963 Arbor (Madrid) A2 SOCIOLOGIA Atualizado\\n\\n0863-1808 Berliner Journal fur Soziologie A2 SOCIOLOGIA Atualizado\\n\\n0102-311X Cadernos de Saúde Pública (ENSP. Impresso) A2 SOCIOLOGIA Atualizado\\n\\n1298-6046 Cahiers du Genre (Paris) A2 SOCIOLOGIA Atualizado\\n\\n0008-0276 Cahiers Internationaux de Sociologie A2 SOCIOLOGIA Atualizado\\n\\n0826-3663 Canadian Journal of Latin American and Caribbean Studies A2 SOCIOLOGIA Atualizado\\n\\n1188-3774 Canadian Journal of Urban Research A2 SOCIOLOGIA Atualizado\\n\\n0309-8168 Capital &amp; Class A2 SOCIOLOGIA Atualizado\\n\\n0341-8162 Catena (Cremlingen) A2 SOCIOLOGIA Atualizado\\n\\n1519-6089 Civitas: Revista de Ciências Sociais (Impresso) A2 SOCIOLOGIA Atualizado\\n\\n0010-4086 Comparative Education Review A2 SOCIOLOGIA Atualizado\\n\\n0360-1315 Computers and Education A2 SOCIOLOGIA Atualizado\\n\\n0102-8529 Contexto Internacional (PUCRJ. Impresso) A2 SOCIOLOGIA Atualizado\\n\\n1478-0046 Cultural and Social History (Online) A2 SOCIOLOGIA Atualizado\\n\\n0419-1633 Diogène (Ed. Française) A2 SOCIOLOGIA Atualizado\\n\\n\\n\\n 4 Quarta-feira 04 Fevereiro 2015 18:33:10\\n&quot; ## [5] &quot;ISSN TÍTULO ESTRATO ÁREA DE AVALIAÇÃO STATUS\\n0392-1921 Diogenes (English ed.) A2 SOCIOLOGIA Atualizado\\n\\n1362-024X Durkheimian Studies A2 SOCIOLOGIA Atualizado\\n\\n0921-8009 Ecological Economics (Amsterdam) A2 SOCIOLOGIA Atualizado\\n\\n0143-831X Economic and Industrial Democracy A2 SOCIOLOGIA Atualizado\\n\\n0142-5455 Employee Relations A2 SOCIOLOGIA Atualizado\\n\\n0104-4036 Ensaio (Fundação Cesgranrio. Impresso) A2 SOCIOLOGIA Atualizado\\n\\n0014-1844 Ethnos (Stockholm) A2 SOCIOLOGIA Atualizado\\n\\n0015-704X Fordham Law Review A2 SOCIOLOGIA Atualizado\\n\\n0016-3287 Futures (London) A2 SOCIOLOGIA Atualizado\\n\\n0197-3975 Habitat International A2 SOCIOLOGIA Atualizado\\n\\n1468-2737 Hispanic Research Journal A2 SOCIOLOGIA Atualizado\\n\\n0018-7615 Humboldt (Spanische Ausg.) A2 SOCIOLOGIA Atualizado\\n\\n0265-5012 IDS Bulletin (Brighton. 1984) A2 SOCIOLOGIA Atualizado\\n\\n0306-4379 Information Systems (Oxford) A2 SOCIOLOGIA Atualizado\\n\\n1469-8412 Innovation: The European Journal of Social Science Research A2 SOCIOLOGIA Atualizado\\n\\n0034-9690 Interamerican Journal of Psychology A2 SOCIOLOGIA Atualizado\\n\\n1861-1303 International Journal of Action Research A2 SOCIOLOGIA Atualizado\\n\\n0020-8523 International Review of Administrative Sciences A2 SOCIOLOGIA Atualizado\\n\\n0037-9174 Journal de la Société des Américanistes A2 SOCIOLOGIA Atualizado\\n\\n1471-0358 Journal of Agrarian Change (Print) A2 SOCIOLOGIA Atualizado\\n\\n0168-7034 Journal of Consumer Policy A2 SOCIOLOGIA Atualizado\\n\\n1353-7903 Journal of Contemporary Religion A2 SOCIOLOGIA Atualizado\\n\\n1533-7928 Journal of Machine Learning Research (Online) A2 SOCIOLOGIA Atualizado\\n\\n0306-6150 Journal of Peasant Studies A2 SOCIOLOGIA Atualizado\\n\\n\\n\\n 5 Quarta-feira 04 Fevereiro 2015 18:33:10\\n&quot; ## [6] &quot;ISSN TÍTULO ESTRATO ÁREA DE AVALIAÇÃO STATUS\\n0047-2697 Journal of Political &amp; Military Sociology A2 SOCIOLOGIA Atualizado\\n\\n1053-1858 Journal of Public Administration Research and Theory A2 SOCIOLOGIA Atualizado\\n\\n0022-4200 Journal of Religion in Africa (Print) A2 SOCIOLOGIA Atualizado\\n\\n0022-4529 Journal of Social History A2 SOCIOLOGIA Atualizado\\n\\n1744-2222 Latin American and Caribbean Ethnic Studies (Print) A2 SOCIOLOGIA Atualizado\\n\\n1531-426X Latin American Politics and Society A2 SOCIOLOGIA Atualizado\\n\\n0439-4216 L&#39;Homme (Paris. 1961) A2 SOCIOLOGIA Atualizado\\n\\n0024-7413 Luso-Brazilian Review A2 SOCIOLOGIA Atualizado\\n\\n1548-9957 Luso-Brazilian Review (Online) A2 SOCIOLOGIA Atualizado\\n\\n1240-1307 Natures Sciences Sociétés A2 SOCIOLOGIA Atualizado\\n\\n0028-6060 New Left Review A2 SOCIOLOGIA Atualizado\\n\\n1461-4448 New Media &amp; Society (Print) A2 SOCIOLOGIA Atualizado\\n\\n0251-3552 Nueva Sociedad A2 SOCIOLOGIA Atualizado\\n\\n0104-6276 Opinião Pública (UNICAMP. Impresso) A2 SOCIOLOGIA Atualizado\\n\\n0146-1672 Personality &amp; Social Psychology Bulletin A2 SOCIOLOGIA Atualizado\\n\\n1203-9438 Politique et Sociétés (Montréal) A2 SOCIOLOGIA Atualizado\\n\\n0032-471X Population Review (Print) A2 SOCIOLOGIA Atualizado\\n\\n1544-8444 Population, Space and Place A2 SOCIOLOGIA Atualizado\\n\\n0102-7972 Psicologia: Reflexão e Crítica (UFRGS. Impresso) A2 SOCIOLOGIA Atualizado\\n\\n0963-6625 Public Understanding of Science (Print) A2 SOCIOLOGIA Atualizado\\n\\n0100-8587 Religião &amp; Sociedade (Impresso) A2 SOCIOLOGIA Atualizado\\n\\n0968-8080 Reproductive Health Matters (Print) A2 SOCIOLOGIA Atualizado\\n\\n0102-3098 Revista Brasileira de Estudos de População (Impresso) A2 SOCIOLOGIA Atualizado\\n\\n1806-9347 Revista Brasileira de História (Online) A2 SOCIOLOGIA Atualizado\\n\\n\\n\\n 6 Quarta-feira 04 Fevereiro 2015 18:33:10\\n&quot; Vamos filtrar a tabela; toda linha que tiver “Soziol” irá aparecer na nossa busca. (escolhi este nome por gerar poucos resultados e não encher nossa tela) grep(&quot;Soziolo&quot;, meupdf, value=T) ## [1] &quot;ISSN TÍTULO ESTRATO ÁREA DE AVALIAÇÃO STATUS\\n0048-3931 Philosophy of the Social Sciences A1 SOCIOLOGIA Atualizado\\n\\n0191-4537 Philosophy &amp; Social Criticism A1 SOCIOLOGIA Atualizado\\n\\n0276-5624 Research in Social Stratification and Mobility A1 SOCIOLOGIA Atualizado\\n\\n0048-7333 Research Policy A1 SOCIOLOGIA Atualizado\\n\\n0102-6909 Revista Brasileira de Ciências Sociais (Impresso) A1 SOCIOLOGIA Atualizado\\n\\n0254-1106 Revista Crítica de Ciências Sociais A1 SOCIOLOGIA Atualizado\\n\\n0034-7701 Revista de Antropologia (USP. Impresso) A1 SOCIOLOGIA Atualizado\\n\\n0188-2503 Revista Mexicana de SociologÍa A1 SOCIOLOGIA Atualizado\\n\\n0390-6701 Revue Internationale de Sociologie A1 SOCIOLOGIA Atualizado\\n\\n0037-7686 Social Compass (Imprimé) A1 SOCIOLOGIA Atualizado\\n\\n0037-7732 Social Forces A1 SOCIOLOGIA Atualizado\\n\\n0303-8300 Social Indicators Research A1 SOCIOLOGIA Atualizado\\n\\n0277-9536 Social Science &amp; Medicine (1982) A1 SOCIOLOGIA Atualizado\\n\\n0102-6992 Sociedade e Estado (UnB. Impresso) A1 SOCIOLOGIA Atualizado\\n\\n0038-0199 Sociologia Ruralis (Print) A1 SOCIOLOGIA Atualizado\\n\\n1517-4522 Sociologias (UFRGS. Impresso) A1 SOCIOLOGIA Atualizado\\n\\n0735-2751 Sociological Theory A1 SOCIOLOGIA Atualizado\\n\\n0038-0296 Sociologie du Travail A1 SOCIOLOGIA Atualizado\\n\\n1069-4404 Sociology of Religion A1 SOCIOLOGIA Atualizado\\n\\n0340-918X Soziologie (Opladen) A1 SOCIOLOGIA Atualizado\\n\\n0103-2070 Tempo Social (USP. Impresso) A1 SOCIOLOGIA Atualizado\\n\\n0002-7162 The Annals of the American Academy of Political and Social Science A1 SOCIOLOGIA Atualizado\\n\\n0263-2764 Theory, Culture &amp; Society A1 SOCIOLOGIA Atualizado\\n\\n0725-5136 Thesis Eleven (Print) A1 SOCIOLOGIA Atualizado\\n\\n\\n\\n 3 Quarta-feira 04 Fevereiro 2015 18:33:10\\n&quot; ## [2] &quot;ISSN TÍTULO ESTRATO ÁREA DE AVALIAÇÃO STATUS\\n0730-8884 Work and Occupations A1 SOCIOLOGIA Atualizado\\n\\n0305-750X World Development A1 SOCIOLOGIA Atualizado\\n\\n0954-0121 Aids Care (Print) A2 SOCIOLOGIA Atualizado\\n\\n0889-2229 AIDS Research and Human Retroviruses A2 SOCIOLOGIA Atualizado\\n\\n1414-753X Ambiente e Sociedade (Campinas) A2 SOCIOLOGIA Atualizado\\n\\n1809-4422 Ambiente &amp; Sociedade (Online) A2 SOCIOLOGIA Atualizado\\n\\n0044-7447 Ambio (Oslo) A2 SOCIOLOGIA Atualizado\\n\\n1130-2887 América Latina Hoy A2 SOCIOLOGIA Atualizado\\n\\n0161-7761 Anthropology &amp; Education Quarterly A2 SOCIOLOGIA Atualizado\\n\\n0210-1963 Arbor (Madrid) A2 SOCIOLOGIA Atualizado\\n\\n0863-1808 Berliner Journal fur Soziologie A2 SOCIOLOGIA Atualizado\\n\\n0102-311X Cadernos de Saúde Pública (ENSP. Impresso) A2 SOCIOLOGIA Atualizado\\n\\n1298-6046 Cahiers du Genre (Paris) A2 SOCIOLOGIA Atualizado\\n\\n0008-0276 Cahiers Internationaux de Sociologie A2 SOCIOLOGIA Atualizado\\n\\n0826-3663 Canadian Journal of Latin American and Caribbean Studies A2 SOCIOLOGIA Atualizado\\n\\n1188-3774 Canadian Journal of Urban Research A2 SOCIOLOGIA Atualizado\\n\\n0309-8168 Capital &amp; Class A2 SOCIOLOGIA Atualizado\\n\\n0341-8162 Catena (Cremlingen) A2 SOCIOLOGIA Atualizado\\n\\n1519-6089 Civitas: Revista de Ciências Sociais (Impresso) A2 SOCIOLOGIA Atualizado\\n\\n0010-4086 Comparative Education Review A2 SOCIOLOGIA Atualizado\\n\\n0360-1315 Computers and Education A2 SOCIOLOGIA Atualizado\\n\\n0102-8529 Contexto Internacional (PUCRJ. Impresso) A2 SOCIOLOGIA Atualizado\\n\\n1478-0046 Cultural and Social History (Online) A2 SOCIOLOGIA Atualizado\\n\\n0419-1633 Diogène (Ed. Française) A2 SOCIOLOGIA Atualizado\\n\\n\\n\\n 4 Quarta-feira 04 Fevereiro 2015 18:33:10\\n&quot; ## [3] &quot;ISSN TÍTULO ESTRATO ÁREA DE AVALIAÇÃO STATUS\\n0034-8910 Revista de Saúde Pública (Impresso) A2 SOCIOLOGIA Atualizado\\n\\n1518-8787 Revista de Saúde Pública (Online) A2 SOCIOLOGIA Atualizado\\n\\n1678-9873 Revista de Sociologia e Política (Online) A2 SOCIOLOGIA Atualizado\\n\\n0104-4478 Revista de Sociologia e Política (UFPR. Impresso) A2 SOCIOLOGIA Atualizado\\n\\n0104-026X Revista Estudos Feministas (UFSC. Impresso) A2 SOCIOLOGIA Atualizado\\n\\n0378-5548 Revista Internacional del Trabajo (Impresa) A2 SOCIOLOGIA Atualizado\\n\\n0034-9712 Revista Internacional de Sociología A2 SOCIOLOGIA Atualizado\\n\\n1293-8882 Revue Tiers Monde A2 SOCIOLOGIA Atualizado\\n\\n1363-4607 Sexualities (London) A2 SOCIOLOGIA Atualizado\\n\\n0097-9740 Signs (Chicago, Ill.) A2 SOCIOLOGIA Atualizado\\n\\n1350-4630 Social Identities (Print) A2 SOCIOLOGIA Atualizado\\n\\n0765-3697 Sociétés (Paris) A2 SOCIOLOGIA Atualizado\\n\\n0210-8364 Sociología del Trabajo A2 SOCIOLOGIA Atualizado\\n\\n2152-8586 South African Review of Sociology A2 SOCIOLOGIA Atualizado\\n\\n1654-0204 Stockholm Review of Latin American Studies A2 SOCIOLOGIA Atualizado\\n\\n1477-7487 Surveillance &amp; Society (Online) A2 SOCIOLOGIA Atualizado\\n\\n0730-479X The Tocqueville Review A2 SOCIOLOGIA Atualizado\\n\\n0143-6597 Third World Quarterly (Print) A2 SOCIOLOGIA Atualizado\\n\\n1745-641X Work Organisation, Labour &amp; Globalisation (Print) A2 SOCIOLOGIA Atualizado\\n\\n1935-6226 World Political Science Review A2 SOCIOLOGIA Atualizado\\n\\n0340-1804 Zeitschrift fur Soziologie A2 SOCIOLOGIA Atualizado\\n\\n0994-4524 Actuel Marx B1 SOCIOLOGIA Atualizado\\n\\n0095-3997 Administration &amp; Society B1 SOCIOLOGIA Atualizado\\n\\n1057-6290 Advances in Medical Sociology B1 SOCIOLOGIA Atualizado\\n\\n\\n\\n 7 Quarta-feira 04 Fevereiro 2015 18:33:10\\n&quot; Filtrando a tabela, toda linha que tiver “A1” irá aparecer, não importa em que coluna esteja. grep(&quot;A1&quot;, meupdf, value=T) ## [1] &quot; Consulta por Classificação / Área Avaliação\\nISSN TÍTULO ESTRATO ÁREA DE AVALIAÇÃO STATUS\\n0335-5322 Actes de la Recherche en Sciences Sociales A1 SOCIOLOGIA Atualizado\\n\\n0002-7294 American Anthropologist A1 SOCIOLOGIA Atualizado\\n\\n1042-0533 American Journal of Human Biology A1 SOCIOLOGIA Atualizado\\n\\n0003-2573 Análise Social A1 SOCIOLOGIA Atualizado\\n\\n1573-3416 An International Journal of Politics, Culture and Society (Dordrecht. Online) A1 SOCIOLOGIA Atualizado\\n\\n0004-0002 Archives of Sexual Behavior A1 SOCIOLOGIA Atualizado\\n\\n0261-3050 Bulletin of Latin American Research A1 SOCIOLOGIA Atualizado\\n\\n1983-8239 Caderno CRH (Online) A1 SOCIOLOGIA Atualizado\\n\\n0103-4979 Caderno CRH (UFBA. Impresso) A1 SOCIOLOGIA Atualizado\\n\\n0104-8333 Cadernos Pagu (UNICAMP. Impresso) A1 SOCIOLOGIA Atualizado\\n\\n0010-4159 Comparative Politics A1 SOCIOLOGIA Atualizado\\n\\n1351-0487 Constellations (Oxford. Print) A1 SOCIOLOGIA Atualizado\\n\\n0094-3061 Contemporary Sociology (Washington) A1 SOCIOLOGIA Atualizado\\n\\n1354-067X Culture &amp; Psychology A1 SOCIOLOGIA Atualizado\\n\\n0011-3204 Current Anthropology A1 SOCIOLOGIA Atualizado\\n\\n0011-3921 Current Sociology (Print) A1 SOCIOLOGIA Atualizado\\n\\n0011-5258 Dados (Rio de Janeiro. Impresso) A1 SOCIOLOGIA Atualizado\\n\\n1351-0347 Democratization (London) A1 SOCIOLOGIA Atualizado\\n\\n0101-7330 Educação &amp; Sociedade (Impresso) A1 SOCIOLOGIA Atualizado\\n\\n1044-3983 Epidemiology (Cambridge, Mass., Print) A1 SOCIOLOGIA Atualizado\\n\\n0185-4186 Estudios Sociológicos A1 SOCIOLOGIA Atualizado\\n\\n0141-9870 Ethnic and Racial Studies (Print) A1 SOCIOLOGIA Atualizado\\n\\n0873-6561 Etnográfica (Lisboa A1 SOCIOLOGIA Atualizado\\n\\n\\n\\n 1 Quarta-feira 04 Fevereiro 2015 18:33:10\\n&quot; ## [2] &quot;ISSN TÍTULO ESTRATO ÁREA DE AVALIAÇÃO STATUS\\n0014-2182 Etudes Rurales A1 SOCIOLOGIA Atualizado\\n\\n1368-4310 European Journal of Social Theory A1 SOCIOLOGIA Atualizado\\n\\n0104-5970 História, Ciências, Saúde-Manguinhos (Impresso) A1 SOCIOLOGIA Atualizado\\n\\n1678-4758 História, Ciências, Saúde-Manguinhos (Online) A1 SOCIOLOGIA Atualizado\\n\\n1806-9983 Horizontes Antropológicos (Online) A1 SOCIOLOGIA Atualizado\\n\\n0104-7183 Horizontes Antropológicos (UFRGS. Impresso) A1 SOCIOLOGIA Atualizado\\n\\n0539-0184 Information sur les Sciences Sociales (Paris) A1 SOCIOLOGIA Atualizado\\n\\n0891-4486 International Journal of Politics, Culture and Society A1 SOCIOLOGIA Atualizado\\n\\n2182-4096 International Journal on Working Conditions A1 SOCIOLOGIA Atualizado\\n\\n0192-5121 International Political Science Review A1 SOCIOLOGIA Atualizado\\n\\n0269-2171 International Review of Applied Economics A1 SOCIOLOGIA Atualizado\\n\\n0020-8701 International Social Science Journal (Print) A1 SOCIOLOGIA Atualizado\\n\\n0268-5809 International Sociology A1 SOCIOLOGIA Atualizado\\n\\n1468-795X Journal of Classical Sociology A1 SOCIOLOGIA Atualizado\\n\\n1467-6443 Journal of Historical Sociology (Online) A1 SOCIOLOGIA Atualizado\\n\\n0022-216X Journal of Latin American Studies (Print) A1 SOCIOLOGIA Atualizado\\n\\n0022-4537 Journal of Social Issues (Print) A1 SOCIOLOGIA Atualizado\\n\\n0094-582X Latin American Perspectives A1 SOCIOLOGIA Atualizado\\n\\n0023-8791 Latin American Research Review A1 SOCIOLOGIA Atualizado\\n\\n0102-6445 Lua Nova (Impresso) A1 SOCIOLOGIA Atualizado\\n\\n1678-4944 Mana (Rio de Janeiro. Online) A1 SOCIOLOGIA Atualizado\\n\\n0104-9313 Mana (UFRJ. Impresso) A1 SOCIOLOGIA Atualizado\\n\\n0101-3300 Novos Estudos CEBRAP (Impresso) A1 SOCIOLOGIA Atualizado\\n\\n0102-4469 Perspectiva Teológica (Belo Horizonte) A1 SOCIOLOGIA Atualizado\\n\\n\\n\\n 2 Quarta-feira 04 Fevereiro 2015 18:33:10\\n&quot; ## [3] &quot;ISSN TÍTULO ESTRATO ÁREA DE AVALIAÇÃO STATUS\\n0048-3931 Philosophy of the Social Sciences A1 SOCIOLOGIA Atualizado\\n\\n0191-4537 Philosophy &amp; Social Criticism A1 SOCIOLOGIA Atualizado\\n\\n0276-5624 Research in Social Stratification and Mobility A1 SOCIOLOGIA Atualizado\\n\\n0048-7333 Research Policy A1 SOCIOLOGIA Atualizado\\n\\n0102-6909 Revista Brasileira de Ciências Sociais (Impresso) A1 SOCIOLOGIA Atualizado\\n\\n0254-1106 Revista Crítica de Ciências Sociais A1 SOCIOLOGIA Atualizado\\n\\n0034-7701 Revista de Antropologia (USP. Impresso) A1 SOCIOLOGIA Atualizado\\n\\n0188-2503 Revista Mexicana de SociologÍa A1 SOCIOLOGIA Atualizado\\n\\n0390-6701 Revue Internationale de Sociologie A1 SOCIOLOGIA Atualizado\\n\\n0037-7686 Social Compass (Imprimé) A1 SOCIOLOGIA Atualizado\\n\\n0037-7732 Social Forces A1 SOCIOLOGIA Atualizado\\n\\n0303-8300 Social Indicators Research A1 SOCIOLOGIA Atualizado\\n\\n0277-9536 Social Science &amp; Medicine (1982) A1 SOCIOLOGIA Atualizado\\n\\n0102-6992 Sociedade e Estado (UnB. Impresso) A1 SOCIOLOGIA Atualizado\\n\\n0038-0199 Sociologia Ruralis (Print) A1 SOCIOLOGIA Atualizado\\n\\n1517-4522 Sociologias (UFRGS. Impresso) A1 SOCIOLOGIA Atualizado\\n\\n0735-2751 Sociological Theory A1 SOCIOLOGIA Atualizado\\n\\n0038-0296 Sociologie du Travail A1 SOCIOLOGIA Atualizado\\n\\n1069-4404 Sociology of Religion A1 SOCIOLOGIA Atualizado\\n\\n0340-918X Soziologie (Opladen) A1 SOCIOLOGIA Atualizado\\n\\n0103-2070 Tempo Social (USP. Impresso) A1 SOCIOLOGIA Atualizado\\n\\n0002-7162 The Annals of the American Academy of Political and Social Science A1 SOCIOLOGIA Atualizado\\n\\n0263-2764 Theory, Culture &amp; Society A1 SOCIOLOGIA Atualizado\\n\\n0725-5136 Thesis Eleven (Print) A1 SOCIOLOGIA Atualizado\\n\\n\\n\\n 3 Quarta-feira 04 Fevereiro 2015 18:33:10\\n&quot; ## [4] &quot;ISSN TÍTULO ESTRATO ÁREA DE AVALIAÇÃO STATUS\\n0730-8884 Work and Occupations A1 SOCIOLOGIA Atualizado\\n\\n0305-750X World Development A1 SOCIOLOGIA Atualizado\\n\\n0954-0121 Aids Care (Print) A2 SOCIOLOGIA Atualizado\\n\\n0889-2229 AIDS Research and Human Retroviruses A2 SOCIOLOGIA Atualizado\\n\\n1414-753X Ambiente e Sociedade (Campinas) A2 SOCIOLOGIA Atualizado\\n\\n1809-4422 Ambiente &amp; Sociedade (Online) A2 SOCIOLOGIA Atualizado\\n\\n0044-7447 Ambio (Oslo) A2 SOCIOLOGIA Atualizado\\n\\n1130-2887 América Latina Hoy A2 SOCIOLOGIA Atualizado\\n\\n0161-7761 Anthropology &amp; Education Quarterly A2 SOCIOLOGIA Atualizado\\n\\n0210-1963 Arbor (Madrid) A2 SOCIOLOGIA Atualizado\\n\\n0863-1808 Berliner Journal fur Soziologie A2 SOCIOLOGIA Atualizado\\n\\n0102-311X Cadernos de Saúde Pública (ENSP. Impresso) A2 SOCIOLOGIA Atualizado\\n\\n1298-6046 Cahiers du Genre (Paris) A2 SOCIOLOGIA Atualizado\\n\\n0008-0276 Cahiers Internationaux de Sociologie A2 SOCIOLOGIA Atualizado\\n\\n0826-3663 Canadian Journal of Latin American and Caribbean Studies A2 SOCIOLOGIA Atualizado\\n\\n1188-3774 Canadian Journal of Urban Research A2 SOCIOLOGIA Atualizado\\n\\n0309-8168 Capital &amp; Class A2 SOCIOLOGIA Atualizado\\n\\n0341-8162 Catena (Cremlingen) A2 SOCIOLOGIA Atualizado\\n\\n1519-6089 Civitas: Revista de Ciências Sociais (Impresso) A2 SOCIOLOGIA Atualizado\\n\\n0010-4086 Comparative Education Review A2 SOCIOLOGIA Atualizado\\n\\n0360-1315 Computers and Education A2 SOCIOLOGIA Atualizado\\n\\n0102-8529 Contexto Internacional (PUCRJ. Impresso) A2 SOCIOLOGIA Atualizado\\n\\n1478-0046 Cultural and Social History (Online) A2 SOCIOLOGIA Atualizado\\n\\n0419-1633 Diogène (Ed. Française) A2 SOCIOLOGIA Atualizado\\n\\n\\n\\n 4 Quarta-feira 04 Fevereiro 2015 18:33:10\\n&quot; A busca está funcionando! No entanto, vale lembrar, não conseguimos aqui delimitar nossa busca a colunas específicas. Poderíamos fazer com que buscássemos apenas na coluna com classificação. Há outros modos de importarmos estes dados e fazermos esta busca no R. Este foi um modo simples para treinarmos o regex no R. 6.2.4 Transformando strings em vetores com strsplit() É possível quebrar uma string em vários elementos de um vetor usando um padrão regex # nosso texto inicial rato_vetor &lt;- &quot;O rato roeu. Roeu a roupa. A roupa que era do rei. Qual rei? O rei de Roma!&quot; # Criando um vetor tendo como critério de quebra o ponto final, deve-se usar o símbolo de escape &quot;\\\\.&quot; strsplit(rato_vetor, &quot;\\\\.&quot;) ## [[1]] ## [1] &quot;O rato roeu&quot; &quot; Roeu a roupa&quot; ## [3] &quot; A roupa que era do rei&quot; &quot; Qual rei? O rei de Roma!&quot; # Vetores a partir da pontuação strsplit(rato_vetor, &quot;\\\\.|\\\\?&quot;) ## [[1]] ## [1] &quot;O rato roeu&quot; &quot; Roeu a roupa&quot; ## [3] &quot; A roupa que era do rei&quot; &quot; Qual rei&quot; ## [5] &quot; O rei de Roma!&quot; # Uma dica. Os elementos de vetores estão ficando com espaço em branco. Podemos resolver isso: strsplit(rato_vetor, &quot;(\\\\.|\\\\?) ?&quot;) ## [[1]] ## [1] &quot;O rato roeu&quot; &quot;Roeu a roupa&quot; &quot;A roupa que era do rei&quot; ## [4] &quot;Qual rei&quot; &quot;O rei de Roma!&quot; No pacote stringr o comando equivalente é o str_split(). Atenção: Ao tentar usar regex com espaços em branco (whitespace) e ele não funciona, é bom saber que há diversos tipos de espaços em branco. Há diferentes tipos de espaço em branco 6.2.5 Exemplo regex Voltando ao nosso exemplo anterior, podemos transformar as datas abaixo, que estão no formado dd/mm/aaaa (dia/mês/ano) para o formato aaaa-mm-dd (ano-mês-dia), para que possamos, por exemplo, ordenar as datas de modo fácil. Original Converter para 20/03/2020 “2020-03-20” 13/01/1990 “1990-01-13” 04/06/2001 “2001-06-04” datas &lt;- c(&#39;20/03/2020&#39;, &#39;13/01/1990&#39;, &#39;04/06/2001&#39;) gsub(&#39;([0-9]{2})/([0-9]{2})/([0-9]{4})&#39;,&#39;\\\\3-\\\\2-\\\\1&#39;, datas) ## [1] &quot;2020-03-20&quot; &quot;1990-01-13&quot; &quot;2001-06-04&quot; Vale lembrar, o R possui funções (como o strptime() ) e pacotes específicos para lidar com datas. O exemplo acima foi apenas um exercício. O R possui diversos pacotes para lidar com regex. As funções do base, que já vem com o R possuem diversas funções. Há ainda o pacote Google RE2 que é uma versão rápida desenvolvida pela Google. Outro pacote interessante é o stringr que veremos a seguir. 6.2.6 Lookaround lookadead e lookbehind É possível fazer com que um padrão passe a valer antes ou depois de outro padrão. Se um padrão deve ser considerado se antes de outro padrão, então usamos lookahead. Se um padrão deve ser considerado se depois de outro padrão, então usamos lookbehind. Para saber mais sobre, este manual pode ser útil. 6.3 Pacote stringr O stringr adiciona diversas funcionalidades que facilitam a manipulação de strings. Vejamos um trecho de A Divisão do Trabalho Social. durkheim.DTS &lt;- &quot;Quanto à questão que originou este trabalho, é a das relações entre a personalidade individual e a solidariedade social. Como é que, ao mesmo passo que se torna mais autõnomo, o indivíduo depende mais intimamente da sociedade? Como pode ser, ao mesmo tempo, mais pessoal e mais solidário? Pois é inconteste que esses dois movimentos, por mais contraditórios que pareçam, seguem-se paralelamente.&quot; stringr::str_count(durkheim.DTS, &quot;indiv&quot;) ## [1] 2 6.3.1 Normalização com stringr Um problema ao lidar com tabelas pode ser a normalização. Por exemplo, ao pegar dados da saúde em uma tabela que quem preenche o formulário, digita por extenso ao invés de escolher a partir de uma lista pré-definida (como são os fatores) pode ocorrer isto aqui: remedios &lt;- read.table(header = T, text = &#39; n remedio 1 bogripe 1 biozina 1 bidioxicloquina 1 betametasona 1 bengripe 1 benegripi 1 benegripe 1 BENEGRIPE 1 benegripe 1 Benegripe 1 BENEFRIPE 1 bena 1 bemegripe&#39;) Estes dados vieram da SRAG 2020, o banco de dados de Síndrome Respiratória aguda grave (salvo engano, na coluna OUT_ANTIV). Repare como um mesmo remédio está escrito de diferentes formas. Um modos de tentar padronizar esta variedade de nomes escritos de formas diferentes - mas não o único e não o mais indicado para este caso que tem muitas grafias diferentes, mas que é interessante em termos didáticos da ferramenta - é este a seguir. Podemos resolver isso com str_detect e dplyr::case_when remedios %&gt;% dplyr::mutate(remedio_novo = dplyr::case_when( stringr::str_detect(remedio,&quot;(?i)be[mn]egrip[ei]&quot;) ~ &quot;Benegripe&quot; )) ## n remedio remedio_novo ## 1 1 bogripe &lt;NA&gt; ## 2 1 biozina &lt;NA&gt; ## 3 1 bidioxicloquina &lt;NA&gt; ## 4 1 betametasona &lt;NA&gt; ## 5 1 bengripe &lt;NA&gt; ## 6 1 benegripi Benegripe ## 7 1 benegripe Benegripe ## 8 1 BENEGRIPE Benegripe ## 9 1 benegripe Benegripe ## 10 1 Benegripe Benegripe ## 11 1 BENEFRIPE &lt;NA&gt; ## 12 1 bena &lt;NA&gt; ## 13 1 bemegripe Benegripe O símbolo (?i) indica que a busca é case insenitive, isto é, não distingue maiúsclas de minúsculas e vice versa. Nosso padrão não detectou todos os casos, ficando para trás “bengripe” e “BENEFRIPE”. case_when(stringr::str_detect( nos dá a condição, se certo padrão for encontrado, faça algo \"(?i)be[mn]egrip[ei]\") o padrão a ser encontrado e ~ \"Benegripe\" diz qual valor será usado em substituição. Por fim, a intenção do exemplo acima é mostrar a ferramenta. Mas no caso deste problema, uma abordagem mais adequada seria usar alguma medida de minimum edit distance (como a de Levenstein), onde teríamos uma lista com os nomes corretos e encontraríamos as palavras mais próximas na lista com nomes com grafia errada. 6.4 Dicas/Sugestões: Regex no R Cheatsheet de expressões regulares no R (em inglês) RECOMENDADO cheatcheet stringr Introdução ao regex com R. Um manual online em portugês onde você pode rodar códigos na página à medida que aprende truques novos. “Regular Expressions as used in R”.Expressão regular no R. Documento oficial. (em inglês) Albert Y. Kim. Regular Expressions in R Regular Expressions with The R Language. Site dedicao às RegEx em várias linguagens de programação. Data Wrangling Cheatsheet em português, tradução de Augusto Queiroz de Macedo Regular expressions PENG, Roger. R Programming for Data Science. 2020. Bookdown online. J. Kyle Armstrong Fundamentals of Data Wrangling with R 2021. bookdown online O pacote regexplain ajuda a testar regexes e comandos que usam regex no R de modo interativo e fácil, utilizando interface baseada em shiny. "],["visualização-de-dados.html", "7 Visualização de dados 7.1 Base plots 7.2 Cores 7.3 O pacote Lattice 7.4 O pacote ggplot2", " 7 Visualização de dados Objetivos deste capítulo: Apresentar uma introdução à visualização de dados com pacote base pacote lattice pacote ggplot confecção de mapas simples EM CONSTRUÇÃO Dicas Quer fazer gráficos no R sem programar? Tente o pacote esquisse. https://dreamrs.github.io/esquisse/articles/get-started.html 7.1 Base plots CAPÍTULO EM CONSTRUÇÃO O R vem com um pacote básico, nativo de gráficos. Repetindo o exemplo da introdução ao R na seção sobre fatores, fazendo um gráfico de barras simples a partir de um vetor, mas agora explicando a parte gráfica e aproveitando o pipe do tidyverse. Perceba que o pacote já faz a soma para nós. # carregando o magritrr para usar os pipes library(magrittr) aeroportos &lt;- c(&quot;BSB&quot;, &quot;CON&quot;, &quot;BSB&quot;, &quot;VIC&quot;, &quot;GUA&quot;, &quot;FOR&quot;, &quot;MAO&quot;, &quot;GUA&quot;, &quot;CON&quot;, &quot;CON&quot;, &quot;REC&quot;, &quot;UDI&quot;, &quot;VIC&quot;, &quot;GUA&quot;) # Numa versão mínima do gráfico: aeroportos %&gt;% factor %&gt;% summary %&gt;% barplot E numa versão mais elaborada do gráfico de barras: aeroportos %&gt;% # transformando o vetor em fator para o barplot funcionar factor %&gt;% # somando os repetidos summary %&gt;% # ordendando com &quot;sort()&quot;, e de modo decrescente com &quot;decreasing = TRUE&quot; sort(., decreasing = TRUE) %&gt;% # plotando o gráfico barplot( main = &quot;Aeroportos Brasil&quot;, sub = &quot;Sublegenda&quot;, xlab = &quot;Legenda eixo x&quot;, ylab = &quot;Legenda eixo y&quot;, legend.text = &quot;Frequência&quot;, # cores col = c(&quot;darkred&quot;, &quot;indianred&quot;), # rotacionando as legendas do das barras. Bom para quando as legendas são extensas las=2, # fazer o gráfico de modo horizontal horiz = TRUE) 7.2 Cores Para saber as cores disponíveis, usamos o comando colors(), que retorna 657 opções de cores. Se quisermos ver, por exemplo, somente as opções de vermelho: grep(&quot;red&quot;, colors(), value = T) ## [1] &quot;darkred&quot; &quot;indianred&quot; &quot;indianred1&quot; &quot;indianred2&quot; ## [5] &quot;indianred3&quot; &quot;indianred4&quot; &quot;mediumvioletred&quot; &quot;orangered&quot; ## [9] &quot;orangered1&quot; &quot;orangered2&quot; &quot;orangered3&quot; &quot;orangered4&quot; ## [13] &quot;palevioletred&quot; &quot;palevioletred1&quot; &quot;palevioletred2&quot; &quot;palevioletred3&quot; ## [17] &quot;palevioletred4&quot; &quot;red&quot; &quot;red1&quot; &quot;red2&quot; ## [21] &quot;red3&quot; &quot;red4&quot; &quot;violetred&quot; &quot;violetred1&quot; ## [25] &quot;violetred2&quot; &quot;violetred3&quot; &quot;violetred4&quot; Dicas: Cores no R Folha de dicas (cheatsheet) de cores no R. Há dicas de pacotes para mais opções de cores, como o colorspace, grDevices e o colorRamps. Outra opção bem extensa sobre cores no R é Paletas de cores no R. 7.3 O pacote Lattice CAPÍTULO EM CONSTRUÇÃO 7.4 O pacote ggplot2 O ggplot2 é um dos pacotes da suíte de pacotes do tidyverse e segue a gramática dos gráficos de Hadley Wickham. O ggplot é um dos pacotes mais famosos do tidyverse ou mesmo do R. Instalando o pacote ggplot, caso não tenha instalado o tidyverse ou o ggplot: install.packages(&#39;ggplot2&#39;, ) Carregando o pacote ggplot: library(ggplot2) Na lógica da gramática dos gráficos, sob a qual o ggplot foi construído, possui 7 níveis: dados: isto é, a base de dados a ser usada. aesthetics aes(): o que você pecisa para plotar, define os eixos x e y. geoms ou geometria, geom_*(), qual tipo de gráfico queremos. Há cerca de 37 tipos disponíveis, como histograma, gráfico de linhas, boxplot, etc. facets Estatística. Refere-e a algumas funções estatísticas. Pode-se, por exemplo, acrescentar uma reta de regressão. Coord ou Sistema de coordenadas. Temas, theme: muda o fundo do gráfico. Desse modo, vamos plotando o gráfico, nível por nível. A ordem pode mudar um pouco, alguns podem estar ausentes, mas são obrigatórios os três primeiros (dados, aes e geoms), e sem eles, não temos o gráfico. Para ilustar, vamos fazer um histograma, um gráfico simples, e que só precisa do eixo x. ggplot(data = MeuDataBase, aes(x=ColunaDoDatabase_que_será_o_eixo_x)) + geom_histogram() E agora um exemplo prático: ggplot(data = mtcars, aes(x=mpg)) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Vamos fazer o mesmo barplot de aeroportos class(aeroportos) ## [1] &quot;character&quot; # aeroportos não pode ser um vetor char para usarmos no ggplot # temos de transformá-lo em um tibble aer.tibble &lt;- tibble::tibble(aer = aeroportos) ggplot(aer.tibble, aes(aer)) + geom_bar() Podemos reordenar com base não na ordem alfabética, mas em valores, crescentes ou decrescentes. Para tal, usamos a função fct_reorder() no nível aes, no seguinte modo: aes(fct_reorder( eixoX, eixoY), eixoY)). 7.4.1 ggplot: nível aes Como dito, o nível “aes” define os eixos x e y. É nele que definimos onde entram os dados. Também é aqui que podemos redefinir a ordem de apresentação dos dados. Por exemplo, no gráfico dos aeroportos, podemos reordená-los da seguinte forma: # plyr cria um data frame com a coluna &quot;x&quot; de nomes/fatores e &quot;freq&quot; com a frequência aeroportos.df &lt;- plyr::count(aeroportos) # gerando o gráfico ggplot(aeroportos.df, aes(reorder(x, -freq), freq)) + geom_col() Usamos reorder para reordenar conforme o valor de “freq”. Se quisermos em ordem crescente, usamos aes(reorder(x, freq), freq)). Se quisermos a ordem inversa, dos valores maiores aos menores, acrescentamos o sinal de - assim: aes(reorder(x, -freq), freq)). No caso abaixo, usamos um database já disponível sobre diamantes. Atribuímos, para cada coluna/variável, um aspecto no gráfico, como eixos x e y, cores diferentes e formas. ggplot(data = diamonds, aes(x=carat, y=price, # &#39;shape&#39; aqui diz que cada valor na variável &#39;cut&#39; terá uma forma (shape) diferente shape = cut, # &#39;color&#39; diz que cada valor na variável terá uma cor diferente. # &quot;clarity&quot; é o nome da variável/coluna com base na qual as cores variarão color = clarity )) + geom_point() ## Warning: Using shapes for an ordinal variable is not advised 7.4.1.1 argumento, position Ao menos no caso de gráficos de barras, podemos especificar como gráficos com mais de uma variável terão as informações agrupadas. Primeiro, vamos criar um database meuDF &lt;- read.table(header = T, text = &#39; mes ano valor 1 2019 23 1 2020 31 1 2021 28 2 2019 28 2 2020 29 2 2021 30 3 2019 19 3 2020 26 3 2021 24&#39;) Gerando o gráfico barras - geom_bar() - ou de colunas - geom_col() - é possível distribuir os gráficos de modos distintos. # para facilitar, vamos salvar parte do código numa variável p &lt;- ggplot(meuDF, aes(x=ano, y=valor, fill=as.factor(mes))) # Vamos agora testar diferentes posições (positions): # No caso, para cada ano, os valores dos meses # usando a posição &quot;dodge&quot;: &quot;desviar&quot; ou &quot;esquivar&quot; p + geom_col(position = &quot;dodge&quot;) # Fill que calcula percentualmente. O eixo y vai até 100% p + geom_col(position = &quot;fill&quot;) # stack vai o valor nominal p + geom_col(position = &quot;stack&quot;) Se está incomodado com a legenda “as.factor(mes)”, veremos mais adiante como personalizá-lo. 7.4.2 ggplot: Nível geom “geom”, ou “geometry” (geometria), define o tipo de gráfico que queremos, se gráfico de barras ou linhas, se boxplot, etc. Há 37 tipos diferentes. Olhando a folha de dicas (cheat sheet) do ggplot2 opção1, opção2 podemos ver as opções de gráficos (geom_alguma_coisa) quando temos uma variável somente, quando tempos duas e assim por diante. 7.4.2.1 ggplot geom_line: gráfico de linha Criando um data frame com duas variáveis numéricas para testarmos. dataf &lt;- read.table(header=TRUE, text=&#39; Letra Valor1 Valor2 A 9 4 B 14 6 C 11 8 D 12 5&#39;) Gerando um gráfico de linha simples ggplot(dataf, aes(x=Valor1, y=Valor2)) + geom_line() Na versão ampliada ggplot(dataf, aes(x=Valor1, y=Valor2)) + geom_line( # largura da linha size=1.5, # tipo de linha. pontilhada=dashed linetype = &quot;dotted&quot;, color = &quot;darkblue&quot;, # cor # adiciona uma seta. ver grid::arrow() arrow=arrow() ) + # adiciona pontos na interseção geom_point(size=3, color=&quot;red&quot;) O linetype pode ser “blank” (vazio), “solid”, “dashed” (tracejado), “dotted” (pontilhado), “dotdash” (ponto e traço), “longdash” (traços longos), “twodash”. Estes também podem ser especificados por números, sendo 1 para “blank”, 2 para “dashed” e assim por diante. Para o caso de várias linhas ggplot(meuDF, aes(x=mes, y=valor)) + geom_line(aes(group =ano, # cor conforme o ano color=as.factor(ano), # tipo de linha conforme a varivel ano linetype = as.factor(ano),), # size: espessura das linhas no gráfico size=1) Se não usarmos o as.factor em ano, os anos serão considerados contínuos e podem aparecer errados na escala, como “2019.5”. Para evitar isso, caso aconteça, usamos o as.factor() na variável. linetype = as.factor(ano), dentro de aes do geom_line, para gerar o gráfico como queremos. Forçamos a variável ano em as.factor() pois ao tentar rodar, vimos na mensagem de erro que estava como variável contínua, o que não funciona para este tipo de gráfico. Forçamos então a se tornar discreta com o comando as.factor e booom! funcionou. Mais à frente veremos opções de configurações de cores mais avançadas. Vejamos agora os níveis opcionais do ggplot. Não há nenhuma ordem certa entre eles. 7.4.3 ggplot: nível facet_ Caso queiramos quebrar as informações em diferentes gráficos, usamos facet. Podemos usar facet_grid ou facet_wrap (este inverte os eixos x e y) ver “facetting” no sheet cheat. # salvando tudo em uma variável para facilitar o uso g &lt;- ggplot(data=diamonds, aes(x=carat, y=price)) +geom_point() g + facet_grid(.~cut) # se quiser compará-los na horizontal: g + facet_grid(cut~.) # cria um grid entre cut e clarity g + facet_grid(cut~clarity) Dica ggplot: facet_ ver seção Facets (ggplot2) do manual Cookbook R 7.4.4 ggplot: nível stat Refere-se a estatística. Pode-se acrescentar, por exemplo, geom_smooth() . Há opções como lm, glm, gam, loss, rlm. Dica: Demystifying stat_ layers in ggplot2 7.4.5 ggplot: nível sistema de coordenadas Caso queira limitar os dados que aparecem no gráfico, é possível com xlim e ylim(). Pode-se mudar a proporção, ampliando ou reduzindo os eixos através do ratio, como em coord_fixed(ratio=4) Para rotacionar o gráfico em 90º, acrescente o parâmetro + coord_flip(). 7.4.6 Cores no ggplot É possível utilizar paletas de cores diferentes do padrão. Um modo é usar o pacote RColorBrewer e o comando scale_fill_brewer() Gerando o gráfico usando apenas a coluna Valor1 e a letra ggplot(dataf, aes(x=Letra, y=Valor1, fill=Letra)) + geom_bar(stat=&quot;identity&quot;) + scale_fill_brewer(palette= &quot;BuGn&quot;) Há diversas outras paletas de cores. Há cores divergentes, como como BrBG, PiYG, PRGn, PuOr, RdBu, RdGy, RdYlBu, RdYlGn e Spectral; há sequência de cores qualitativas, como Accent, Dark2, Paired, Pastel1, Pastel2, Set1, Set2, Set3 Sequenciais como: Blues, BuGn, BuPu, GnBu, Greens, Greys, Oranges, OrRd, PuBu, PuBuGn, PuRd, Purples, RdPu, Reds, YlGn, YlGnBu, YlOrBr e YlOrRd. Fonte: cookbook-r.com Há ainda outras escalas de cores, como scale_alpha(), scale_colour_continuous(), scale_colour_gradient(), scale_colour_grey(), scale_colour_hue(), scale_colour_steps(), scale_colour_viridis_d(). 7.4.6.1 Cores definidas manualmente: scale_fill_manual Para usar sequência de cores personalizadas usa-se comando é scale_fill_manual e uma sequência de nomes de cores - como “green”, “blue”. Para ver a lista completa, digite colors() no console - ou use valores hexadecimais das cores. Cores = c(&quot;yellowgreen&quot;, &quot;#66CC99&quot;, &quot;#3CB371&quot;, &quot;seagreen4&quot;) ggplot(dataf, aes(x=Letra, y=Valor1, fill=Letra)) + geom_bar(stat=&quot;identity&quot;) + scale_fill_manual(values=Cores) 7.4.6.2 Cores contínuas Em um gráfico de pontos, podemos Primeiro criando um data frame com valores aleatórios. df &lt;- read.table(header=TRUE, text=&#39; valorX valorY 3 3.4 2 4 2.5 5 1 2.3 3.5 5.4 1.7 2.7 2.3 2.6 2.7 3.1&#39;) Podemos acrescentar gradientes diferentes, como o comando rainbow(). O valor dentro dele refere-se ao número de cores dentro do espectro do arco-íris ggplot(df, aes(x=valorX, y=valorY, colour=valorX)) + geom_point(stat=&quot;identity&quot;) + scale_colour_gradientn(colours=rainbow(4)) PARTE SOBRE GGPLOT AINDA EM CONSTRUÇÃO 7.4.7 Dicas ggplot Dicas Quer fazer gráficos no R sem programar? Tente o pacote esquisse. https://dreamrs.github.io/esquisse/articles/get-started.html folha de dicas/cheat sheet ggplot2: opção1, opção2, com resumo dos comandos do ggplot. Para entender cada elemento do gráfico ggplot, como legenda, titulo, etc. de Claragrannel Cheatsheet de Christian Bukhard Cheatsheets de Interactive web visualizations for R com dicas do que fazer diversos pacotes, como DiagrammeR, Leflet, Dygraphs, ggiraph, Plotly, etc. Livro online gratuito em português Introdução a R para Visualização e Apresentação de Dados com geração automática de relatórios, mapas, e diferentes gráficos com o ggplot2. Saindo do básico no ggplot Exemplos de gráficos variados feitos com ggplot e com tutoriais ggplotr. Bom para sair do básico. É possível personalizar mais ainda o texto do ggplot. Para isso podemos usar o pacote ggtext, que nos permite usar com texto em markdown e html. https://github.com/wilkelab/ggtext https://www.r-bloggers.com/2020/06/ggplot2-text-customization-with-ggtext-data-visualization-in-r/ https://wilkelab.org/ggtext/articles/introduction.html Para gráficos animados Pacote tourr, para visualizar dados multivariados. Aqui um exemplo do tourr em ação. 7.4.8 Dicas outros pacotes gráficos Dica para tirar dúvidas com o GGplot O pacote ggx permite digitar sua dúvida sobre o ggplot e este retornar a solução. Não faz milagres, mas pode ajudar. Para utilizá-lo, após instalá-lo através do install.packages('ggx'): library(ggx) # carregando o pacote gghelp(&quot;flip x and y axis&quot;) ## coord_flip() gghelp(&quot;label in darkblue&quot;) ## theme(axis.title.x=element_text(color=&#39;darkblue&#39;)) gghelp(&quot;rotate x-axis label 45 degree&quot;) ## theme(axis.text.x = element_text(angle = 45)) Dicas O pacote patchwork torna fácil fazer gráficos múltiplos. psych::pairs.panels() apresenta correlação de Pearson, histograma e regressão pairs: ggaly "],["análise-textual-text-mining.html", "8 Análise Textual (text mining) 8.1 Introdução 8.2 Abordagens: saco de palavras (bag of words) e análise semântica (semantic parsing) 8.3 Abordagem Bag of words 8.4 Remoção de palavra vazia (stopwords) 8.5 Estemização (stemming) e lematização 8.6 Nuvem de palavras 8.7 Palavras em contexto (keyword-in-context KWIC)", " 8 Análise Textual (text mining) Orientações para ler este capítulo: Em vários dos códigos aqui presentes, usaremos a notação pacote::função, que dispensa carregar o pacote previamente. Apesar de desnecessária caso o pacote seja carregado anteriormente, ele facilitar saber qual função de que pacote está sendo usada, além de desambiguar, uma vez que há funções de nome idêntico em pacotes diferentes. Assim, sempre confira se o pacote utilizado no exemplo já está instalado em sua máquina. No Rstudio, basta ir à aba “packages” e fazer a busca na lupa para conferir. Se preferir usar o console do R, use o comando installed.packages()[,1] para listar todos os pacotes instalados, e grep(\"dplyr\", installed.packages()[,1], value=T) para checar se um pacote (no caso, o dplyr) está instalado. Há também uma listagem com datasets para usar na análise textual, algumas inclusive já no formato R. 8.1 Introdução A análise computacional de textos é praticamente um sinônimo de Mineração de Texto (text mining) e tem muito em comum com o campo de Processamento de Língua Natural ou Processamento de Linguagem Natural, mas não são exatamente a mesma coisa. Como vimos no capítulo sobre história da análise textual, esta existia antes antes da inteligência artifical e mesmo dos computadores. Há diversas funções nativas do R que usamos na mineração de texto/análise textual, mas também há diversas suítes de pacotes (pacotes com vários pacotes, com várias funções) focados em análise textual com diversas ferramentas, como o tidytext, quanteda (QUantitative ANalysis TExtual DAta), OpenNLP, Rweka, languageR, koRpus, RcmdrPlugin.temis, RKEA (R Keyphrase Extraction Algorithm), tm (Text Mining Package) e qdap (Quantitative Discourse Analysis Package). Estas são algumas das mais famosas suítes de pacotes, com diversas ferramentas, mas há alguns outros pacotes focados em funções mais específicas, como o pacote wordcloud, ggwordcloud (nuvem de palavras para o ggplot2, com mais opções), por exemplo. Há redundância entre estes pacotes, isto é, eles tem funções próprias muito semalhantes às funções de outros pacotes, o que não quer dizer que não existam diferenças significativas. Há também pacotes em R para análise textual em modo gráfico. Um software bem conhecido de análise textual e que possui interface gráfica é o iramuteq (Interface de R pour les Analyses Multidimensionnelles de Textes et de Questionnaires), criado em 2009 por Pierre Ratinaud. Apesar de ainda ser bastante utilizado, o Iramuteq tem diversas limitações. Vimos um pouco sobre o RCommander. Há um plugin para ele dedicado à análise textual, o RcmdrPlugin.temis. Porém, sua última atualização ocorreu em 2018. Dicas lista com diversos pacotes R, relacionados à Processamento de Linguagem Natural. Lista extensa, porém desatualizada. 8.2 Abordagens: saco de palavras (bag of words) e análise semântica (semantic parsing) Na análise textual podemos analisar levando ou não em consideração a ordem das palavras ou sua função gramatical. Se o ordenamento ou a função das palavras não é importante, e queremos saber, por exemplo, apenas a frequência de termos, então faremos uma abordagem tipo “saco de palavras” (bag of words). Se precisamos saber as classes gramaticais, então a ordem das palavras é importante. Vamos começar os exemplos com um pacote que pega dados do Google Ngram e nos retorna frequência de termos longitudinalmente, com base de dados do Google Books. 8.3 Abordagem Bag of words Na abordagem de “saco de palavras” (bag of words) a ordem dos termos não importa, bem como geralmente não importa a sua classe gramatical. 8.3.1 Frequência de palavras/termos e Ngrams Numa abordagem do tipo saco-de-palavras, a abordagem mais simples, mas sempre útil, é verificar a frequência de certos termos. Apesar de simples, análises mais sofisticadas podem começar com a análise de frequência e partir para abordagens mais sofisticadas. aprendizado instrumental de uma língua, ao identificar as palavras mais frequentes em certa área do conhecimento. detecção de língua detecção de termos mais frequentes em uma busca identificação de palavras compostas 8.3.1.1 n-gram: explicando o conceito Se partirmos do exemplo da frase “Ivo viu a uva” teremos unigram N=1 “a” “viu” “Ivo” “uva” bigrams N=2 “a uva” “Ivo viu” “viu a” trigrams N=3 “Ivo viu a” “viu a uva” ngram=4 N=4 “Ivo viu a uva” … … … Quando o N passa de 3, chamamos de ngram e seu valor. Agora um exemplo com o R. Primeiro veremos exemplos com o Google Ngram, que é mais simples, e depois montaremos nosso próprio ngram. 8.3.1.2 GoogleNgrams A Google pegou sua enorme base de dados dos milhares de livros do Google Books e extraiu os termos mais frequentes, e os colocou disponível para consulta no site Goolge Books Ngram Viewer. O Google Ngrams facilitou a busca por ngrams nesta base de dados, naquilo que chamavam de “culturonomics”. O nome não pegou, a ferramenta tem suas limitações, mas ainda assim pode ser bem útil. A base de dados possui 5.2 milhões de livros, cerca de 4% de todos os livros já publicados. Para mais informações sobre a base de dados e sobre o GoogleNgram no site. Tanto o Python (com o get-ngrams) como o R (ngramr) possuem pacotes que usam os dados do Google Ngram. Instalando o pacote ngramr install.packages(&#39;ngramr&#39;) Carregando os pacote library(ngramr) E um exemplo de uso ng &lt;- ngramr::ngram(c(&quot;Max Weber&quot;, &quot;Émile Durkheim&quot;), year_start = 1890) ggplot2::ggplot(ng, aes(x=Year, y=Frequency, colour=Phrase)) + geom_line() Um exemplo da página do ngramr no Github com mais opções, usando a função ggram() no ngramr, que pega dados do GoogleNgram e plota os dados com o ggplot2: ggram(c(&quot;monarchy&quot;, &quot;democracy&quot;), year_start = 1500, year_end = 2000, corpus = &quot;eng_gb_2012&quot;, ignore_case = TRUE, geom = &quot;area&quot;, geom_options = list(position = &quot;stack&quot;)) + labs(y = NULL) É possível mudar entre diferentes corpus, que neste caso representam as diferentes línguas, como “eng_us_2019”, “eng_gb_2019”, “chi_sim_2019”, “fre_2019”, “ger_2019”, “heb_2019”, “ger_2012”, “spa_2012”, “rus_2012”, “ita_2012”. Para ver todos os corpus disponíveis veja no site busque a sessão “Corpora”. Infelizmente, não há corpus em português no Google Ngram. classicos = c(&quot;Max Weber&quot;, &quot;Émile Durkheim&quot;, &quot;Karl Marx&quot;, &quot;Gabriel Tarde&quot;, &quot;Georg Simmel&quot;) ggram(classicos, year_start = 1980, year_end = 2000, # Para mudar lingua, mude o corpus # ignore case: se diferencia maiúsculo de minúsculo corpus = &quot;fre_2019&quot;, ignore_case = TRUE, # tipo de grafico em geom geom = &quot;line&quot;, geom_options = list()) + # labs: label do eixo y labs(y = NULL) Dicas Ngramr: Site do Books Ngram Viewer explicando seus parâmetros. PDF com a documentação do ngramr Instalação/Primeiros passos com o Ngramr na página do Github do ngramr Um projeto similar ao Google Ngram - inclusive usando parte do mesmo pessoal -, porém melhorado, é o bookworm:HalthiTrust do projeto Halthi Trust-Digital Livrary, com muito mais línguas, inclusive o português e mais opções de busca. Há uma API dedicada ao HalthiTrust, podendo baixar as bases de dados direto do R, o hathiTools 8.3.1.3 N-grams no R library(ngram) ## ## Attaching package: &#39;ngram&#39; ## The following object is masked from &#39;package:ngramr&#39;: ## ## ngram Vamos pegar um trecho de Alfred Shutz. txt=&quot;A Fenomenologia busca o início real de todo pensamento filosófico... Seu lugar é além - ou melhor, antes - de todas as distinções entre realismo e idealismo.&quot; Vamos quebrar o texto em ngrams. Geralmente usa-se valores entre 1 e 3. ng &lt;- ngram::ngram(txt, # n = valor do ngram n=3) # imprimindo o objeto que criamos, que mostra o total de ngrams ng ## An ngram object with 25 3-grams # imprimindo os ngrams gerados. ngram::get.ngrams(ng) ## [1] &quot;além - ou&quot; &quot;início real de&quot; ## [3] &quot;- de todas&quot; &quot;antes - de&quot; ## [5] &quot;busca o início&quot; &quot;entre realismo e&quot; ## [7] &quot;o início real&quot; &quot;A Fenomenologia busca&quot; ## [9] &quot;distinções entre realismo&quot; &quot;lugar é além&quot; ## [11] &quot;as distinções entre&quot; &quot;de todo pensamento&quot; ## [13] &quot;filosófico... Seu lugar&quot; &quot;é além -&quot; ## [15] &quot;- ou melhor,&quot; &quot;de todas as&quot; ## [17] &quot;Fenomenologia busca o&quot; &quot;melhor, antes -&quot; ## [19] &quot;todo pensamento filosófico...&quot; &quot;todas as distinções&quot; ## [21] &quot;ou melhor, antes&quot; &quot;realismo e idealismo.&quot; ## [23] &quot;real de todo&quot; &quot;Seu lugar é&quot; ## [25] &quot;pensamento filosófico... Seu&quot; Diversos outros pacotes::funções fazem a quebra em ngrams, como RWeka::NGramTokenizer ou o quanteda. A função de ngram do quanteda tem a vantagem de poder definir um escopo de valores de ngram de uma vez, podendo gerar unigramas, bigramas e trigramas com um só comando. Em outros pacotes isto é possível apenas com pós processamento. A quebra do texto em ngrams faz mais sentido quando, com eles, observamos os termos mais repetidos. Isso é o que vamos fazer a seguir. Num exemplo mais prático, fomos até o site gutenberg (site com vários livros gratuitos) e pegamos o link para o txt do livro “O Príncipe” de Maquiavel, em inglês. # link para o livro &quot;The Prince&quot; de Maquiavel. url.prince = &quot;https://www.gutenberg.org/files/1232/1232-0.txt&quot; # carregando o url num objeto R maquiavel &lt;- readLines(url(url.prince)) Observando a estrutura do objeto “maquiavel” que acabamos de criar: # Como o objeto importado está como um vetor com vários elementos: str(maquiavel) ## chr [1:5188] &quot;The Project Gutenberg eBook of The Prince, by Nicolo Machiavelli&quot; ... # vemos que é um vetor com 5.188 itens. Precisamos transformar estes vários vetores em um só elemento com o comando # paste0(var, collapse = &quot; &quot;) maquiavel2 &lt;- paste(maquiavel, collapse = &quot; &quot;) Por hora, usaremos o pacote tradicional ngram, escrito em C, e por isso, rápido. Podemos fazer a sumarização (summarizing) obtendo a frequência de vezes que um ngram apareceu no texto, bem como também a frequência relativa (proporcional) com a função ngram:: get.phrasetable, que retorna um data frame. Rode o ngram com diferentes valores para ver qual deles ertorna resultados mais informativos do conteúdo. prince_ngrams &lt;- ngram::get.phrasetable(ngram::ngram(maquiavel2, n = 3)) # restringindo aos trigramas mais frequentes prince_ngrams[1:16,] ## ngrams freq prop ## 1 he did not 20 0.0003770526 ## 2 it is necessary 20 0.0003770526 ## 3 in order to 19 0.0003582000 ## 4 the King of 19 0.0003582000 ## 5 Project Gutenberg-tm electronic 18 0.0003393473 ## 6 ought to be 18 0.0003393473 ## 7 in such a 18 0.0003393473 ## 8 prince ought to 18 0.0003393473 ## 9 so as to 17 0.0003204947 ## 10 that it was 15 0.0002827894 ## 11 those who have 15 0.0002827894 ## 12 if he had 15 0.0002827894 ## 13 for him to 14 0.0002639368 ## 14 the Project Gutenberg 14 0.0002639368 ## 15 such a way 14 0.0002639368 ## 16 the death of 13 0.0002450842 Dicas Sugestão de leitura JURAFSKY, Dan.; MARTIN, James H. cap.3 N-gram Language Models de Speech and Language Processing - An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition. 3ª Edição. 2020. Manual do pacote ngram 8.4 Remoção de palavra vazia (stopwords) 8.4.1 Criando lista com stopwords Ao analisarmos texto, o mais frequente são palavras bem pouco informativas, como artigos “o”, “a” “os”, “as”. Para termos uma noção melhor removemos as chamadas “stopwords”. manifesto &lt;- &quot;A História de toda a sociedade até hoje é a história da luta de classes.&quot; # criamos uma pequena lista de stopwords para nosso exemplo atual minhas_sw &lt;- c(&quot;a&quot;,&quot;o&quot;, &quot;e&quot;, &quot;da&quot;, &quot;de&quot;, &quot;do&quot;) # transformando o texto em vetor manif_vetor &lt;- manifesto %&gt;% # convertendo o texto todo para minúsculo tolower %&gt;% # quebrando o texto em vetores strsplit(., &quot; &quot;) %&gt;% # o comando strplit retorna lista. Vamos forçar para retornar como vetor char unlist manif_vetor ## [1] &quot;a&quot; &quot;história&quot; &quot;de&quot; &quot;toda&quot; &quot;a&quot; &quot;sociedade&quot; ## [7] &quot;até&quot; &quot;hoje&quot; &quot;é&quot; &quot;a&quot; &quot;história&quot; &quot;da&quot; ## [13] &quot;luta&quot; &quot;de&quot; &quot;classes.&quot; Por se tratar de vetor, podemos usar comando tradicionais, com os operadores ! que indica negação, e %in% que checa se algo está contido em um vetor. manif_vetor[!(manif_vetor) %in% minhas_sw] ## [1] &quot;história&quot; &quot;toda&quot; &quot;sociedade&quot; &quot;até&quot; &quot;hoje&quot; &quot;é&quot; ## [7] &quot;história&quot; &quot;luta&quot; &quot;classes.&quot; Explicando: (manif_vetor) %in% minhas_sw checa se itens de “manif_vetor” estão contidos em “minhas_sw”. Retorna um booleanoo de “TRUE” e “FALSE”. ! inverte o comando anterior, checando agora quais itens de “manif_vetor” não estão contidos em “minhas_sw”, também retornando um vetor com booleanos de “TRUE” e “FALSE”. Para obter os valores (as palavras), jogamos esta fórmula anterior dentro de “manif_vetor[fórmula_anterior]”. As stopwords costumam ser as mesmas. E se já houvesse uma lista pronta? Existe. É possível encontrar listas prontas na internet, mas diversas funções no R já incluem em si tais listas. Para ver a lista padrão no R, use: library(tm, quietly = T) # pegando apenas as primeiras 20 stopwords em inglês tm::stopwords(&quot;en&quot;) %&gt;% head(.,20) ## [1] &quot;i&quot; &quot;me&quot; &quot;my&quot; &quot;myself&quot; &quot;we&quot; ## [6] &quot;our&quot; &quot;ours&quot; &quot;ourselves&quot; &quot;you&quot; &quot;your&quot; ## [11] &quot;yours&quot; &quot;yourself&quot; &quot;yourselves&quot; &quot;he&quot; &quot;him&quot; ## [16] &quot;his&quot; &quot;himself&quot; &quot;she&quot; &quot;her&quot; &quot;hers&quot; # vendo a lista em português tm::stopwords(&quot;pt&quot;) ## [1] &quot;de&quot; &quot;a&quot; &quot;o&quot; &quot;que&quot; &quot;e&quot; ## [6] &quot;do&quot; &quot;da&quot; &quot;em&quot; &quot;um&quot; &quot;para&quot; ## [11] &quot;com&quot; &quot;não&quot; &quot;uma&quot; &quot;os&quot; &quot;no&quot; ## [16] &quot;se&quot; &quot;na&quot; &quot;por&quot; &quot;mais&quot; &quot;as&quot; ## [21] &quot;dos&quot; &quot;como&quot; &quot;mas&quot; &quot;ao&quot; &quot;ele&quot; ## [26] &quot;das&quot; &quot;à&quot; &quot;seu&quot; &quot;sua&quot; &quot;ou&quot; ## [31] &quot;quando&quot; &quot;muito&quot; &quot;nos&quot; &quot;já&quot; &quot;eu&quot; ## [36] &quot;também&quot; &quot;só&quot; &quot;pelo&quot; &quot;pela&quot; &quot;até&quot; ## [41] &quot;isso&quot; &quot;ela&quot; &quot;entre&quot; &quot;depois&quot; &quot;sem&quot; ## [46] &quot;mesmo&quot; &quot;aos&quot; &quot;seus&quot; &quot;quem&quot; &quot;nas&quot; ## [51] &quot;me&quot; &quot;esse&quot; &quot;eles&quot; &quot;você&quot; &quot;essa&quot; ## [56] &quot;num&quot; &quot;nem&quot; &quot;suas&quot; &quot;meu&quot; &quot;às&quot; ## [61] &quot;minha&quot; &quot;numa&quot; &quot;pelos&quot; &quot;elas&quot; &quot;qual&quot; ## [66] &quot;nós&quot; &quot;lhe&quot; &quot;deles&quot; &quot;essas&quot; &quot;esses&quot; ## [71] &quot;pelas&quot; &quot;este&quot; &quot;dele&quot; &quot;tu&quot; &quot;te&quot; ## [76] &quot;vocês&quot; &quot;vos&quot; &quot;lhes&quot; &quot;meus&quot; &quot;minhas&quot; ## [81] &quot;teu&quot; &quot;tua&quot; &quot;teus&quot; &quot;tuas&quot; &quot;nosso&quot; ## [86] &quot;nossa&quot; &quot;nossos&quot; &quot;nossas&quot; &quot;dela&quot; &quot;delas&quot; ## [91] &quot;esta&quot; &quot;estes&quot; &quot;estas&quot; &quot;aquele&quot; &quot;aquela&quot; ## [96] &quot;aqueles&quot; &quot;aquelas&quot; &quot;isto&quot; &quot;aquilo&quot; &quot;estou&quot; ## [101] &quot;está&quot; &quot;estamos&quot; &quot;estão&quot; &quot;estive&quot; &quot;esteve&quot; ## [106] &quot;estivemos&quot; &quot;estiveram&quot; &quot;estava&quot; &quot;estávamos&quot; &quot;estavam&quot; ## [111] &quot;estivera&quot; &quot;estivéramos&quot; &quot;esteja&quot; &quot;estejamos&quot; &quot;estejam&quot; ## [116] &quot;estivesse&quot; &quot;estivéssemos&quot; &quot;estivessem&quot; &quot;estiver&quot; &quot;estivermos&quot; ## [121] &quot;estiverem&quot; &quot;hei&quot; &quot;há&quot; &quot;havemos&quot; &quot;hão&quot; ## [126] &quot;houve&quot; &quot;houvemos&quot; &quot;houveram&quot; &quot;houvera&quot; &quot;houvéramos&quot; ## [131] &quot;haja&quot; &quot;hajamos&quot; &quot;hajam&quot; &quot;houvesse&quot; &quot;houvéssemos&quot; ## [136] &quot;houvessem&quot; &quot;houver&quot; &quot;houvermos&quot; &quot;houverem&quot; &quot;houverei&quot; ## [141] &quot;houverá&quot; &quot;houveremos&quot; &quot;houverão&quot; &quot;houveria&quot; &quot;houveríamos&quot; ## [146] &quot;houveriam&quot; &quot;sou&quot; &quot;somos&quot; &quot;são&quot; &quot;era&quot; ## [151] &quot;éramos&quot; &quot;eram&quot; &quot;fui&quot; &quot;foi&quot; &quot;fomos&quot; ## [156] &quot;foram&quot; &quot;fora&quot; &quot;fôramos&quot; &quot;seja&quot; &quot;sejamos&quot; ## [161] &quot;sejam&quot; &quot;fosse&quot; &quot;fôssemos&quot; &quot;fossem&quot; &quot;for&quot; ## [166] &quot;formos&quot; &quot;forem&quot; &quot;serei&quot; &quot;será&quot; &quot;seremos&quot; ## [171] &quot;serão&quot; &quot;seria&quot; &quot;seríamos&quot; &quot;seriam&quot; &quot;tenho&quot; ## [176] &quot;tem&quot; &quot;temos&quot; &quot;tém&quot; &quot;tinha&quot; &quot;tínhamos&quot; ## [181] &quot;tinham&quot; &quot;tive&quot; &quot;teve&quot; &quot;tivemos&quot; &quot;tiveram&quot; ## [186] &quot;tivera&quot; &quot;tivéramos&quot; &quot;tenha&quot; &quot;tenhamos&quot; &quot;tenham&quot; ## [191] &quot;tivesse&quot; &quot;tivéssemos&quot; &quot;tivessem&quot; &quot;tiver&quot; &quot;tivermos&quot; ## [196] &quot;tiverem&quot; &quot;terei&quot; &quot;terá&quot; &quot;teremos&quot; &quot;terão&quot; ## [201] &quot;teria&quot; &quot;teríamos&quot; &quot;teriam&quot; Há também o pacote stopwords, que no momento possui, para o português, de fontes como snowball, nltk e stopwords-iso. Para instalar, basta rodar o já conhecido install.packages(\"stopwords\"). # vendo as linguagens disponiveis stopwords::stopwords_getlanguages(&quot;snowball&quot;) ## [1] &quot;da&quot; &quot;de&quot; &quot;en&quot; &quot;es&quot; &quot;fi&quot; &quot;fr&quot; &quot;hu&quot; &quot;ir&quot; &quot;it&quot; &quot;nl&quot; &quot;no&quot; &quot;pt&quot; &quot;ro&quot; &quot;ru&quot; &quot;sv&quot; # vendo as fontes de stopwords disponíveis stopwords::stopwords_getsources() ## [1] &quot;snowball&quot; &quot;stopwords-iso&quot; &quot;misc&quot; &quot;smart&quot; ## [5] &quot;marimo&quot; &quot;ancient&quot; &quot;nltk&quot; &quot;perseus&quot; # vendo um extrato das stopwords em português, fonte snowball head(stopwords::stopwords(&quot;pt&quot;, source = &quot;snowball&quot;), 20) ## [1] &quot;de&quot; &quot;a&quot; &quot;o&quot; &quot;que&quot; &quot;e&quot; &quot;do&quot; &quot;da&quot; &quot;em&quot; &quot;um&quot; &quot;para&quot; ## [11] &quot;com&quot; &quot;não&quot; &quot;uma&quot; &quot;os&quot; &quot;no&quot; &quot;se&quot; &quot;na&quot; &quot;por&quot; &quot;mais&quot; &quot;as&quot; # vendo um extrato das stopwords em português, fonte stopwords-iso head(stopwords::stopwords(&quot;pt&quot;, source = &quot;stopwords-iso&quot;), 20) ## [1] &quot;a&quot; &quot;acerca&quot; &quot;adeus&quot; &quot;agora&quot; &quot;ainda&quot; &quot;alem&quot; &quot;algmas&quot; ## [8] &quot;algo&quot; &quot;algumas&quot; &quot;alguns&quot; &quot;ali&quot; &quot;além&quot; &quot;ambas&quot; &quot;ambos&quot; ## [15] &quot;ano&quot; &quot;anos&quot; &quot;antes&quot; &quot;ao&quot; &quot;aonde&quot; &quot;aos&quot; E comparando o número de elementos das diferentes fontes de stopwords stopwords::stopwords(&quot;pt&quot;, source = &quot;stopwords-iso&quot;) %&gt;% length() ## [1] 560 stopwords::stopwords(&quot;pt&quot;, source = &quot;snowball&quot;) %&gt;% length() ## [1] 203 stopwords::stopwords(&quot;pt&quot;, source = &quot;nltk&quot;) %&gt;% length() ## [1] 204 Para aplicar esta função no nosso texto e retirar as stopwords, podemos usar diversas funções (lista mais abaixo). Diferentes pacotes de análise textual possuem diferentes formas de retirar as stopwords. Para adicionar novas palavras à lista de stopwords que vamos usar no momento, cria-se um novo vetor - chamamos aqui de “novas_stopwords” - com as novas palavras a serem retiradas, e em seguida o stopwords() # checando o tamanho do vetor stopwords disponível length(tm::stopwords(&quot;pt&quot;)) ## [1] 203 # criando novo vetor com mais palavras novas_stopwords &lt;- c(&quot;então&quot;, &quot;portanto&quot;, tm::stopwords(&quot;pt&quot;)) # checando se nossos termos foram incluídos length(novas_stopwords) ## [1] 205 Ou para facilitar a inclusão de novos termos, podemos fazer do seguinte modo: # Separamos nossos termos apenas por espaço novas &lt;- &quot;então portanto&quot; # quebrando o char em vetor de termos # ao invés de usarmos unlist, podemos usar [[1]] strsplit(novas, &quot; &quot;)[[1]] ## [1] &quot;então&quot; &quot;portanto&quot; # colocando os novos termos em um novo vetor novas_stopwords &lt;- c(strsplit(novas, &quot; &quot;)[[1]], tm::stopwords(&quot;pt&quot;)) length(novas_stopwords) ## [1] 205 Deste modo, podemos ir acrescentando mais facilmente novos termos à nossa lista de stopwords. Há outras funções com listas de stopwords, como qdap::stopwords e vários outras listas de stopwords no pacote - lexicon. 8.4.1.1 Removendo as stopwords Para remover stopwords, temos diferentes pacotes com diferentes funções, como por exemplo: dplyr::anti_join(stopwords(pt)), tm::tm_map(corpus, removeWords, stopwords(\"english\"), tm::removeWords(texto, stopwords(\"pt\")), [tau::remove_stopwords()](https://cran.r-project.org/web//packages/tau/tau.pdf) e qdap::rm_stopwords(). O dplyr possui ainda a função semi_join() que mostra termos em comum, que se repetem em x e y. Já anti_join faz o oposto, mostra todas linhas de ‘x’ sem match em ‘y’, e é com ela que retiramos as stopwords. 8.4.1.1.1 Modo 1: pacote base Se não quisermos carregar nenhum pacote, um modo possível de retirar stopwords de um vetorde palavras com o vetor de setopwords se dá com os operadores ! e %in% manif_vetor[!(manif_vetor) %in% minhas_sw] ## [1] &quot;história&quot; &quot;toda&quot; &quot;sociedade&quot; &quot;até&quot; &quot;hoje&quot; &quot;é&quot; ## [7] &quot;história&quot; &quot;luta&quot; &quot;classes.&quot; 8.4.1.1.2 Modo 2: dplyr Outro modo de retirar stopwords usando o tidytext: 8.5 Estemização (stemming) e lematização Imagine que tenha palavras como “escrever, escrevi, escreveu” e você está interessado nos verbos mais frequentes. É útil considerar estas variações do verbo como uma palavra só. Isso pode ser obtido de dois modos, através da stemização e por lematização. Em ambos o objetivo é o mesmo, reduzir a flexão a uma base comum ou raiz. A estemização funciona cortando um pedaço do final da palavra, ao passo que lematização reduz as variações à raiz, podendo inclusive pegar verbos irregulares. Por que então usar estemização? A construção de lematizadores é mais complicada, além de ser um processo mais demorado e que consome mais recursos. 8.5.1 Estemização A estemização pode ser feita com o pacote SnowballC,que é baseado no snowball, que continua sendo desenvolvido no GitHub do projeto. Desenvolvida originalmente por Martin Porter, seu nome é um tributo ao SNOBOL, uma linguagem dos anos 1960 que lidava com strings. Para entender o algoritmo de estemização em português e alguns exemplos, veja aqui. Carregando o pacote SnowballC library(SnowballC) Exemplo de estemização # Vendo as línguas disponíveis SnowballC::getStemLanguages() ## [1] &quot;arabic&quot; &quot;basque&quot; &quot;catalan&quot; &quot;danish&quot; &quot;dutch&quot; ## [6] &quot;english&quot; &quot;finnish&quot; &quot;french&quot; &quot;german&quot; &quot;greek&quot; ## [11] &quot;hindi&quot; &quot;hungarian&quot; &quot;indonesian&quot; &quot;irish&quot; &quot;italian&quot; ## [16] &quot;lithuanian&quot; &quot;nepali&quot; &quot;norwegian&quot; &quot;porter&quot; &quot;portuguese&quot; ## [21] &quot;romanian&quot; &quot;russian&quot; &quot;spanish&quot; &quot;swedish&quot; &quot;tamil&quot; ## [26] &quot;turkish&quot; # criando um vetor de palavras palavras= c(&quot;plantar&quot;, &quot;plantei&quot;, &quot;ajudou&quot;, &quot;ajudarás&quot;, &quot;comer&quot;, &quot;comendo&quot;) # testando a stemização SnowballC::wordStem(palavras, language = &quot;portuguese&quot;) ## [1] &quot;plant&quot; &quot;plant&quot; &quot;ajud&quot; &quot;ajud&quot; &quot;com&quot; &quot;com&quot; Vamos testar com outras palavras: palavras= c(&quot;estou&quot;, &quot;está&quot;, &quot;estamos&quot;, &quot;sou&quot;, &quot;és&quot;) SnowballC::wordStem(palavras, language = &quot;portuguese&quot;) ## [1] &quot;estou&quot; &quot;está&quot; &quot;estam&quot; &quot;sou&quot; &quot;és&quot; Repare que verbos irregulares como “ser” e “estar” não funcionaram muito bem. Uma alternativa é usar a lematização ao invés da stemização. 8.5.2 Lematização EM CONSTRUÇÃO A lematização reduz variações/inflexões de uma palavra, de modo que sejam analisados como um termo único. A lematização chega à forma raiz da palavra, ainda que sejam, por exemplo, verbos irregulares. Funções como textstem::lemmatize_words() , koRpus::treetag, SnowballC::wordStem nlp_lemmatizer, e udpipe fazem este trabalho de lematização. goffman_stigma &lt;- c(&quot;The central feature of the stigmatized individual&#39;s situation in life can now be stated.&quot;, &quot;It is a question of what is often, if vaguely, called `acceptance&#39;.&quot;, &quot;How does the stigmatized person respond to his situation?&quot;) ## Default lexicon::hash_lemmas dictionary textstem::lemmatize_strings(goffman_stigma) ## [1] &quot;The central feature of the stigmatize individual&#39;s situation in life can now be state.&quot; ## [2] &quot;It be a question of what be often, if vague, call `acceptance&#39;.&quot; ## [3] &quot;How do the stigmatize person respond to his situation?&quot; 8.6 Nuvem de palavras Vários pacotes fazem as chamadas nuvem de palavras no R. Um deles é o wordcloud, que além de fazer nuvens de palavras, também é capaz de fazê-lo comparando documentos, Em sua forma mais simples texto_tocqueville &lt;- &quot;Em nosso tempo, a liberdade de associação tornou-se uma garantia necessária contra a tirania da maioria. Nos Estados Unidos, quando uma vez um partido se toma dominante. todo o poder público passa para as suas mãos; seus amigos particulares ocupam todos os empregos e dispõem de todas as forças organizadas. Como os homens mais distintos do partido contrário não podem atravessar a barreira que os separa do poder, é preciso que possam se estabelecer fora; é preciso que a minoria oponha sua força moral inteira ao poderio material que a oprime. Opõe-se, pois, um perigo a um perigo mais temível. A onipotência da maioria parece-me um risco tão grande para as repúblicas americanas que o meio perigoso que se usa para limitá-la parece-me, ainda assim, um bem. Exprimirei aqui um pensamento que lembrará o que disse em outra parte a respeito das liberdades comunais: não há país em que as associações sejam mais necessárias, para impedir o despotismo dos partidos ou a arbitrariedade do príncipe, do que aquele em que o estado social é democrático. Nas nações aristocráticas, os corpos secundários formam associações naturais que detêm os abusos de poder. Nos países em que semelhantes associações não existem, se os particulares não podem criar artificial e momentaneamente alguma coisa que se lhes assemelhe, não percebo mais nenhum dique contra nenhuma sorte de tirania, e um grande povo pode ser oprimido impunemente por um punhado de facciosos ou por um homem. ... Não podemos dissimular que a liberdade ilimitada de associação, em matéria política, é, de todas as liberdades, a última que um povo pode suportar. Se ela não o faz cair na anarquia, o faz tocá-la por assim dizer a cada instante. Essa liberdade, tão perigosa, oferece porém num ponto algumas garantias: nos países em que as associações são livres, as sociedades secretas são desconhecidas. Na América, há facciosos, mas não conspiradores.&quot; E para criar uma nuvem de palavras simples, basta usar o comando: wordcloud::wordcloud(texto_tocqueville) ## Warning in tm_map.SimpleCorpus(corpus, tm::removePunctuation): transformation ## drops documents ## Warning in tm_map.SimpleCorpus(corpus, function(x) tm::removeWords(x, ## tm::stopwords())): transformation drops documents E para usar num modo mais detalhado: wordcloud::wordcloud(texto_tocqueville, # se o input para esta função contém as frequências de palavras, o item abaixo deve ser descomentado # freq, # vetor com dois termos indicado o espectro de tamanho das palavras scale=c(2,.8), # número mínimo de repetições que uma palavra tem de ter para entrar no gráfico min.freq = 2, # número máximo de palavras a ser plotado na nuvem de palavras max.words = 70, # Não plotar palavras em ordem aleatória, mas sim em ordem decrescente random.order = FALSE, # cores, do menos frequente ao mais frequente colors = c(&quot;royalblue&quot;,&quot;blue&quot;, &quot;darkblue&quot;)) ## Warning in tm_map.SimpleCorpus(corpus, tm::removePunctuation): transformation ## drops documents ## Warning in tm_map.SimpleCorpus(corpus, function(x) tm::removeWords(x, ## tm::stopwords())): transformation drops documents Esta função aceita como entrada (input) tanto o texto puro como a tabela de frequência (e aí, deve-se usar o parâmetro freq). Para textos pequenos, como é o caso aqui, não há problema em usar texto diretamente na função, mas partir do momento que textos se tornam grandes, o ideal é fazer a contagem previamente e mandar a tabela para a função wordcloud. Além disso, fazer a contagem previamente permite fazer uma série de pré-processamentos no texto, como retirada de palavras pouco instrutivas (as stopwords), passar todas as palavras para minúsculo, etc. Vemos que algumas palavras frequentes não nos dizem muita coisa, como “que”, “nos”, “para”. Como queremos apreender algo do sentido do texto com a nuvem de palavras, seria interessante remover tais termos pouco significativos, as chamadas “palavras vazias” ou “stopwords”. Usamos aí um pequeno texto. Caso tivéssemos um texto grande, este procedimento de mandar o texto direto para a função wordcloud::wordcloud não seria indicado. Além disso, precisamos fazer alguns pré-processamentos no texto para obter algo mais significativo. Tocq &lt;- texto_tocqueville |&gt; as_tibble(falas = texto_tocqueville) # tudo.tokens &lt;- tudo %&gt;% tidytext::unnest_tokens(word, falas) # tudo.tokens &lt;- tidytext::unnest_tokens(tudo.df , falas) Tocq.tokens &lt;- Tocq %&gt;% tidytext::unnest_tokens(word, value) SW &lt;- c(stopwords::stopwords(&#39;pt&#39;), &#39;é&#39;, &#39;aqui&#39;, &#39;então&#39;, &#39;porque&#39;) # retirando as stopwords Tocq.semSW &lt;- Tocq.tokens$word[!(tudo.tokens$word) %in% SW] # Se quisermos observar algumas das palavras mais frequentes, sem as stopwords head(Tocq.semSW, 40) ## [1] &quot;tempo&quot; &quot;liberdade&quot; &quot;associação&quot; &quot;tornou&quot; &quot;garantia&quot; ## [6] &quot;necessária&quot; &quot;contra&quot; &quot;tirania&quot; &quot;maioria&quot; &quot;estados&quot; ## [11] &quot;unidos&quot; &quot;vez&quot; &quot;partido&quot; &quot;toma&quot; &quot;dominante&quot; ## [16] &quot;todo&quot; &quot;poder&quot; &quot;público&quot; &quot;passa&quot; &quot;mãos&quot; ## [21] &quot;amigos&quot; &quot;particulares&quot; &quot;ocupam&quot; &quot;todos&quot; &quot;empregos&quot; ## [26] &quot;dispõem&quot; &quot;todas&quot; &quot;forças&quot; &quot;organizadas&quot; &quot;homens&quot; ## [31] &quot;distintos&quot; &quot;partido&quot; &quot;contrário&quot; &quot;podem&quot; &quot;atravessar&quot; ## [36] &quot;barreira&quot; &quot;separa&quot; &quot;poder&quot; &quot;preciso&quot; &quot;possam&quot; Tocq.tibble &lt;- tibble(words = Tocq.semSW ) words.counts &lt;- Tocq.tibble %&gt;% dplyr::count(words, sort = TRUE) head(words.counts$words, 40) # Observando as palavras mais frequentes ## [1] &quot;associações&quot; &quot;liberdade&quot; &quot;poder&quot; &quot;assim&quot; ## [5] &quot;associação&quot; &quot;contra&quot; &quot;facciosos&quot; &quot;faz&quot; ## [9] &quot;grande&quot; &quot;la&quot; &quot;liberdades&quot; &quot;maioria&quot; ## [13] &quot;países&quot; &quot;parece&quot; &quot;particulares&quot; &quot;partido&quot; ## [17] &quot;perigo&quot; &quot;pode&quot; &quot;podem&quot; &quot;povo&quot; ## [21] &quot;preciso&quot; &quot;tão&quot; &quot;tirania&quot; &quot;todas&quot; ## [25] &quot;abusos&quot; &quot;ainda&quot; &quot;alguma&quot; &quot;algumas&quot; ## [29] &quot;américa&quot; &quot;americanas&quot; &quot;amigos&quot; &quot;anarquia&quot; ## [33] &quot;arbitrariedade&quot; &quot;aristocráticas&quot; &quot;artificial&quot; &quot;assemelhe&quot; ## [37] &quot;atravessar&quot; &quot;barreira&quot; &quot;bem&quot; &quot;cada&quot; # Para não poluir demais a nuvem de palavras, restringir às 150 mais frequentes: words.counts.head &lt;- head(words.counts, 150) Gerando a nuvem de palavras: wordcloud::wordcloud(words.counts.head$words, # se o input para esta função contém as frequências de palavras, o item abaixo deve ser descomentado freq = words.counts.head$n, # vetor com dois termos indicado o espectro de tamanho das palavras scale = c(3,1), min.freq = 2, # Frequência mínima de termos que serão usados # cores, do menos frequente ao mais frequente colors = c(&quot;royalblue&quot;,&quot;blue&quot;, &quot;darkblue&quot;, &quot;black&quot;) ) 8.7 Palavras em contexto (keyword-in-context KWIC) Podemos ver como certas palavras são usadas em diversas frases no texto para ter uma ideia melhor do contexto em que aparecem. No quanteda, usamos a função kwic(Dados, pattern = \"padrão\"), após o texto ter sido tokenizado. Se ainda não tiver carregado o pacote Quanteda: library(quanteda) ## Package version: 3.2.1 ## Unicode version: 14.0 ## ICU version: 70.1 ## Parallel computing: 4 of 4 threads used. ## See https://quanteda.io for tutorials and examples. Vamos para um exemplo do texto “Ciência como vocação” de Max Weber: texto = &quot;Por fim, é da sabedoria quotidiana que algo pode ser verdadeiro, embora não seja nem belo, nem sagrado, nem bom. Mas estes são apenas os casos mais elementares da luta que entre si travam os deuses dos ordenamentos e valores singulares. Como será possível pretender decidir &#39;cientificamente&#39; entre o valor da cultura francesa e o da alemã é coisa que não enxergo. Também aqui diferentes deuses lutam entre si, e para sempre. Acontece, embora noutro sentido, o mesmo que ocorria no mundo antigo, quando ainda se não tinha desencantado dos seus deuses e demónios: tal como os Gregos ofereciam sacrifícios, umas vezes, a Afrodite, outras a Apolo e, sobretudo, aos deuses da sua cidade, assim acontece ainda hoje, embora o culto se tenha desmistificado e careça da plástica mítica, mas intimamente verdadeira, daquela conduta. Sobre estes deuses e a sua eterna luta decide o destino, não decerto uma &#39;ciência&#39;. Apenas se pode compreender o que seja o divino para uma e outra ordem ou numa e noutra ordem&quot; # termos a serem buscados termos.vetor= c(&quot;deus*&quot;, &quot;divin*&quot;, &quot;luta&quot;) texto %&gt;% # precisamos primeiro tokenizar tokens%&gt;% # rodando a função de palavras chave em contexto kwic(., # termos a serem buscados. Pode ser um termo ou um vetor termos.vetor, # quantas palavras devem ser mostradas ao redor 4, # Para pegar tanto palavras minúsculas como as em maiúsculo. case_insensitive = TRUE) ## Keyword-in-context with 8 matches. ## [text1, 35] casos mais elementares da | luta | que entre si travam ## [text1, 41] entre si travam os | deuses | dos ordenamentos e valores ## [text1, 75] . Também aqui diferentes | deuses | lutam entre si, ## [text1, 106] tinha desencantado dos seus | deuses | e demónios: tal ## [text1, 131] , sobretudo, aos | deuses | da sua cidade, ## [text1, 162] conduta. Sobre estes | deuses | e a sua eterna ## [text1, 167] e a sua eterna | luta | decide o destino, ## [text1, 187] o que seja o | divino | para uma e outra No KWIC é possível ainda: usar regex como padrão de busca, através do parâmetro valuetype = \"regex em buscar por duas ou mais palavras em contexto com pattern = phrase( texto %&gt;% # precisamos primeiro tokenizar tokens%&gt;% # rodando a função de palavras chave em contexto kwic(., # termos a serem buscados. Pode ser um termo ou um vetor pattern = phrase(&quot;eterna luta&quot;), # quantas palavras devem ser mostradas ao redor 7, # Para pegar tanto palavras minúculas como as em maiúsculo. case_insensitive = TRUE) ## Keyword-in-context with 1 match. ## [text1, 166:167] . Sobre estes deuses e a sua | eterna luta | ## ## decide o destino, não decerto uma "],["text-mining-semantic-parsing.html", "9 Text mining: Semantic Parsing 9.1 POS - Part-of-speech tagging 9.2 Pacote UDPipe", " 9 Text mining: Semantic Parsing Até agora vimos abordagem onde a ordem das palavras e sua função gramatical não importava na análise, a chamada abordagem “saco-de-palavras”. Vamos agora para análise onde isso se faz importante, a abordagem semântica. 9.1 POS - Part-of-speech tagging É possível identificar a classe gramatical de cada palavras das frases. Vários pacotes no R fazem isso: openNLP, uma interface em R sobre o Apache OpenNLP tools, escrito em Java, com suporte a vários modelos de linguagem, inclusive o português coreNLP (Wrapper ao redor do Stanford CoreNLP Tools) Qdap com a função qdap::pos() (O pacote requer rJava, que requer JDE e JRE do Java instalados no seu computador, fora do R), RcppMeCab que é um wrapper da biblioteca “mecab”, spacyr, um wrapper ao redor do spaCy do Python (requer a instalação do Python e algumas de suas bibliotecas), UDPipe em C++(após a instalação, roda sem problemas no R) que possui modelos pré-treinados em 65 liguagens, inclusive o português. koRpus com suporte ao português e que possui integração com o programa gráfico rkward. No caso de pacotes que requerem o Rjava, uma dica é, ao menos no Linux, antes de instalar o Rjava, rodar o seguinte comando no terminal (não no console do R!). O comando a seguir faz com que o Rjava consiga encontrar o Java, e assim evita alguns tipos de erro na instalação. sudo R CMD javareconf 9.2 Pacote UDPipe Para o P.O.S (part-of-speech tagging), vamos usar o pacote UDPipe, já que ele não requer Python ou Java, sendo um wrapper do UDPipe C++, evitando boa parte das complicações de instalação, como em outros pacotes. O projeto é da Institute of Formal and Applied Linguistics, Faculty of Mathematics and Physics, Charles University da Reṕublica Tcheca. A função de POS é baseada no Google universal part-of-speech tags. UD vem de universal dependencies, um framework aberto para anotações gramaticais com 200 treebanks em amsi de 100 linguas. Milan Straka, Jan Hajiˇc, Jana Strakov. ́UDPipe: Trainable Pipeline for Processing CoNLL-U Files Performing Tokenization, Morphological Analysis, POS Tagging and Parsing Modelos de línguas no github de jwijffels Após instalar, carregando o pacote: library(udpipe) Vamos instalar um modelo de lingua não inglesa. Para ver a lista de linguagens disponíveis, rode o comando ?udpipe_download_model. Mas atente que nem todas as línguas estão disponíveis na última versão, sendo necessário a sua especificação. Para saber sobre os modelos em portuges utilizados no UD, veja aqui. Vamos utilisar a versão bosque, que funciona para PT-PT e PT-Br. Tal como está, o download ocorrerá no diretório de trabalho atual (digite getwd() para saber) # opção 1 dl &lt;- udpipe_download_model(language = &quot;portuguese-br&quot;, udpipe_model_repo = &#39;jwijffels/udpipe.models.ud.2.0&#39;) # Opção 2. &quot;bosque&quot; é a mais atual e mais utilisada dl &lt;- udpipe_download_model(language = &quot;portuguese-bosque&quot;) str(dl) Uma vez que o modelo foi baixado, vamos carregá-lo udmodel_ptBosque &lt;- udpipe_load_model(file = dl$file_model) Ou, caso tenha baixado em outro local: udmodel_ptBosque &lt;- udpipe_load_model(file = &quot;~/Documentos/R/portuguese-bosque-ud-2.5-191206.udpipe&quot;) E vamos aos testes: library(dplyr) texto &lt;- &quot;O rato Rogério roeu rapidamente a roupa roxa do rei Roberto de Roma.&quot; txt.anotado &lt;- udpipe::udpipe_annotate(udmodel_ptBosque, x = texto) %&gt;% as.data.frame() str(txt.anotado) ## &#39;data.frame&#39;: 16 obs. of 14 variables: ## $ doc_id : chr &quot;doc1&quot; &quot;doc1&quot; &quot;doc1&quot; &quot;doc1&quot; ... ## $ paragraph_id : int 1 1 1 1 1 1 1 1 1 1 ... ## $ sentence_id : int 1 1 1 1 1 1 1 1 1 1 ... ## $ sentence : chr &quot;O rato Rogério roeu rapidamente a roupa roxa do rei Roberto de Roma.&quot; &quot;O rato Rogério roeu rapidamente a roupa roxa do rei Roberto de Roma.&quot; &quot;O rato Rogério roeu rapidamente a roupa roxa do rei Roberto de Roma.&quot; &quot;O rato Rogério roeu rapidamente a roupa roxa do rei Roberto de Roma.&quot; ... ## $ token_id : chr &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ token : chr &quot;O&quot; &quot;rato&quot; &quot;Rogério&quot; &quot;roeu&quot; ... ## $ lemma : chr &quot;o&quot; &quot;rato&quot; &quot;Rogério&quot; &quot;roer&quot; ... ## $ upos : chr &quot;DET&quot; &quot;NOUN&quot; &quot;PROPN&quot; &quot;VERB&quot; ... ## $ xpos : chr NA NA NA NA ... ## $ feats : chr &quot;Definite=Def|Gender=Masc|Number=Sing|PronType=Art&quot; &quot;Gender=Masc|Number=Sing&quot; &quot;Gender=Masc|Number=Sing&quot; &quot;Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin&quot; ... ## $ head_token_id: chr &quot;2&quot; &quot;4&quot; &quot;2&quot; &quot;0&quot; ... ## $ dep_rel : chr &quot;det&quot; &quot;nsubj&quot; &quot;appos&quot; &quot;root&quot; ... ## $ deps : chr NA NA NA NA ... ## $ misc : chr NA NA NA NA ... # Para vermos apenas as classes gramaticais, apenas filtramos pela coluna: txt.anotado$upos ## [1] &quot;DET&quot; &quot;NOUN&quot; &quot;PROPN&quot; &quot;VERB&quot; &quot;ADV&quot; &quot;DET&quot; &quot;NOUN&quot; &quot;ADJ&quot; NA ## [10] &quot;ADP&quot; &quot;DET&quot; &quot;NOUN&quot; &quot;PROPN&quot; &quot;ADP&quot; &quot;PROPN&quot; &quot;PUNCT&quot; Na coluna “upos”: Roberto e Rogério são “PROPN”, ou seja, “proper names”, ou “nomes próprios” rato aparece como “NOUN”, isto é, substantivo. “VERB é verbo, ADJ é adjetivo, ADV é advérbio. Se quiser fazer só o POS Tagging, sem fazer lematização, e com isto ganhar tempo, pode-se restringir com o argumento tagger que pode ser um vetor: texto2 &lt;- &quot;O fundamento psicológico sobre o qual se eleva o tipo das individualidades da cidade grande é a intensificação da vida nervosa&quot; txt.anotado2 &lt;- udpipe_annotate(udmodel_ptBosque, x = texto2, tagger = &quot;default&quot; , parser = &quot;none&quot;) %&gt;% as.data.frame() ## This looks like you restarted your R session which has invalidated the model object, trying now to reload the model again from the file at /home/alisson/Documentos/Programação/R/analise_textual_sociologia/portuguese-bosque-ud-2.5-191206.udpipe in order to do the annotation. txt.anotado2 ## doc_id paragraph_id sentence_id ## 1 doc1 1 1 ## 2 doc1 1 1 ## 3 doc1 1 1 ## 4 doc1 1 1 ## 5 doc1 1 1 ## 6 doc1 1 1 ## 7 doc1 1 1 ## 8 doc1 1 1 ## 9 doc1 1 1 ## 10 doc1 1 1 ## 11 doc1 1 1 ## 12 doc1 1 1 ## 13 doc1 1 1 ## 14 doc1 1 1 ## 15 doc1 1 1 ## 16 doc1 1 1 ## 17 doc1 1 1 ## 18 doc1 1 1 ## 19 doc1 1 1 ## 20 doc1 1 1 ## 21 doc1 1 1 ## 22 doc1 1 1 ## 23 doc1 1 1 ## 24 doc1 1 1 ## 25 doc1 1 1 ## 26 doc1 1 1 ## 27 doc1 1 1 ## sentence ## 1 O fundamento psicológico sobre o qual se eleva o tipo das individualidades da cidade grande é a intensificação da vida nervosa ## 2 O fundamento psicológico sobre o qual se eleva o tipo das individualidades da cidade grande é a intensificação da vida nervosa ## 3 O fundamento psicológico sobre o qual se eleva o tipo das individualidades da cidade grande é a intensificação da vida nervosa ## 4 O fundamento psicológico sobre o qual se eleva o tipo das individualidades da cidade grande é a intensificação da vida nervosa ## 5 O fundamento psicológico sobre o qual se eleva o tipo das individualidades da cidade grande é a intensificação da vida nervosa ## 6 O fundamento psicológico sobre o qual se eleva o tipo das individualidades da cidade grande é a intensificação da vida nervosa ## 7 O fundamento psicológico sobre o qual se eleva o tipo das individualidades da cidade grande é a intensificação da vida nervosa ## 8 O fundamento psicológico sobre o qual se eleva o tipo das individualidades da cidade grande é a intensificação da vida nervosa ## 9 O fundamento psicológico sobre o qual se eleva o tipo das individualidades da cidade grande é a intensificação da vida nervosa ## 10 O fundamento psicológico sobre o qual se eleva o tipo das individualidades da cidade grande é a intensificação da vida nervosa ## 11 O fundamento psicológico sobre o qual se eleva o tipo das individualidades da cidade grande é a intensificação da vida nervosa ## 12 O fundamento psicológico sobre o qual se eleva o tipo das individualidades da cidade grande é a intensificação da vida nervosa ## 13 O fundamento psicológico sobre o qual se eleva o tipo das individualidades da cidade grande é a intensificação da vida nervosa ## 14 O fundamento psicológico sobre o qual se eleva o tipo das individualidades da cidade grande é a intensificação da vida nervosa ## 15 O fundamento psicológico sobre o qual se eleva o tipo das individualidades da cidade grande é a intensificação da vida nervosa ## 16 O fundamento psicológico sobre o qual se eleva o tipo das individualidades da cidade grande é a intensificação da vida nervosa ## 17 O fundamento psicológico sobre o qual se eleva o tipo das individualidades da cidade grande é a intensificação da vida nervosa ## 18 O fundamento psicológico sobre o qual se eleva o tipo das individualidades da cidade grande é a intensificação da vida nervosa ## 19 O fundamento psicológico sobre o qual se eleva o tipo das individualidades da cidade grande é a intensificação da vida nervosa ## 20 O fundamento psicológico sobre o qual se eleva o tipo das individualidades da cidade grande é a intensificação da vida nervosa ## 21 O fundamento psicológico sobre o qual se eleva o tipo das individualidades da cidade grande é a intensificação da vida nervosa ## 22 O fundamento psicológico sobre o qual se eleva o tipo das individualidades da cidade grande é a intensificação da vida nervosa ## 23 O fundamento psicológico sobre o qual se eleva o tipo das individualidades da cidade grande é a intensificação da vida nervosa ## 24 O fundamento psicológico sobre o qual se eleva o tipo das individualidades da cidade grande é a intensificação da vida nervosa ## 25 O fundamento psicológico sobre o qual se eleva o tipo das individualidades da cidade grande é a intensificação da vida nervosa ## 26 O fundamento psicológico sobre o qual se eleva o tipo das individualidades da cidade grande é a intensificação da vida nervosa ## 27 O fundamento psicológico sobre o qual se eleva o tipo das individualidades da cidade grande é a intensificação da vida nervosa ## token_id token lemma upos xpos ## 1 1 O o DET &lt;NA&gt; ## 2 2 fundamento fundamento NOUN &lt;NA&gt; ## 3 3 psicológico psicológico ADJ &lt;NA&gt; ## 4 4 sobre sobre ADP &lt;NA&gt; ## 5 5 o o DET &lt;NA&gt; ## 6 6 qual qual PRON &lt;NA&gt; ## 7 7 se se PRON &lt;NA&gt; ## 8 8 eleva elevar VERB &lt;NA&gt; ## 9 9 o o DET &lt;NA&gt; ## 10 10 tipo tipo NOUN &lt;NA&gt; ## 11 11-12 das &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 12 11 de de ADP &lt;NA&gt; ## 13 12 as o DET &lt;NA&gt; ## 14 13 individualidades individualidade NOUN &lt;NA&gt; ## 15 14-15 da &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 16 14 de de ADP &lt;NA&gt; ## 17 15 a o DET &lt;NA&gt; ## 18 16 cidade cidade NOUN &lt;NA&gt; ## 19 17 grande grande ADJ &lt;NA&gt; ## 20 18 é ser AUX &lt;NA&gt; ## 21 19 a o DET &lt;NA&gt; ## 22 20 intensificação intensificação NOUN &lt;NA&gt; ## 23 21-22 da &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 24 21 de de ADP &lt;NA&gt; ## 25 22 a o DET &lt;NA&gt; ## 26 23 vida vida NOUN &lt;NA&gt; ## 27 24 nervosa nervoso ADJ &lt;NA&gt; ## feats head_token_id dep_rel ## 1 Definite=Def|Gender=Masc|Number=Sing|PronType=Art &lt;NA&gt; &lt;NA&gt; ## 2 Gender=Masc|Number=Sing &lt;NA&gt; &lt;NA&gt; ## 3 Gender=Masc|Number=Sing &lt;NA&gt; &lt;NA&gt; ## 4 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 5 Gender=Masc|Number=Sing|PronType=Art &lt;NA&gt; &lt;NA&gt; ## 6 Gender=Masc|Number=Sing|PronType=Rel &lt;NA&gt; &lt;NA&gt; ## 7 Case=Acc|Gender=Masc|Number=Sing|Person=3|PronType=Prs &lt;NA&gt; &lt;NA&gt; ## 8 Mood=Ind|Number=Sing|Person=3|Tense=Imp|VerbForm=Fin &lt;NA&gt; &lt;NA&gt; ## 9 Definite=Def|Gender=Masc|Number=Sing|PronType=Art &lt;NA&gt; &lt;NA&gt; ## 10 Gender=Masc|Number=Sing &lt;NA&gt; &lt;NA&gt; ## 11 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 12 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 13 Definite=Def|Gender=Fem|Number=Plur|PronType=Art &lt;NA&gt; &lt;NA&gt; ## 14 Gender=Fem|Number=Plur &lt;NA&gt; &lt;NA&gt; ## 15 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 16 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 17 Definite=Def|Gender=Fem|Number=Sing|PronType=Art &lt;NA&gt; &lt;NA&gt; ## 18 Gender=Fem|Number=Sing &lt;NA&gt; &lt;NA&gt; ## 19 Gender=Fem|Number=Sing &lt;NA&gt; &lt;NA&gt; ## 20 Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin &lt;NA&gt; &lt;NA&gt; ## 21 Definite=Def|Gender=Fem|Number=Sing|PronType=Art &lt;NA&gt; &lt;NA&gt; ## 22 Gender=Fem|Number=Sing &lt;NA&gt; &lt;NA&gt; ## 23 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 24 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 25 Definite=Def|Gender=Fem|Number=Sing|PronType=Art &lt;NA&gt; &lt;NA&gt; ## 26 Gender=Fem|Number=Sing &lt;NA&gt; &lt;NA&gt; ## 27 Gender=Fem|Number=Sing &lt;NA&gt; &lt;NA&gt; ## deps misc ## 1 &lt;NA&gt; &lt;NA&gt; ## 2 &lt;NA&gt; &lt;NA&gt; ## 3 &lt;NA&gt; &lt;NA&gt; ## 4 &lt;NA&gt; &lt;NA&gt; ## 5 &lt;NA&gt; &lt;NA&gt; ## 6 &lt;NA&gt; &lt;NA&gt; ## 7 &lt;NA&gt; &lt;NA&gt; ## 8 &lt;NA&gt; &lt;NA&gt; ## 9 &lt;NA&gt; &lt;NA&gt; ## 10 &lt;NA&gt; &lt;NA&gt; ## 11 &lt;NA&gt; &lt;NA&gt; ## 12 &lt;NA&gt; &lt;NA&gt; ## 13 &lt;NA&gt; &lt;NA&gt; ## 14 &lt;NA&gt; &lt;NA&gt; ## 15 &lt;NA&gt; &lt;NA&gt; ## 16 &lt;NA&gt; &lt;NA&gt; ## 17 &lt;NA&gt; &lt;NA&gt; ## 18 &lt;NA&gt; &lt;NA&gt; ## 19 &lt;NA&gt; &lt;NA&gt; ## 20 &lt;NA&gt; &lt;NA&gt; ## 21 &lt;NA&gt; &lt;NA&gt; ## 22 &lt;NA&gt; &lt;NA&gt; ## 23 &lt;NA&gt; &lt;NA&gt; ## 24 &lt;NA&gt; &lt;NA&gt; ## 25 &lt;NA&gt; &lt;NA&gt; ## 26 &lt;NA&gt; &lt;NA&gt; ## 27 &lt;NA&gt; SpacesAfter=\\\\n Dicas POST - Part-of-Speech Tagging An introduction to part-of-speech tagging and the Hidden Markov Model do free code camp. Vignette do Udpipe no CRan. Para ir além do básico com o Udpipe, ver Jan Wijffels. UDPipe Natural Language Processing - Basic Analytical Use Cases. 2021. 9.2.1 Coocorrência de palavras A coocorrência de palavras pode nos auxiliar a pegar o sentido de uma grande quantidade de frases, nos mostrando palavras usadas na mesma sentença ou nas proximidades umas das outras. Por exemplo, podemos ver quantas vezes substantivos (nouns) aparecem junto a adjetivos (adj) na mesma sentença, ou junto a verbos (VERB), ou até alguma distância determinada. Vários pacotes fazem este trabalho, como o widyr::pairwise_count, mas usaremos o pacote do UDpipe. O comando udpipe::cooccurrence() aceita vetores, dataframes e objetos tipo “cooccurrence” como input. Usaremos um exemplo com vetor. O data frame requer formato especial. Para mais detalhes, conferir o help do termo com o comando ?udpipe::cooccurrence(). Num exemplo simples: coocor &lt;- udpipe::cooccurrence(c(&quot;Abacate&quot;, &quot;Banana&quot;, &quot;Abacate&quot;, &quot;Abacate&quot;, &quot;Banana&quot;, &quot;carambola&quot;, &quot;Banana&quot;, &quot;uva&quot;)) coocor ## term1 term2 cooc ## 1 Abacate Banana 2 ## 2 Banana Abacate 1 ## 3 Abacate Abacate 1 ## 4 Banana carambola 1 ## 5 carambola Banana 1 ## 6 Banana uva 1 Podemos fazer a rede de palavras a partir deste vetor. Primeiro, carregamos os pacotes de análise e de visualização de redes. library(igraph) library(ggraph) Rodando: rede.palavras &lt;- igraph::graph_from_data_frame(coocor) ggraph::ggraph(rede.palavras, layout = &quot;fr&quot;) + geom_edge_link(aes(width = cooc, edge_alpha = cooc), edge_colour = &quot;lightskyblue&quot;) + geom_node_text(aes(label = name), col = &quot;darkgreen&quot;, size = 4) + theme_graph(base_family = &quot;Arial Narrow&quot;) + theme(legend.position = &quot;none&quot;) + labs(title = &quot;Coocorrência&quot;) Uma vantagem da função de coocorrência do UDpipe para o do widyr é a possibilidade de utilizar skipgram como parâmetros. Isto significa que podemos controlar uma janela de quantas palavras de contexto, as palavras ao redor da nossa palavra alvo, contará no nosso cálculo de coocorrência. Assim, skipgrams de valores maiores terão mais palavras vizinhas computadas. var1 &lt;- c(&quot;A&quot;, &quot;B&quot;, &quot;A&quot;, &quot;A&quot;, &quot;B&quot;, &quot;c&quot;) udpipe::cooccurrence(var1, skipgram = 0) ## term1 term2 cooc ## 1 A B 2 ## 2 B A 1 ## 3 A A 1 ## 4 B c 1 udpipe::cooccurrence(var1, skipgram = 1) ## term1 term2 cooc ## 1 A B 3 ## 2 B A 2 ## 3 A A 2 ## 4 B c 1 ## 5 A c 1 Vamos usar uma base de dados mais extensa, as Notas Taquigráficas da CPI da Pandemia. Elas foram estruturadas em data frames em csv e Rds. O modo mais fácil e indicado é importar o .Rds, que já está no formato do R. As notas foram separadas por pessoa, partido, bloco parlamentar, função na CPI, e estado de origem. NotasTaq &lt;- readRDS(url(&quot;https://github.com/SoaresAlisson/NotasTaquigraficas/raw/master/rds/NT_30-Oitiva-Luiz_Paulo_Dominguetti_Pereira.Rds&quot;)) # vamos transformar nosso dataframe em tibble NotasTaq = dplyr::as_tibble(NotasTaq) # pegando apenas as falas e transformando em um vetor de um elemento, para poder usar no udpipe falas &lt;- NotasTaq %&gt;% #filter(nome == &quot;Omar Aziz&quot;) %&gt;% select(fala) %&gt;% filter(nome == unique(NotasTaq$nome)[2]) %&gt;% select(fala) %&gt;% paste0() NT.ud &lt;- udpipe_annotate(udmodel_ptBosque, x = falas) %&gt;% as.data.frame() ## This looks like you restarted your R session which has invalidated the model object, trying now to reload the model again from the file at /home/alisson/Documentos/Programação/R/analise_textual_sociologia/portuguese-bosque-ud-2.5-191206.udpipe in order to do the annotation. Podemos fazer uma frequência básica NT.ud.lemma &lt;- NT.ud %&gt;% filter(upos == &quot;ADJ&quot;) %&gt;% select(lemma) # pegando apenas substantivos (noun) da coluna upos estatisticasTexto &lt;- subset(NT.ud, upos %in% c(&quot;NOUN&quot;)) # txt_freq retorna um df com 3 colunas: 1) termo (key); 2) frequência (freq) e 3) frequencia percentual (freq_pct) estatisticasTexto &lt;- txt_freq(estatisticasTexto$token) estatisticasTexto$key &lt;- factor(estatisticasTexto$key, levels = rev(estatisticasTexto$key)) lattice::barchart(key ~ freq, # pegando os 25 casos mais frequentes data = head(estatisticasTexto, 25), col = &quot;indianred&quot;, main = &quot;Substantivos mais frequentes do depoente&quot;, xlab = &quot;Frequência&quot;) Perceba que há imprecisões: “Sr.” é pronome de tratamento, mas figura como substantivo. 9.2.2 Rede de palavras (wordnet) Montando a rede de palavras com os dados acima. coocorrencias &lt;- cooccurrence(x = subset(NT.ud, upos %in% c(&quot;NOUN&quot;, &quot;ADJ&quot;, &quot;VERB&quot;)), term = &quot;lemma&quot;, group = c(&quot;doc_id&quot;, &quot;paragraph_id&quot;, &quot;sentence_id&quot;)) wordnetwork &lt;- head(coocorrencias, 60) wordnetwork &lt;- igraph::graph_from_data_frame(wordnetwork) ggraph::ggraph(wordnetwork, layout = &quot;fr&quot;) + ggraph::geom_edge_link(aes(width = cooc, edge_alpha = cooc), edge_colour = &quot;lightskyblue3&quot;) + geom_node_text(aes(label = name), col = &quot;darkgreen&quot;, size = 4) + theme_graph(base_family = &quot;Arial&quot;) + theme(legend.position = &quot;none&quot;) + labs(title = &quot;Coocorrência dentro da sentença&quot;, subtitle = &quot;60 substantivos, adjetivos e verbos no depoimento \\nde Dominguetti na CPI da Pandemia&quot;) É possível ainda fazer rede de palavras com a função qdap::word_associate que ao invés de mostrar ligações mais frequentes, destaca as palavras mais frequentes através de seu tamanho, como numa nuvem de palavras. 9.2.3 Análise de semelhanças 9.2.3.1 Algoritmo Smith_Waterman Se busca regiões similares entre dois textos, um modo de detectar tais semelhança é usando o algoritmo Smith-Waterman, desenvolvido inicialmente na Biologia para identificar sequências de moléculas no artigo: SMITH T.F.Smith, WATERMAN, M. S. Identification of common molecular subsequences. Journal of Molecular Biology. Volume 147, Issue 1, 25 March 1981, Pages 195-197 Dadas duas sequências de letras, o algoritmo encontra o local ótimo de alinhamento. O pacote text.alignment do UDPipe aplica o algoritmo a palavras e letras, tentando identificar regiões similares entre duas strings. Você pode conferir um vignette do pacote (no linguajar do R, “vignette” é um guia rápido, com exemplo passo a passo) ou o manual. Com este pacote é possível: - encontrar palavras em documentos mesmo com grafia incorreta - Encontrar sequências de um texto em outros. Bom para comparar traduções ou identificar plágios. # traducao Nelson Jahr Garcia txt1 = &quot;E esqueceu-se de acrescentar: a primeira vez como tragédia, a segunda como farsa.&quot; # traducao Boitempo txt2 = &quot;Ele se esqueceu de acrescentar: a primeira vez como tragédia, a segunda como farsa.&quot; text.alignment::smith_waterman(txt1, txt2) ## Swith Waterman local alignment score: 153 ## ---------- ## Document a ## ---------- ## E ###esqueceu-se de acrescentar: a primeira vez como tragédia, a ## segunda como farsa. ## ---------- ## Document b ## ---------- ## e se esqueceu### de acrescentar: a primeira vez como tragédia, a ## segunda como farsa. Repare que em ambas as frases, preencheu-se com o sinal de tralha (#) até os textos ficarem alinhados. O modo padrão da função é buscar por caracteres, mas podemos mudar o padrão para palavras, o que pode ser mais adequado para nosso caso. text.alignment::smith_waterman(txt1, txt2, type = &quot;words&quot;) ## Swith Waterman local alignment score: 23 ## ---------- ## Document a ## ---------- ## se ######## de acrescentar a primeira vez como tragédia a segunda como ## farsa ## ---------- ## Document b ## ---------- ## se esqueceu de acrescentar a primeira vez como tragédia a segunda como ## farsa Dicas Analise Textual Julia Silge Learn tidytext with my new learnr course. Um curso interativo do pacote Tidytext. Textos sobre análise textual CASTELFRANCHI, Yurij. A análise de textos auxiliada pelo computador: um laboratório a céu aberto para as ciências sociais. Journal of Science Communication 16(02)(2017)C04 GRIMMER, Justin.STEWART, Brandom. Text as Data: The Promise and Pitfalls of Automatic ContentAnalysis Methods for Political Texts. Political Analysis(2013) pp. 1–31. doi:10.1093/pan/mps028. TREADWELL, Donald. Content Analysis: Understanding Text and Image in Numbers. Understanding Text and Image in Numbers. In __ Introducing Communication Research: paths of Inquiry. Sage. 2014. (Capítulo sobre análise de conteúdo) Link para diversos artigos de Gary King sobre Automated Text Analysis. Vídeos BROWN, Taylor W. Workshop on automated text analysis no Summer Institute in Computational Social Science na Universidade de Oxford em 2019. Em inglês, sem legendas, usando o pacote Quanteda. Parte 1 e Parte 2. O material da aula no Google Drive. "],["análise-de-redes-sociais.html", "10 Análise de Redes Sociais 10.1 O pacote Igraph 10.2 Os pacotes ggraph e tidygraph . Construindo grafos com o tidyverse. 10.3 Redes de palavras 10.4 Redes de citação 10.5 Gráfico de centralidade 10.6 Comunidades 10.7 Sugestões de links", " 10 Análise de Redes Sociais O R possui diversos pacotes para análise de rede, como o igraph, statnet, e do tidyverse temos tydygraph e ggraph. 10.1 O pacote Igraph Instalando o pacote igraph: install.packages(&quot;igraph&quot;) # instalando o pacote chamando o pacote já instalado library(igraph) # chamando o pacote já instalado ## ## Attaching package: &#39;igraph&#39; ## The following objects are masked from &#39;package:purrr&#39;: ## ## compose, simplify ## The following object is masked from &#39;package:tidyr&#39;: ## ## crossing ## The following object is masked from &#39;package:tibble&#39;: ## ## as_data_frame ## The following objects are masked from &#39;package:lubridate&#39;: ## ## %--%, union ## The following objects are masked from &#39;package:dplyr&#39;: ## ## as_data_frame, groups, union ## The following objects are masked from &#39;package:stats&#39;: ## ## decompose, spectrum ## The following object is masked from &#39;package:base&#39;: ## ## union Pegando o famoso poema de Drummond: “João amava Teresa que amava Raimundo que amava Maria que amava Joaquim que amava Lili que não amava ninguém” E o transformando em um grafo (os “gráficos” em análise de rede recebem este nome): library(igraph) g &lt;- graph.empty(directed = TRUE) # &quot;directed&quot; implica distinguir entre &quot;de&quot; e &quot;para&quot; na relação entre os nós. # Adicionando os vértices. g &lt;- g + vertex(&quot;João&quot;) g &lt;- g + vertex(&quot;Teresa&quot;) g &lt;- g + vertex(&quot;Raimundo&quot;) g &lt;- g + vertex(&quot;Maria&quot;) g &lt;- g + vertex(&quot;Joaquim&quot;) g &lt;- g + vertex(&quot;Lili&quot;) # Especificando as relações entres os vértices, os edges g &lt;- g + edges(&quot;João&quot;, &quot;Teresa&quot;) g &lt;- g + edges(&quot;Teresa&quot;, &quot;Raimundo&quot;) g &lt;- g + edges(&quot;Raimundo&quot;, &quot;Maria&quot;) g &lt;- g + edges(&quot;Maria&quot;, &quot;Joaquim&quot;) g &lt;- g + edges(&quot;Joaquim&quot;, &quot;Lili&quot;) plot.igraph(g) # plotando o grafo Neste caso, poderíamos ter feito este mesmo grafo com código mais compacto: library(igraph) g &lt;- graph.empty(directed=TRUE) # Adicionando os vértices. g &lt;- g + vertex(c(&quot;João&quot;, &quot;Teresa&quot;, &quot;Raimundo&quot;, &quot;Maria&quot;, &quot;Joaquim&quot;, &quot;Lili&quot;)) # Adicionando os edges em pares g &lt;- g + edges(c(&quot;João&quot;, &quot;Teresa&quot;, &quot;Teresa&quot;, &quot;Raimundo&quot;, &quot;Raimundo&quot;, &quot;Maria&quot;,&quot;Maria&quot;, &quot;Joaquim&quot;,&quot;Joaquim&quot;, &quot;Lili&quot;)) plot.igraph(g) Se o grafo sobe ou desce, pouco importa para nós aqui, importa as pessoas e as relações entre elas. Repare que os edges são entendidos aos pares. Se fizéssemos um vetor sem as devidas repetições, teríamos um gráfico errado das relações: g &lt;- graph.empty(directed=TRUE) g &lt;- g + vertex(c(&quot;João&quot;, &quot;Teresa&quot;, &quot;Raimundo&quot;, &quot;Maria&quot;, &quot;Joaquim&quot;, &quot;Lili&quot;)) g &lt;- g + edges(c(&quot;João&quot;, &quot;Teresa&quot;, &quot;Raimundo&quot;, &quot;Maria&quot;,&quot;Joaquim&quot;, &quot;Lili&quot;)) plot.igraph(g) Ou com código modo mais econômico ainda: g &lt;- graph.formula( João --+ Teresa --+ Raimundo --+ Maria --+ Joaquim --+ Lili ) plot(g) &lt; https://economia.estadao.com.br/noticias/geral,incra-reduz-assentamento-no-para-mineracao-ouro,70003919108!-- g &lt;- g + edges(“Diana”, “William”) –&gt; : :mineração: Incra vai reduzir assentamento no PA para favorecer mineração de ouro em troca de fazenda em MT - Economia - Estadão Cerca de 600 famílias serão afetadas, mas Incra diz não ter encontrado terra legalizada que pudesse ser adquirada para os assentados Vamos visualizar o exemplo de Franzosi que vimos anteriormente na seção . Transcrevi os dados da tabela 5. franzosi &lt;- &quot;Subject Action Object Frequency Fascists violence Workers 871 Fascists violence People 677 Fascists violence Socialists 482 Fascists violence Individuals 324 Police violence Workers 207 Individuals violence Workers 174 Police violence People 129 Fascists violence workers_agric 126 Police violence Protesters 92 Police violence workers_agric 88 Fascists violence Communists 87 Police violence Socialists 84 Police Violence Individuals 81 Individuals Violence Individuals 69 Workers Violence Fascists 56&quot; Vamos carregar o texto como uma tabela tabelaFranzosi &lt;- read.table(text = franzosi, header = TRUE, sep = &quot; &quot;) str(tabelaFranzosi) ## &#39;data.frame&#39;: 15 obs. of 4 variables: ## $ Subject : chr &quot;Fascists&quot; &quot;Fascists&quot; &quot;Fascists&quot; &quot;Fascists&quot; ... ## $ Action : chr &quot;violence&quot; &quot;violence&quot; &quot;violence&quot; &quot;violence&quot; ... ## $ Object : chr &quot;Workers&quot; &quot;People&quot; &quot;Socialists&quot; &quot;Individuals&quot; ... ## $ Frequency: num 871 677 482 324 207 174 129 126 92 88 ... Plotando o grafo com o qgraph: library(ggraph) # a coluna Action não nos interessa,vamos retirá-la tabelaFranzosi2 &lt;- tabelaFranzosi[,c(1,3,4)] # transformando o dataframe em grafo grafoFranz &lt;- igraph::graph_from_data_frame(tabelaFranzosi2) # Usando o qgraph qgraph::qgraph(tabelaFranzosi2, title= &quot;Violência entre grupos durante o fascismo na Itália da primeira metade do século XX&quot;) tabelaFranzosi2 |&gt; ggraph::ggraph() + geom_edge_fan(aes(colour = stat(&quot;Subject&quot;)), show.legend = TRUE) + geom_node_point(aes(size = &quot;Object&quot;, colour = &quot;Frequency&quot;), show.legend = TRUE) + # scale_colour_gradient(low = &quot;steelblue&quot;, high = &quot;black&quot;) + theme_graph(foreground = &#39;steelblue&#39;, fg_text_colour = &#39;yellow&#39;) + labs(title= &quot;Violência intragrupos durante o fascismo na Itália na primeira metade do século XX&quot;, caption= &quot;Fonte: compilado com base em Franzosi ()&quot;) ## Using `stress` as default layout ## Warning: Using size for a discrete variable is not advised. qgraph::qgraph(tabelaFranzosi[,c(1,3,4)]) novodf &lt;- tabelaFranzosi[,c(1,3,4)] # renomeando as colunas colnames(novodf) &lt;- c(&quot;vertex&quot;, &quot;edges&quot;, &quot;n&quot;) igraph::plot.igraph(novodf) 10.1.1 Clusterização EM CONSTRUÇÃO 10.2 Os pacotes ggraph e tidygraph . Construindo grafos com o tidyverse. O pacote ggraph é um pacote elaborado por Thomas Lin Pedersen, o mesmo do ggplot2, e pretende ser uma extensão deste, usando a mesma gramática de gráficos, o que nos dá grande flexibilidade visual. Com o ggraph é possível construir graficamente redes, mas ele vai além dos grafos, construindo também dendogramas, diferentes tipos de árvores, matrizes, gráficos hierárquicos, diagrama de arc, sunburst, etc. Para inserir os dados no ggraph, é necessário colocá-lo no formato “tidy” do “tidyverse”, e fazemos isso com o pacote tidygraph: Para instalar, usamos os comandos: install.packages(&#39;ggraph&#39;) install.packages(&#39;tidygraph&#39;) Carregando os pacotes library(ggraph) library(tidygraph) ## ## Attaching package: &#39;tidygraph&#39; ## The following object is masked from &#39;package:igraph&#39;: ## ## groups ## The following object is masked from &#39;package:quanteda&#39;: ## ## convert ## The following object is masked from &#39;package:stats&#39;: ## ## filter Seguindo o exemplo na página do criador do GGraph Thomas Lin Pedersen, vamos usar o dataset highschool do ggraph, que contém dados sobre a evolução da amizade entre garotos numa escola do ensino médio no Illinois, que nos anos de 1957 e 1958 responderam à pergunta: “Com que colegas desta escola você anda mais frequentemente?”. Esta pesquisa apareceu originalmente nos livros “Introduction to Mathematical Sociology” e “The Adolescent Society”, ambos do sociólogo James Coleman. Para obter mais informações sobre este dataset, basta digitar no console: help(highschool). str(highschool) # observando a estrutura do data frame ## &#39;data.frame&#39;: 506 obs. of 3 variables: ## $ from: num 1 1 1 1 1 2 2 3 3 4 ... ## $ to : num 14 15 21 54 55 21 22 9 15 5 ... ## $ year: num 1957 1957 1957 1957 1957 ... head(highschool,10) # observado as primeiras linhas do data frame ## from to year ## 1 1 14 1957 ## 2 1 15 1957 ## 3 1 21 1957 ## 4 1 54 1957 ## 5 1 55 1957 ## 6 2 21 1957 ## 7 2 22 1957 ## 8 3 9 1957 ## 9 3 15 1957 ## 10 4 5 1957 Vemos que há na coluna 1 de (“from”) pessoa número X para (“to”) para pessoa Y no ano (“year”). Assim, a pessoa 1 teve contato com as pessoas 14, 15, 21, 54 e 55 em 1957. A pessoa 2 teve contato com as pessoas 21 e 22, e assim por diante. Vamos preparar os dados para plotar o grafo com ggraph. Antes, é necessário colocá-lo no formato “tidy” do “tidyverse”, e fazemos isso com o pacote tidygraph. A função as_tbl_graph() do pacote tidygraph funciona como a função grouped_df(), que agrupa nós (nodes) e arestas (edges). as_tbl_graph(highschool) ## # A tbl_graph: 70 nodes and 506 edges ## # ## # A directed multigraph with 1 component ## # ## # Node Data: 70 × 1 (active) ## name ## &lt;chr&gt; ## 1 1 ## 2 2 ## 3 3 ## 4 4 ## 5 5 ## 6 6 ## # … with 64 more rows ## # ## # Edge Data: 506 × 3 ## from to year ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1 13 1957 ## 2 1 14 1957 ## 3 1 20 1957 ## # … with 503 more rows Vamos criar uma lista chamada “grafo”, adicionando um campo novo com mutate(), de nome “Popularidade” e que vai medir a centralidade de grau através da função centrality_degree() do tidygraph. Centralidade de grau é a medida mais simples de centralidade, que conta o número de conexões, as arestas (“edges”) de cada nó. grafo &lt;- as_tbl_graph(highschool) %&gt;% mutate(Popularidade = centrality_degree(mode = &#39;in&#39;)) grafo ## # A tbl_graph: 70 nodes and 506 edges ## # ## # A directed multigraph with 1 component ## # ## # Node Data: 70 × 2 (active) ## name Popularidade ## &lt;chr&gt; &lt;dbl&gt; ## 1 1 2 ## 2 2 0 ## 3 3 0 ## 4 4 4 ## 5 5 5 ## 6 6 2 ## # … with 64 more rows ## # ## # Edge Data: 506 × 3 ## from to year ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1 13 1957 ## 2 1 14 1957 ## 3 1 20 1957 ## # … with 503 more rows Plotando o grafo: ggraph(grafo, layout = &#39;kk&#39;) + geom_edge_fan(aes(colour = stat(index)), show.legend = FALSE) + geom_node_point(aes(size = Popularidade, colour= Popularidade), show.legend = TRUE) + scale_colour_gradient(low = &quot;steelblue&quot;, high = &quot;black&quot;) + facet_edges(~year) + theme_graph(foreground = &#39;steelblue&#39;, fg_text_colour = &#39;yellow&#39;) + labs(title = &quot;Evolução da amizade entre adolescentes de uma escola no Illinóis&quot;, caption = &quot;Fonte: Elaboração própria a partir dos dados de Coleman(1961) apud ggraph (v.2.0.5; Pedersen)&quot;) layout define como os nós serão alocados. O layout do ggraph possui os mesmos do igraph e outros mais como, hive plots, treemaps e circle packing. kk indica que está sendo usado o algortimo Kamada-Kawai para dispersar os nós e facilitar nossa visualização. geom_edge_fan() desenha os laços de modo curvo. Há diversas outras opções possíveis neste caso, como: geom_edge_arc, geom_edge_bend, geom_edge_diagonal,geom_edge_elbow, geom_edge_fan, geom_edge_hive, geom_edge_link, geom_edge_parallel. Substitua geom_edge_fan() por alguns estes e vjea a diferença no grafo. colour indica que a intensidade das ligações será por um gradiente de cor, stat() indica que segue ali uma informação estatística. geom_node_point() mostra os nós como pontos/círculos e permite que sejam plotados em diferentes tamanhos, cores e formas em aes(). size = Popularidade indica que o tamanho dos nós é controlado pela variável “Popularidade” que criamos. colour = Popularidade indica que além do tamanho, a cor também vaira conforme a popularidade. Para mais opções, digite ?geom_node_point() no console ou consulte a documentação do ggraph. scale_colour_gradient(low = \"steelblue\", high = \"black\") é opcional, podendo ser retirada. Especifica o gradiente de cores do comando anterior (no caso, nós), qual o valor mais baixo até o mais elevado. Sua informação é redundante com relação ao tamanho dos nós, mas ajuda a reforçar tal informação. facet_edges() função de “faceting”, de criar facetas, gráficos multiplos, e o símbolo de til ~ seguido de year indica que o critério aqui são as categorias dentro de ano, que no caso, são 1957 e 1958. Os nós são repetidos em cada painel. Caso tivéssesmos usado facet_edges(1957) teríamos o grafo apenas do ano 1957. theme_graph especifica as cores das legendas nas facetas labs(title = \" indica o título e caption o rodapé. Veja também cheatsheet/folha de dicas do ggraph Para ver os diferentes layouts possíves do ggraph e seus respectivos códigos, para além dos grafos clique aqui CAPÍTULO A SER EXPANDIDO 10.3 Redes de palavras EM CONSTRUÇÃO 10.4 Redes de citação EM CONSTRUÇÃO 10.5 Gráfico de centralidade EM CONSTRUÇÃO 10.6 Comunidades EM CONSTRUÇÃO 10.7 Sugestões de links AQUINO, Jackson A. “Análise de redes sociais”, capítulo 12 de ___. R para cientistas sociais. Ilhéus, BA: EDITUS, 2014. 157 p. ISBN: 978-85-7455-369-6. (PDF gratuito bem introdutório com R) HIGGINS, Silvio S.; RIBEIRO, Antônio Carlos. Análise de redes em Ciências Sociais. Brasília: ENAP. 2018. 229p. (PDF Gratuito de livro. Bom para aprender os conceitos/teorias básicos de análise de rede). Static and dynamic network visualization with R Manual online do ipgraph para R; PDF do Manual do igraph para R (ambos em inglês) ggraph Documentation no Cran. d’ANDRÉA, Carlos Frederico de Brito. Pesquisando plataformas online: conceitos e métodos. EDUFBA. 2020. A obra visa introduzir os Estudos de Plataforma, um campo de estudos que, desde o início da década de 2010, discute as especificidades políticas e materiais das mídias sociais e de outras plataformas online. Datificação, algoritmos, governança e os modelos de negócio das plataformas são algumas das dimensões sintetizadas no livro. De modo didático, o autor apresenta um conjunto de leituras e de experimentações metodológicas conduzidas com um diversificado grupo de colaboradoras(es) no país e no exterior. (ebook PDF e Epub gratuitos) RECUERO, Raquel. Introdução à análise de redes sociais online. EDUFBA.2017. A Análise de Redes Sociais (ARS) é uma abordagem de pesquisa cuja popularidade tem aumentado nos últimos anos, principalmente, entre os pesquisadores da área de Comunicação. É nesse âmbito que várias obras, entre artigos e livros, vêm surgindo e introduzindo o estudo dessas estruturas a partir da análise de redes e da compreensão da representação dessas redes sociais na internet. Este livro é uma pequena compilação dos principais conceitos e elementos para a compreensão e a aplicação da ARS. É baseado em uma breve apresentação e histórico do paradigma, os principais conceitos, suas métricas e, finalmente, suas formas de representação e visualização. (ebook PDF e Epub gratuitos). LIZARDO Omar; JILBERT Isaac. Social Networks: An Introduction. 2021. (ebook online) "],["links-úteis.html", "11 Links úteis 11.1 Humanidades digitais 11.2 Análise de redes sociais 11.3 Textos sobre análise textual 11.4 Processamento Linguagem Natural (PLN ou NLP) 11.5 Revistas / Journals acadêmicos 11.6 Dados Abertos 11.7 Vídeos 11.8 Sites / Blogs 11.9 Organizações 11.10 Podcasts relacionados à Digital Humanities 11.11 Links Programação 11.12 Links de Cursos Online 11.13 Grupos de discussão/Forum 11.14 Links de folhas de dicas (Cheat-sheets) 11.15 Alguns datasets/databases para análise textual", " 11 Links úteis Segue aqui uma lista com links para livros, artigos, sites, manutais, tutoriais, vídeos e canais de vídeos. A maioria e a prioridade é de material gratuito, sobre temas gerais relacionados a humanidades digitais e em especial, à sociologia. Há também sugestões mais focadas nos assuntos específicos nos capítulos. O critério de seleção aqui foi o de contribuição para esclarecer o potencial das humanidades digitais para quem inicia na área de humanidades digitais/sociologia digital. Os itens não foram selecionados tanto pela contribuição científica, mas com base no critério de exemplos que podem ajudar a esclarecer o potencial das humanidades digitais para quem inicia. 11.1 Humanidades digitais Introduction to Digital Humanities Textbook A digital textbook designed for UCLA’s Introduction to Digital Humanities course website. (ebook disponível gratuito online) EDMOND, Jennifer Digital Technology and the Practices of Humanities Research. (Livro gratuito) The Data Journalism Handbook. Towards a Critical Data Practice. 415p. 2021. ISBN 9789048542079. (Livro GRATUITO). BAUER, Paul C. Computational Social Science: Theory &amp; Application. (livro online grátis). 11.2 Análise de redes sociais ver - Ver sugestões Ver sugestões no capítulo “Análise de Redes Sociais”. 11.3 Textos sobre análise textual GRIMMER, Justin.STEWART, Brandom. Text as Data: The Promise and Pitfalls of Automatic ContentAnalysis Methods for Political Texts. Political Analysis(2013) pp. 1–31. doi:10.1093/pan/mps028. CASTELFRANCHI, Yurij. A análise de textos auxiliada pelo computador: um laboratório a céu aberto para as ciências sociais. Journal of Science Communication 16(02)(2017)C04 TREADWELL, Donald. Content Analysis: Understanding Text and Image in Numbers. Understanding Text and Image in Numbers. In __ Introducing Communication Research: paths of Inquiry. Sage. 2014. (Capítulo sobre análise de conteúdo) 11.3.1 Sociologia Digital / Sociologia Computacional KATEMBERA, Serge. “Sociologia digital ou sociologia do digital?” V. 2 N. 1 (2020): Dossiê Ambiente e Sociedade. (Artigo) NASCIMENTO, Leonardo F. Sociologia digital : uma breve introdução. EDUFBA. 2020. (Livro gratuito em PDF e epub) Podcast “New Work in Digital Humanities”. Episódio: Neil Selwyn, “What is Digital Sociology?” (Polity, 2019) BERNAU, John A. Text Analysis with JSTOR Archives. November 12, 2018 https://doi.org/10.1177/2378023118809264. (Aplicação de métodos de humanidades digitais, usando a base do Jstor, para uma rápida análise de variação temática em revistas sociológicas). FUSSEY, Pete e ROTH, Silke (ed.) Digitizing Sociology. edição da revista “Sociology” da British Sociological Association. Evans J, Foster JG. Computation and the Sociological Imagination. Contexts. 2019;18(4):10-15. doi:10.1177/1536504219883850 11.3.1.1 Netnografia, etnografia digital MARKHAM, Annette N. 2013. Fieldwork in Social Media. Qualitative Communication Research 2, 4 (Dec. 2013), 434–446. https://doi.org/10.1525/qcr.2013.2.4.434 SHAFFER, David Williamson. Quantitative Etnography. Boswell Press. 2017. “This is a book about understanding why, in the digital age, the old distinctions between qualitative and quantitative research methods, between the sciences and humanities, and between numbers and understanding, limit the kinds of questions we can ask, in some cases, and lead us accept superficial answers in others. Quantitative Ethnography is a research method that goes beyond those distinctions to help us understand how to make sense of our increasingly data-rich world…”. (PDF da Introdução disponível gratuitamente) 11.4 Processamento Linguagem Natural (PLN ou NLP) JURAFSKY, D.; MARTIN, J. Speech and language processing: An introduction to speech recognition, computational linguistics and natural language processing. Upper Saddle River, NJ: Prentice Hall, 2020. link pdf dos capítulos individuais, link livro completo. (Um manual bastante extenso e mais teórico sobre PLN) BIRD, S.; KLEIN, E.; LOPER., E. Natural language processing with Python – analyzing text with the natural language toolkit. (Livro online gratuito, baseado em Python 3.) Playlist no Youtube das aulas da Stanford University sobre PLN 11.5 Revistas / Journals acadêmicos SIGCAS Computers and Society da Association for Computing Machinery Digital Scholarship in the Humanities. Revista da Universidade de Oxford. Sessão com artigos gratuitos Journal: Digital humanities Quartely International Journal of Digital Humanities Socius: Sociological Research for a Dynamic World. Special Collection: Data Visualization. Jornal de acesso livre International Journal of Humanities and Arts Computing (Universidade de Edimburgo) magazén International Journal for Digital and Public Humanities. (open access). Revista do Dipartimento di Studi Umanistici da Università Ca’ Foscari de Veneza Journal of Digital Social Research. Open Access Reviews in Digital Humanities. (O Review já não publica desde 2014) Journal of Digital Humanities. (O Journal of DH tem uma sessão de resenha de novas ferramentas disponíveis). Journal of Cultural Analytics. Department of Languages, Literatures, and Cultures at McGill University, Canada. open-access journal dedicated to the computational study of culture 11.6 Dados Abertos Episódio 005 do Podcast “História FM Acesso à informação: como fazer uso da Lei de Acesso? com Maria Vitória Ramos e Luiz Fernando Toledo, do projeto Fiquem Sabendo. Ou ainda no Spotify. 5 estrelas dos dados abertos (Tim Berners-Lee, criador do termo “dados abertos”. Site explica o que são dados abertos e seus 5 níveis. Em português) Busca do Google por base de dados Abertos Dados abertos. (Se não sabe onde encontrar algum dado específico que você procura, veja aqui) SHIKIDA, Claudio D., MONASTERIO, Leonardo, NER, Pedro Fernando. Guia Brasileiro de Análise de Dados: Armadilhas e Soluções. Brasília. 2021. ( Tópicos: Causalidade, Pobreza e Desigualdade, Análise de dados em Saúde, Educação, Crimes e Violência, Macroeconomia, Mercado e Trabalho e Opinião Pública.) Dados Abertos: Fórum de discussão. Workshop do Henrique Xavier, no canal “Base dos Dados” sobre como explorar os dados do Diário Oficial da União. Como usar a biblioteca basedosdados no R. Pacote basedosdados do R para baixar diversas bases de dados. Data sets do Brasil.io, um “repositório de dados públicos disponibilizados em formato acessível” como “Eleições Brasil”, “Cursos e notas de corte do Prouni 2018”, gastos de deputados e do governo federal, salários de magistrados, etc. 11.7 Vídeos Vídeos do 1º Summerschool of Digital Humanities da Universidade de Heidelberg, Alemanha, ocorrido em 2017. link. (Em inglês) 11.8 Sites / Blogs Text analysis info Textual Analysis - University of Notre Dame Site Digital Humanities Now. (Agrega oportunidade de emprego, notícias, bolsas de pesquisa). site Go Digital Humanities. (Novidades sobre humanidades digitais, como eventos). Blog Digital Society Blog. (Blog do Institut für Internet und Gesellschaft da Alexander von Humboldt). Site The Programming Historian, com diverso conteúdos em português. 11.9 Organizações Alliance of Digital Humanities Organizations (ADHO). Global Network of Internet and Society Research Centers (NoC) i. (Catálogo com grupos de pesquisa sobre internet e sociedade ao redor do mundo). 11.10 Podcasts relacionados à Digital Humanities Pizza de Dados. Podcast em portugês sobre ciência de dados. Episódio 032 com a Gabriela de Queiroz, fundadora do R-Ladies e do AI inclusive. Complexity: Peter Dodds on Text-Based Timeline Analysis &amp; New Instruments for The Science of Stories New Work in Digital Humanities. New Books Network. Interviews with digital humanists about their new work. Lista com mais podcasts dedicados às digital humanities Letsdata. Podcast em português 11.11 Links Programação 11.11.1 R introdução LENTE, Caio. Zen do R. “O objetivo deste livro é ensinar ao leitor que não costuma programar algumas formas simples de melhorar a organização de seus projetos de análise de dados em R”. (Livro online gratuito). AQUINO, Jackson A.. R para cientistas sociais. Ilhéus, BA: EDITUS, 2014. 157 p. ISBN: 978-85-7455-369-6. (PDF gratuito) Livro Curso-R (em construção) Blog: Curso-R KUBRUSLY, Jessica. Uma Introdução à Programação com o R. (ebook online em português) FREIRE, Sergio Miranda. Introdução ao R. (Livro online, no formato bookdown) WICKHAM, Hadley. Advanced R. 2nd edition. (Livro online gratuito, no formato bookdown, em inglês, para entender melhor os conceitos do R). 11.11.2 R e estatística FERREIRA, E.B.;. de OLIVEIRA, M.S. Introdução à Estatística com R. Unifal. 2020. (PDF gratuito). Gareth James; Daniela Witten; Trevor Hastie; Robert Tibshirani. An Introduction to Statistical Learning with Applications in R. Segunda edição. 2021. Possui conteúdo sobre regressões, métodos de classificação, deep learning, aprendizado não supervisionado, K-means, Naives Bayes. PDF gratuito 11.11.3 R - tópicos específicos WICKHAM, H. GROLEMUND, Garret. R for Data Science. O’Reilly. 2017. (Livro Online, em inglês). IRIZARRY, Rafael A. Introduction to Data Science. Livro Online, em inglês, feito como notas de aulas da HarvardX Data Science Series CLARK, Michael. R &amp; Social Science. Getting Started with applied use of R in the Social Sciences. (pequeno manual em PDF da Universidade de Notre Dame) ggplot2 on-line version of work-in-progress 3rd edition of “ggplot2: elegant graphics for data analysis” SILGE, Julia, ROBINSON, David Text Mining with R. (ebook online) RYDBERG-COX, Jeff. Statistical Methods for Studying Literature Using R da Universidade Missouri-Kansas City. R-tutor- An R Introduction to Statistics. Site com tutoriais diversos sobre R. Em Inglês. Diversos links para livros gratuitos de R no bookdown. 11.11.4 R - avançado WICHKAM, Hadley (2014). Advanced R. Ed: Chapman and Hall/CRC. Livro gratuito. 11.11.5 Links Python Aprenda Computação com Python. Livro online em português de introdução ao Python. A Whirlwind Tour of Python. PDF disponível gratuitamente. HEINOLD, Brian. A Practical Introduction to Python Programming. 2012. 263 p. (PDF de introdução ao Python) Jake VanderPlas. Python Data Science Handbook: Essential Tools for Working with data. (livro online). 11.11.6 Python - tópicos específicos KARSDORP, Folgert. Python Programming for the Humanities. Livro online. Pyhton Humanities. Site com introdução às DH em Python, com alguns tutoriais. Constellate What do you want to learn today?. (Projeto Constellate da JStor junto a diversas universidades. Conta com sessão com tutoriais sobre análise textual, a maioria em Python. 11.12 Links de Cursos Online EdX, Cursos online de Universidades como Harvard, MIT, etc. gratuitos como ouvinte. Paga-se pelo certificado. Há cursos grautuitos, como “Introducing Text Analytics and Natural Language Processing with Python”, “Introduction to Digital Humanities”, “Data Science: Visualization”, “Using Python for Research”. DataCamp. Cursos mais práticos, em R, Python, SQL, com exercícios, totalmente online (não é necessário instalar nada em seu computador). As partes iniciais dos cursos costumam ser gratuitas, mas há parte paga com anuidades. Udemy Possui cursos gratuitos e cursos pagos. É possível encontrar cursos pagos por volta de R$20,00. Coursera. Possui parceria com mais de 200 universidades e empresas como o Google e IBM. Cognitive Class Da IBM, Cursos gratuitos em data science, alguns gratuitos com certificado. Cursos em inglês e espanhol. Possui cursos como “Data Visualization with R”. Big Data University. Cursos em Portugues. Curso gratuito de Estatística e probabilidade da Khan Academy, em português. Inclui teste de hipótese, regressão. 11.13 Grupos de discussão/Forum 11.13.1 Telegram Processamento de Linguagem Natural em Português PT-Br Data Science - Python R Brasil R e Rstudio Humanidades Análise Textual-Humanidades Digitais 11.14 Links de folhas de dicas (Cheat-sheets) “Cheat sheets” seriam a tradução para “cola”, aquela feita para consulta em exames na escola. Em programação, refere-se a uma tabela muito bem resumida, com o que há de essencial em determinado assunto. Text Analysis Glossary Um glossário de termos usados na análise textual, em inglês, do projeto Constellate (JStor e diversas universidades) Lista com mais de 100 cheat-sheets em R e Python, sobre Machine Learning: link Git-GitHub, Git-Gitlab, Cheatsheets do R como: Base R, Base R em portguês, Data-table em português, Data Import, Data e horários com Lubridate, trabalhe com mais facilidade com listas e funções com o purr, stringr, dplyr, R Reference Card, Usar Python no R com reticulate, ggplot, R Markdown com o R Markdown Cheatsheet ou o Reference Guide, Regular Expressions, R Programming por Arianne Colton e Sean Chen, Uma lista com estes e outros cheatsheets aqui do Rstudio aqui. 11.15 Alguns datasets/databases para análise textual Alguns pacotes R com datasets inclusos em pacotes que podem ser interessantes para análise textual: data(presidential_debates_2012) do pacote textstem, um dataset com versão limpa de três debates presidenciais dos EUA da eleição de 2012. “acq” do pacote tm contém 50 artigos da Reuters e suas meta-informações, referentes à aquisições corporativas; ou “crude” do pacote tm com 20 artigos, também da Reuters, que versam sobre “crude oil”. pacote corpus: Text Corpus Analysis. Possui estas base de dados: federalist com os 85 textos dos federalistas, um texto por linha. gutenberg_corpus corpus de textos do projeto Gutenberg, criando um texto por linha. Discursos inaugurais dos presidentes dos EUA, no pacote data_corpus_inaugural do Quanteda. Pacote Harry Potter com texto completo dos sete primeiros livros. Para instalar, use o comando devtools::install_github(\"bradleyboehmke/harrypotter\") e para carregá-lo library(harrypotter). Requer o pacote devtools instalado. Datasets em sites diversos: Site do Projeto Gutenberg possui diversos livros gratuitos em formato texto puro e gratuito. O pacote gutenbergr pode auxiliar neste processo. Tweets de Trump no The Trump Archive ou já no formato R com trump_tweets: Trump Tweets from2009 to 2017. fivethyrteight russian troll tweets: 2,973,371 tweets da “fábrica de trolls” da Agência de Pesquisa da Internet da Rússia, que foram usados para tentar influenciar as eleições nos EUA. Mais detalhes em Why We’re Sharing 3 Million Russian Troll Tweets que virou um working paper Troll Factories: The Internet Research Agency and State-Sponsored Agenda Building. Datasets no Kaggle: Star Trek Scripts. “Raw text scripts and processed lines of all Star Trek series scripts”. (Necessita de conta no Kaggle). Lista com 31 datasetes para datascience, contendo, por exemplo, dataset com 300k de artigos da CNN, outro com o Wiki how to, outro com coleção de papers do Arxiv, outro com texto completo de artigos relacionados à Covid-19, coleção sobre filmes do Neflix, dentre outros. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
