[["objetivos-deste-manual.html", "Introdução Análise Textual aplicada à Sociologia Objetivos deste manual Plano do livro", " Introdução Análise Textual aplicada à Sociologia Alisson Soares 2021-05-12 Objetivos deste manual Sou Alisson Soares, sociólogo, e comecei há pouco tempo no campo das humanidades digitais. Achei por bem montar este manual como uma forma de compartilhar o que venho aprendendo. Algumas ferramentas, softwares serão de modo gráfico, mas por vezes vamos recorrer à programação. A principal linguagem aqui será o R, mas o uso de Python não está completamente excluído. O objetivo deste manual é: Ser um livro em progresso constante. Ser introdutório, mas também sempre indicar bons materiais para maior aprofundamento dos temas tratados. Sempre que possível, oferecer material em português, apesar de nem sempre isto ser possível. Oferecer uma introdução às ferramentas computacionais utilizadas em pesquisa das ciências sociais. Usar preferencialmente ferramentas gratuitas e de código aberto. Sempre que possível, apresentar exemplos de pesquisa e ciência social utilizando estas ferramentas. Plano do livro Os capítulos planejados até o momento, muito já em elaboração: História da Análise Textual Rápida introdução à programação (conceitos básicos como variável, loops, condicionais if-else, função, etc.) Normalização e expressões regulares. Rápida introdução ao R (tipos de dados, estrutura de dados, importação de dados) Introdução à análise textual via computador Frequência de termos (bag of words, n-grams, skipgrams, TF-IDF) dendogramas Correlação, tipos de distâncias Introdução à análise de redes. Inteligência Artificial: clusterização; topic modelling Análise de sentimentos. "],["intro.html", "Capítulo 1 Introdução 1.1 O termo “humanidade digitais”", " Capítulo 1 Introdução “the best digital theory-building of the past decade stems from social and computational origins. As such, it is increasingly apparent that digital sociologists need to develop a computational as well as a sociological imagination.” 1.1 O termo “humanidade digitais” Segundo um estudo do LinkedIn em 15 países, prevendo 150 milhões de vagas nos próximos 5 anos, das áreas de trabalhos digitais em alta e 2021, duas se relacionam a Humanidades Digitais: Big data Analytics (segundo lugar) e “Text, image and voice processing” (6º lugar). Profissionalmente, pode ser interessante entrar nesta área. Existem diversos termos correlatos a “Humanidades digitais” (“Digital humanities”), como “E-humanities,”Cultural Analytics“,”ciências sociais computacionais“,”sociologia digital“,”história digital“,”etnografia digital“,”etnografia quantitativa“,”Análise cultural quantitativa\" (quantitative cultural analysis) “cultural analytics”, “humanities data science”, “humanities data analysis” “humanities computing”, “distant reading”, “computational social science”, etc. Humanidades digitais inclui a análise de: sons/música, imagens. textos. Nosso objetivo aqui valores &lt;- c(12, 34, 13) # atribuindo nomes ao vetor acima nomes &lt;- c(&quot;banana&quot;, &quot;uva&quot;, &quot;abacate&quot;) # criando o vetor names(valores) &lt;- nomes names ## function (x) .Primitive(&quot;names&quot;) "],["história-da-análise-textual.html", "Capítulo 2 História da Análise Textual 2.1 Linha do tempo da história da Análise Textual", " Capítulo 2 História da Análise Textual “May we hope that when things come to such a crisis, human labor of the literary sort may be in part superseded by machinery? Machinery has done wonders, and when we think of what literature is becoming, it is certainly to be wished that we could read it by machinery, and by machinery digest it” (Andrew Stauffer In London’s Daily News. 15 de Setembro de 1869 apud Catherine DeRose.) A análise textual abarca campos do conhecimento bem variados, como psicologia, ciências da computação, ciências da informação, linguística, ciência política, sociologia, etc. Apresentamos aqui uma linha do tempo com alguns dos principais eventos relacionados à análise textual, bem como ao seu uso com computadores. De modo resumido, podemos pensar nos primeiros desenvolvimentos ao final do século XIX, a introdução do computador e mais recentemente, a introdução da inteligência artificial como pontos marcantes nesta cronologia. Fizemos aqui uma breve cronologia, que não pretende ser extensiva, com todos eventos importantes, mas apenas demarcar alguns pontos interessantes, para ajudar a dar alguma ideia àqueles que iniciam no campo das humanidades digitais e na sociologia digital. 2.1 Linha do tempo da história da Análise Textual 1887 Medenhall. Anaisa o comprimento de palavras: MENDENHALL, T. C. . The characteristic curves of composition. Science.Vol ns-9, Issue 214S. 11 March 1887. baixar pdf Wincenty Lutoslawski. Análise de palavras raras na obra de Platão. Cunhou o termo “estilometria” Lutoslawski’s Origin and Growth of Plato’s Logic - The Origin and Growth of Plato’s Logic, 1888 Benjamin Bourdon (1860-1943, psicólogo e professor da Université de Rennes): Ao pesquisar sobre a expressão de emoções através de palavras, analisou o livro “Exodus” da Bíblia e calculou frequências, classificou e eliminou as stopwords. “In 1888, in a research on the expression of emotions through words, Benjamin Bourdon analysed the Exodus of the Bible and calculated the frequencies by rearranging and classifying them, eliminating the stop words” fonte. 1888 Friedrich Kaeding (1855 - 1929), cria índices de frequência para estruturação de sistemas estenográficos (sistema de escrita por abreviações para que a escrita seja tão rápida como a fala). 1934 Harold Laswell (1902-1978, cientista político) produz a primeira contagem de palavras chave. 1934 Vygostky produz a primeira análise quantitativa de narrativa 1949 Robert Busa (padre jesuíta) junto à IBM com o projeto Index Thomisticus, que levou 34 anos, envolveu cerca de 70 pessoas, sobre as obras de São Tomás de Aquino. “The IBM… considered this first enterprise of using a computer for linguistic and lexicographic goals as a pilot-project” fonte, indexando mais de 10 milhões de palavras. Busa, R. (1980). “The Annals of Humanities Computing: The Index Thomisticus”. Computers and the Humanities. 14 (2): 83–90. doi:10.1007/BF02403798. ISSN 0010-4817. ROCKWELL, Geoffrey; PASSAROTTI, Marco (2019-05-27). “The Index Thomisticus as a Big Data Project”. Umanistica Digitale (5). doi:10.6092/issn.2532-8816/8575. 1950 Gottschalk usa Content Analysis para rastrear temas freudianos. GOTTSCHALK, Louis A. The Measurement of Psychological States Through the Content Analysis of Verbal Behavior. University of California Press. 1969. 317p. Gottschalk-Gleser Content Analysis Method of Measuring the Magnitude of Psychological Dimensions 1950 Alan Turing aplica Inteligência Artificial a textos. 1952 Bereleson publica o primeiro manual de análise de conteúdo. BERELSON, B. (1952). Content analysis in communication research. New York: Hafner. 1954 Primeira tradução automática de texto (Georgetown–IBM experiment) do russo ao inglês. HUTCHINS, John. The first public demonstration of machine translation: the Georgetown-IBM system, 7th January 1954. 2006. Press Release da IBM 1963 Mosteller e Wallace analisam a autoria dos Federalist Papers. MOSTELLER, F., WALLACE, D. L.. 1963. Inference in an authorship problem. Journal of the American Statistical Association 58:275–309. 1965 Tomashevsky formaliza análise quantitativa de narrativa. TOMASHEVSKY, B. (1965). Thematics. In L T. Lemon &amp; M. I. Reis (Eds. &amp; Trans.), Russian formalist criticism: Four essays (pp. 61-95). Lincoln: University of Nebraska Press. (Original de 1925) 1966 Stones e Bales usam computador para medir propriedades psicométricas de textos na RAND. 1980 Declínio do formalismo chomskyano; nascimento do Processamento de Linguagem Natural (PLN). 1980 Aplicação de Aprendizado de máquinas (Machine Learning) ao Processamento de Linguagem Natural 1981 Walter Weintraub e a contagem de parts-of-speech. WEINTRAUB, Walter. Verbal Behavior: adaptation and psychopathology. Springer:NY. 1981. SOBEL, Dava. Language patterns reveal problems in personality. NYT. Oct. 27,1981. 1985 Schrodt introduz codificação automática de eventos (Automated Event Coding). SCHRODT, Philip A. Automated Coding Of International Event Data Using Sparse Parsing Techniques. 2000. 1986 James W. Pennebaker desenvolve LIWC (Linguistic Inquiry and Word Count). 1989 Roberto Franzosi (perfil no Research Gate) (sociólogo) traz a análise de narrativa quantitativa (quantitative Narrative Analysis) para as Ciências Sociais. 1998 Primeiro desenvolvimento de Topic Models. 1998 John W Mohr conduz a primeira análise quantitativa de visões de mundo. 1999 Peter Bearman (sociólogo) et al. aplicam métodos de rede a narrativas “Narrative network”. 2001 David M. Blei et al desenvolvem a LDA (Latent Dirichlet Allocation). David M. Blei, Andrew Y. Ng, Michael I. Jordan. Latent Dirichlet Allocation. Journal of Machine Learning Research 3 (2003) 993-1022. github Blei Lab. 2003 MALLET (MAchine Learning for LanguagE Toolkit), um dos primeiros sistemas de topic models, é criado. “MALLET is a Java-based package for statistical natural language processing, document classification, clustering, topic modeling, information extraction, and other machine learning applications to text. MALLET includes sophisticated tools for document classification: efficient routines for converting text to”features“, a wide variety of algorithms (including Naïve Bayes, Maximum Entropy, and Decision Trees), and code for evaluating classifier performance using several commonly used metrics.” 2005 Quin et al analisam discursos políticos usando topic models. Kevin M Quinn, Burt L Monroe, Michael Colaresi,Michael H Crespin, and Dragomir R Radev. 2010. How to analyze political attention with minimal assumptions and costs. American Journal of Political Science54(1):209–228 2010 Gary King e Daniel Hopkins trazem Topic Models ao mainstream. Hopkins, Daniel, and Gary King. 2010. “A Method of Auto-mated Nonparametric Content Analysis for Social Science.”American Journal of Political Science54(1): 229–47. Fonte: Versão ampliada, baseado parcialmente em: “SICSS 2018 - History of Quantitative Text Analysis” slides, video. Pretende-se posteriormente expandir esta seção, explicando em mais detalhes alguns dos exemplos acima "],["organização-dos-dados-quanto-a-sua-estrutura.html", "Capítulo 3 Organização dos dados quanto a sua estrutura 3.1 1) Dados estruturados 3.2 2) Dados não estruturados 3.3 3.Dados semi-estruturados", " Capítulo 3 Organização dos dados quanto a sua estrutura Podemos pensar a organização de dados quanto à sua estrutura de três formas: dados estruturados, dados semi estruturados e dados não estruturados. 3.1 1) Dados estruturados Formatos de arquivos estruturados são csv,xml, json, xls, xlsx, etc. Muitos destes possuem formato de tabela, o que torna bastante fácil encontrar a informação buscada. 3.1.1 Os formatos csv (comma separeted values) e tsv. O formato csv (comma separeted values ou “valores separados por vírgula”) é um dos mais simples, consiste de arquivo de texto simples, com valores separados por um caractere (ou conjunto de caracteres) que separam os valores em cada linha, sendo geralmente vírgula ou ponto e vírgula ou tabulação (tecla tab). Qualquer caractere ou conjunto de caracteres pode ser usado como separador de campos. Na imensa maioria dos casos cada linha é separada pela quebra de linha. Por exemplo, a seguinte tabela: Estado sigla capital região Acre AC Rio Branco Norte Alagoas AL Maceió Nordeste Amapá AP Macapá Norte Amazonas AM Manaus Norte Bahia BA Salvador Nordeste Ceará CE Fortaleza Nordeste Em abrirmos o csv no bloco de notas (notepad): Estado;sigla;capital;região; Acre;AC;Rio Branco;Norte; Alagoas;AL;Maceió;Nordeste; Amapá;AP;Macapá;Norte; Amazonas;AM;Manaus;Norte; Bahia;BA;Salvador;Nordeste; Ceará;CE;Fortaleza;Nordeste; O separador de campo neste arquivo CSV é o ponto e vírgula ;. Ao pedirmos ao computador para localizar qual a designação da sigla “AP”, ele saberá buscar facilmente esta informação. No caso ali, a vírgula é o separador de campos, mas qualquer outro caractere pode ser usado como separador. O formato .tsv, por exemplo, é separado por tabulação - ou o símbolo \\t. Mas é possível encontrar arquivo csv, porém com separador tipo “ ou”;\". 3.2 2) Dados não estruturados Os dados não estruturados são a forma como encontramos em livros impressos, artigos, são a forma como humanos lêem textos. “Algum tempo hesitei se devia abrir estas memorias pelo principio ou pelo fim, isto é, se poria em primeiro logar o meu nascimento ou a minha morte. Supposto o uso vulgar seja começar pelo nascimento, duas considerações me levaram a adoptar differente methodo: a primeira é que eu não sou propriamente um autor defunto, mas um defunto autor, para quem a campa foi outro berço; a segunda é que o escripto ficaria assim mais galante e mais novo. Moysés, que tambem contou a sua morte, não a poz no introito, mas no cabo: differença radical entre este livro e o Pentateuco….” Este tipo de texto, não estruturado, é alvo do Processamento de linguagem natural (PLN)/ Natural Language Process (NLP) 3.3 3.Dados semi-estruturados Dados semi-estruturados são um meio termo entre os estruturados e os semi estruturados. Por vezes são chamados de “auto-descritivos” 3.3.1 Exemplos de dados semi-estruturados 3.3.1.1 O formato Json O Json (“JavaScript Object Notation”, isto é “Notação de Objetos JavaScript”), é organizado no esquema de pares nome/valor. Por exemplo, ao separarmos primeiro nome firstName de sobrenome lastName no Json: {&quot;employees&quot;:[ { &quot;firstName&quot;:&quot;João&quot;, &quot;lastName&quot;:&quot;da Silva&quot; }, { &quot;firstName&quot;:&quot;Ana&quot;, &quot;lastName&quot;:&quot;Maria&quot; }, { &quot;firstName&quot;:&quot;Joaquim&quot;, &quot;lastName&quot;:&quot;Xavier&quot; } ]} O arquivo json inicia e termina com colchetes [] Todo Json é delimitado por chaves {}, os dados são representados no esquema nome/valor `\"nome\": \"valor\". estes são separados por vírgula. Caso queira mais detalhes sobre este formato: Um video introdutório sobre o formato Json do canal Código Fonte TV JSON // Dicionário do Programador. Um video introdutório mais prático sobre Json, JSON em 6 minutos do canal “Canal TI”. Para ver as regras de sintaxe do Json. 3.3.1.2 Markup Códigos especiais, ou linguagem “markup” é uma notação de documento que tem duas apresentações, uma simplificada como texto normal para humanos, e outra com os “markup” para que o computador entenda. 3.3.1.2.1 O formato Markdown Um exemplo bem simples de markup é o Mardown, usado na escrita rápida de textos. Exemplo de markdown 3.3.1.3 O formato YAML O YAML é um padrão de serialização de dados que prima por ser “human friendly”, isto é, de fácil leittura também para humanos. Em arquivos markdown tem-se usado o yaml como cabeçalho, com informações para a renderização do pdf, como título, subtítulo, resumo, palavras chave, etc. Ao converter markdown para o formato final, o computador irá interpretar estas informações. Um exemplo de yaml no arquivo markdown: --- title: &quot;Título do meu pdf&quot; subtitle: subtitulo qualquer author: Fulano de Tal fontsize: 12pt urlcolor: blue geometry: margin=2.5cm abstract: &gt; meu resumo bla bla bla bla --- # Titulo Texto texto texto texto texto texto texto ## Subtitulo Texto texto texto texto texto texto texto O cabeçalho em yaml é delimitado no seu início e fim por três traços consecutivos ---. 3.3.1.4 O Formato LaTex O LaTex é uma linguagem usada na confecção, principalmente de textos (livros, artigos) acadêmicos, bem como apresentações. O formato LaTex permite grande flexibilidade, e é muito usado para escrever fórmulas matemáticas e gerar as referências bibliográficas automaticamente. Por isso, o LaTex é muito usado no contexto acadêmico. O seu formato mínimo pode ser visto assim: \\documentclass{article} \\begin{document} Olá Mundo \\end{document} Exemplo de LaTex Ou em um exemplo um pouco mais elaborado: Exemplo de LaTex Perceba que antes de \\begin{document}, isto é, no cabeçalho do documento temos várias informações, entre elas o título do artigo na linha 5 em title{}, e em \\author{}, nas linhas de 6 a 8, temos os autores. Temos também delimitados os capítulos ou seções, no caso ali em section{}. 3.3.1.5 Os formatos xml e html No caso, nome seria “FirstName” e seu valor seria “João”, nome seria “lastName” e seu valor “da Silva” E esses mesmos dados no formato xml: &lt;employees&gt; &lt;employee&gt; &lt;firstName&gt;João&lt;/firstName&gt; &lt;lastName&gt;da Silva&lt;/lastName&gt; &lt;/employee&gt; &lt;employee&gt; &lt;firstName&gt;Ana&lt;/firstName&gt; &lt;lastName&gt;Maria&lt;/lastName&gt; &lt;/employee&gt; &lt;employee&gt; &lt;firstName&gt;Joaquim&lt;/firstName&gt; &lt;lastName&gt;Xavier&lt;/lastName&gt; &lt;/employee&gt; &lt;/employees&gt; Algumas linguagens usadas em texto são chamadas de markup, onde o que é mostrado na tela, para humanos lerem, difere do que o computador “entende”. Exemplo é o xml acima, o html ou ainda linguagens como markdown e LaTex. O html tem por base o xml. O html possui basicamente a seguinte estrutura &lt;!doctype html&gt; &lt;html&gt; &lt;head&gt; &lt;title&gt;Titulo da pagina&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;Título do capítulo&lt;/h1&gt; &lt;p&gt;Texto texto texto&lt;/p&gt; &lt;/body&gt; &lt;/html&gt; Se você copiar o conteúdo acima e salvar num arquivo com o nome, digamos teste.html e abrí-lo com seu navegador de internet (firefox, Chrome, Opera, etc.), verá como funciona esta ideia de markup. No caso do html, os valores são delimitados por tags, por exemplo: &gt; &lt;ALGO&gt;conteudo&lt;/ALGO&gt; onde &lt;/ indica que estamos fechando a tag. Assim: &lt;h1&gt;Título do capítulo&lt;/h1&gt; O texto “Título do capítulo” está entre a tag “h1”. Temos duas partes no html: Entre &lt;head&gt; e seu fechamento, &lt;/head&gt; ficam os metadados, como título, data, etc. Entre &lt;body&gt; e &lt;/body&gt; fica o conteúdo da página que aparece dentro do navegador. Um outro exemplo: &lt;name&gt;Joaquim José da Silva Xavier&lt;/name&gt;, o Tiradentes (&lt;local&gt;Fazenda do Pombal&lt;/local&gt;, batizado em &lt;data&gt;12 de novembro de 1746&lt;/data&gt; — &lt;local&gt;Rio de Janeiro&lt;/local&gt;, &lt;data&gt;21 de abril de 1792&lt;/data&gt;), foi um &lt;profissao&gt;dentista&lt;/profissao&gt;, &lt;profissao&gt;tropeiro&lt;/profissao&gt;, &lt;profissao&gt;minerador&lt;/profissao&gt;, &lt;profissao&gt;comerciante&lt;/profissao&gt;, &lt;profissao&gt;militar&lt;/profissao&gt; e &lt;profissao&gt;ativista político&lt;/profissao&gt; &lt;gentilico&gt;brasileiro&lt;/gentilico&gt;, que atuou nas capitanias de &lt;local&gt;Minas Gerais&lt;/local&gt; e &lt;local&gt;Rio de Janeiro&lt;/local&gt;. Onde podemos ver tags como &lt;name&gt;, &lt;local&gt;, &lt;data&gt;, etc. ao redor de certas informações, o que torna possível ao computador encontrar estas informações. Grande parte do trabalho em análise textual trata-se passar do formato não-estruturado para o semi-estruturado ou estruturado, para que possamos trabalhar programaticamente. Por exemplo, Franzosi (2010) ao fazer análise da narrativa de jornais italianos da época de ascensão do Fascismo, passou textos não estruturados como este: Republicans plunged in Bissone di S. Cristina around 10pm of this month at the pub Prati. A guy, who went by the name of “captain,” took out a list of names and did the roll call loudly. Para o seguinte formato: [Semantic triplet 1: [Participant: [Actor: republicans]] [[Process: [[Verb: plunge] [Circumstances: [Space: [City: Bissone di S. Cristina] [[Location: pub] [Name: Prati]]]] [[Time: [Date: 05/07/1921] [Hour: 10pm]]]]] [Semantic triplet 2: [Participant: [Actor: captain]] [Process: [[Verb: does roll call] [Circumstances: [Type of action: loudly] [Instrument: list]]] [Participant: [Actor: workers]] Para tal, Franzosi desenvolveu um software para análise de narrativas textuais, o PC-ACE (Program for Computer-Assisted Coding of Events) e pôde ter uma noção da violência cotidiana na época: Tabela de Franzosi. List of daily occurences of triplets of violence in the Avanti! database (FRANZOSI, p.607) Frequency distribution of triplets of violence in the Avanti! database (FRANZOSI, p.607) E ainda fez um “mapa de calor” (“heat map”) com a localização da violência fascista na Itália (FRANZOSI, p.609) Referência: FRANZOSI, Roberto P.. Sociology, narrative, and the quality versus quantity debate (Goethe versus Newton): Can computer-assisted story grammars help us understand the rise of Italian fascism (1919–1922)?. Theor Soc (2010) 39:593–629. DOI 10.1007/s11186-010-9131-3 Os dados semi-estruturados não tem, portanto, formato de tabela, mas contêm indicações de informações mais abstratas, através de tags ou outras marcações. Com base nestas informações que faremos análises de texto. Este processo de transformação de dados não estruturados em estruturados é chamado de “datificação”. "],["análise-de-redes-sociais.html", "Capítulo 4 Análise de Redes Sociais 4.1 O pacote Igraph 4.2 O pacote ggraph 4.3 Redes de palavras 4.4 Redes de citação 4.5 Gráfico de centralidade 4.6 Comunidades 4.7 Sugestões de links", " Capítulo 4 Análise de Redes Sociais O R possui diversos pacotes para análise de rede, como o igraph, ggraph, statnet. 4.1 O pacote Igraph Instalando o pacote igraph: install.packages(&quot;igraph&quot;) # instalando o pacote chamando o pacote já instalado library(igraph) # chamando o pacote já instalado ## ## Attaching package: &#39;igraph&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## decompose, spectrum ## The following object is masked from &#39;package:base&#39;: ## ## union A partir da ajuda do igraph — no caso, digitando ?igraph.plotting no console do R, e correndo até o final da ajuda — temos alguns exemplos de grafos com o Igraph. Por exemplo, construindo um anel: g &lt;- make_ring(10) g$layout &lt;- layout_in_circle plot(g) É possível ainda plotar com os comandos tkplot(g) e rglplot(g). Rode no seu console e veja a diferença nos gráficos. Mas vamos a algo mais prático. Pegando o famoso poema: “João amava Teresa que amava Raimundo que amava Maria que amava Joaquim que amava Lili que não amava ninguém” library(igraph) g &lt;- graph.empty(directed=TRUE) # &quot;directed&quot; implica distinguir entre &quot;de&quot; e &quot;para&quot; na relação entre os nós. # Adicionando os vértices. g &lt;- g + vertex(&quot;João&quot;) g &lt;- g + vertex(&quot;Teresa&quot;) g &lt;- g + vertex(&quot;Raimundo&quot;) g &lt;- g + vertex(&quot;Maria&quot;) g &lt;- g + vertex(&quot;Joaquim&quot;) g &lt;- g + vertex(&quot;Lili&quot;) # Especificando as relações entres os vértices, os edges g &lt;- g + edges(&quot;João&quot;, &quot;Teresa&quot;) g &lt;- g + edges(&quot;Teresa&quot;, &quot;Raimundo&quot;) g &lt;- g + edges(&quot;Raimundo&quot;, &quot;Maria&quot;) g &lt;- g + edges(&quot;Maria&quot;, &quot;Joaquim&quot;) g &lt;- g + edges(&quot;Joaquim&quot;, &quot;Lili&quot;) plot.igraph(g) # plotando o grafo Neste caso, poderíamos ter feito este mesmo gráfico de modo mais compacto: library(igraph) g &lt;- graph.empty(directed=TRUE) # Adicionando os vértices. g &lt;- g + vertex(c(&quot;João&quot;, &quot;Teresa&quot;, &quot;Raimundo&quot;, &quot;Maria&quot;, &quot;Joaquim&quot;, &quot;Lili&quot;)) # Adicionando os edges em pares g &lt;- g + edges(c(&quot;João&quot;, &quot;Teresa&quot;, &quot;Teresa&quot;, &quot;Raimundo&quot;, &quot;Raimundo&quot;, &quot;Maria&quot;,&quot;Maria&quot;, &quot;Joaquim&quot;,&quot;Joaquim&quot;, &quot;Lili&quot;)) plot.igraph(g) Se o grafo sobe ou desce, pouco importa para nós aqui, importa as pessoas e as relações entre elas. Repare que os edges são entendidos aos pares. Se fizéssemos um vetor sem as devidas repetições, teríamos um gráfico errado das relações: g &lt;- graph.empty(directed=TRUE) g &lt;- g + vertex(c(&quot;João&quot;, &quot;Teresa&quot;, &quot;Raimundo&quot;, &quot;Maria&quot;, &quot;Joaquim&quot;, &quot;Lili&quot;)) g &lt;- g + edges(c(&quot;João&quot;, &quot;Teresa&quot;, &quot;Raimundo&quot;, &quot;Maria&quot;,&quot;Joaquim&quot;, &quot;Lili&quot;)) plot.igraph(g) 4.2 O pacote ggraph A ser elaborado 4.3 Redes de palavras A ser elaborado 4.4 Redes de citação A ser elaborado 4.5 Gráfico de centralidade A ser elaborado 4.6 Comunidades A ser elaborado 4.7 Sugestões de links Manual online do ipgraph para R; PDF do Manual do igraph para R (ambos em inglês) d’ANDRÉA, Carlos Frederico de Brito. Pesquisando plataformas online: conceitos e métodos. EDUFBA. 2020. A obra visa introduzir os Estudos de Plataforma, um campo de estudos que, desde o início da década de 2010, discute as especificidades políticas e materiais das mídias sociais e de outras plataformas online. Datificação, algoritmos, governança e os modelos de negócio das plataformas são algumas das dimensões sintetizadas no livro. De modo didático, o autor apresenta um conjunto de leituras e de experimentações metodológicas conduzidas com um diversificado grupo de colaboradoras(es) no país e no exterior. (ebook PDF e Epub gratuitos) RECUERO, Raquel. Introdução à análise de redes sociais online. EDUFBA.2017. A Análise de Redes Sociais (ARS) é uma abordagem de pesquisa cuja popularidade tem aumentado nos últimos anos, principalmente, entre os pesquisadores da área de Comunicação. É nesse âmbito que várias obras, entre artigos e livros, vêm surgindo e introduzindo o estudo dessas estruturas a partir da análise de redes e da compreensão da representação dessas redes sociais na internet. Este livro é uma pequena compilação dos principais conceitos e elementos para a compreensão e a aplicação da ARS. É baseado em uma breve apresentação e histórico do paradigma, os principais conceitos, suas métricas e, finalmente, suas formas de representação e visualização. (ebook PDF e Epub gratuitos). LIZARDO Omar; JILBERT Isaac. Social Networks: An Introduction. 2021. (ebook online) AQUINO, Jackson A. “Análise de redes sociais”, capítulo 12 de ___. R para cientistas sociais. Ilhéus, BA: EDITUS, 2014. 157 p. ISBN: 978-85-7455-369-6. (PDF gratuito) "],["links-úteis.html", "Capítulo 5 Links úteis 5.1 Humanidades digitais 5.2 Análise de redes sociais 5.3 Textos sobre análise textual 5.4 Processamento Linguagem Natural (PLN ou NLP) 5.5 Revistas / Journals 5.6 Dados Abertos 5.7 Vídeos 5.8 Sites / Blogs 5.9 Organizações 5.10 Podcasts 5.11 Programação 5.12 Cursos 5.13 Grupos de discussão/Forum 5.14 Links de Cheat-sheets", " Capítulo 5 Links úteis Segue aqui uma lista com links para livros, artigos, sites, manutais, tutoriais, vídeos e canais de vídeos. A maioria e a prioridade é de material gratuito, sobre temas gerais relacionados a humanidades digitais e em especial, à sociologia. Há também sugestões mais focadas nos assuntos específicos nos capítulos. O critério de seleção aqui foi o de contribuição para esclarecer o potencial das humanidades digitais para quem inicia na área de humanidades digitais/sociologia digital. Os itens não foram selecionados tanto pela contribuição científica, mas com base no critério de exemplos que podem ajudar a esclarecer o potencial das humanidades digitais para quem inicia. 5.1 Humanidades digitais Introduction to Digital Humanities Textbook A digital textbook designed for UCLA’s Introduction to Digital Humanities course website. (ebook disponível gratuito online) EDMOND, Jennifer Digital Technology and the Practices of Humanities Research. (Livro gratuito) The Data Journalism Handbook. Towards a Critical Data Practice. 415p. 2021. ISBN 9789048542079. (Livro GRATUITO). BAUER, Paul C. Computational Social Science: Theory &amp; Application. (livro online grátis). 5.2 Análise de redes sociais Ver sugestões no capítulo “Análise de Redes Sociais”. 5.3 Textos sobre análise textual GRIMMER, Justin.STEWART, Brandom. Text as Data: The Promise and Pitfalls of Automatic ContentAnalysis Methods for Political Texts. Political Analysis(2013) pp. 1–31. doi:10.1093/pan/mps028. CASTELFRANCHI, Yurij. A análise de textos auxiliada pelo computador: um laboratório a céu aberto para as ciências sociais. Journal of Science Communication 16(02)(2017)C04 TREADWELL, Donald. Content Analysis: Understanding Text and Image in Numbers. Understanding Text and Image in Numbers. In __ Introducing Communication Research: paths of Inquiry. Sage. 2014. (Capítulo sobre análise de conteúdo) 5.3.1 Sociologia Digital KATEMBERA, Serge. “Sociologia digital ou sociologia do digital?” V. 2 N. 1 (2020): Dossiê Ambiente e Sociedade. (Artigo) NASCIMENTO, Leonardo F. Sociologia digital : uma breve introdução. EDUFBA. 2020. (Livro gratuito em PDF e epub) Podcast “New Work in Digital Humanities”. Episódio: Neil Selwyn, “What is Digital Sociology?” (Polity, 2019) BERNAU, John A. Text Analysis with JSTOR Archives. November 12, 2018 https://doi.org/10.1177/2378023118809264. (Aplicação de métodos de humanidades digitais, usando a base do Jstor, para uma rápida análise de variação temática em revistas sociológicas). FUSSEY, Pete e ROTH, Silke (ed.) Digitizing Sociology. edição da revista “Sociology” da British Sociological Association. 5.3.1.1 Netnografia, etnografia digital MARKHAM, Annette N. 2013. Fieldwork in Social Media. Qualitative Communication Research 2, 4 (Dec. 2013), 434–446. https://doi.org/10.1525/qcr.2013.2.4.434 SHAFFER, David Williamson. Quantitative Etnography. Boswell Press. 2017. “This is a book about understanding why, in the digital age, the old distinctions between qualitative and quantitative research methods, between the sciences and humanities, and between numbers and understanding, limit the kinds of questions we can ask, in some cases, and lead us accept superficial answers in others. Quantitative Ethnography is a research method that goes beyond those distinctions to help us understand how to make sense of our increasingly data-rich world…\". (PDF da Introdução disponível gratuitamente) 5.4 Processamento Linguagem Natural (PLN ou NLP) JURAFSKY, D.; MARTIN, J. Speech and language processing: An introduction to speech recognition, computational linguistics and natural language processing. Upper Saddle River, NJ: Prentice Hall, 2020. link pdf dos capítulos individuais, link livro completo. (Um manual bastante extenso e mais teórico sobre PLN) BIRD, S.; KLEIN, E.; LOPER., E. Natural language processing with Python – analyzing text with the natural language toolkit. (Livro online gratuito, baseado em Python 3.) 5.5 Revistas / Journals SIGCAS Computers and Society da Association for Computing Machinery Digital Scholarship in the Humanities. Revista da Universidade de Oxford. Sessão com artigos gratuitos Journal: Digital humanities Quartely International Journal of Digital Humanities Socius: Sociological Research for a Dynamic World. Special Collection: Data Visualization. Jornal de acesso livre International Journal of Humanities and Arts Computing (Universidade de Edimburgo) magazén International Journal for Digital and Public Humanities. (open access). Revista do Dipartimento di Studi Umanistici da Università Ca’ Foscari de Veneza Journal of Digital Social Research. Open Access Reviews in Digital Humanities. (O Review já não publica desde 2014) Journal of Digital Humanities. (O Journal of DH tem uma sessão de resenha de novas ferramentas disponíveis). Journal of Cultural Analytics. Department of Languages, Literatures, and Cultures at McGill University, Canada. open-access journal dedicated to the computational study of culture 5.6 Dados Abertos 5 estrelas dos dados abertos (Tim Berners-Lee, criador do termo “dados abertos”. Site explica o que são dados abertos e seus 5 níveis. Em português) Busca do Google por base de dados Abertos Dados abertos. (Se não sabe onde encontrar algum dado específico que você procura,veja aqui) SHIKIDA, Claudio D., MONASTERIO, Leonardo, NER, Pedro Fernando. Guia Brasileiro de Análise de Dados: Armadilhas e Soluções. Brasília. 2021. ( Tópicos: Causalidade, Pobreza e Desigualdade, Análise de dados em Saúde, Educação, Crimes e Violência, Macroeconomia, Mercado e Trabalho e Opinião Pública.) dados abertos: Fórum de discussão. Workshop do Henrique Xavier, no canal “Base dos Dados” sobre como explorar os dados do Diário Oficial da União. 5.7 Vídeos Vídeos do 1º Summerschool of Digital Humanities da Universidade de Heidelberg, Alemanha, ocorrido em 2017. link. (Em inglês) 5.8 Sites / Blogs Text analysis info Textual Analysis - University of Notre Dame Site Digital Humanities Now. (Agrega oportunidade de emprego, notícias, bolsas de pesquisa). site Go Digital Humanities. (Novidades sobre humanidades digitais, como eventos). Blog Digital Society Blog. (Blog do Institut für Internet und Gesellschaft da Alexander von Humboldt). 5.9 Organizações Alliance of Digital Humanities Organizations (ADHO). Global Network of Internet and Society Research Centers (NoC) i. (Catálogo com grupos de pesquisa sobre internet e sociedade ao redor do mundo). 5.10 Podcasts Complexity: Peter Dodds on Text-Based Timeline Analysis &amp; New Instruments for The Science of Stories New Work in Digital Humanities. New Books Network. Interviews with digital humanists about their new work. Lista com mais podcasts dedicados às digital humanities 5.11 Programação 5.11.1 R introdução Caio Lente. zen do R. “O objetivo deste livro é ensinar ao leitor que não costuma programar algumas formas simples de melhorar a organização de seus projetos de análise de dados em R”. (Livro online gratuito). AQUINO, Jackson A.. R para cientistas sociais. Ilhéus, BA: EDITUS, 2014. 157 p. ISBN: 978-85-7455-369-6. (PDF gratuito) FERREIRA, E.B.;. de OLIVEIRA, M.S. Introdução à Estatística com R. Unifal. 2020. (PDF gratuito). Livro Curso-R (em construção) Blog: Curso-R KUBRUSLY, Jessica. Uma Introdução à Programação com o R. (ebook online em português) Sergio Miranda Freire. Introdução ao R. (Livro online, no formato bookdown) WICKHAM, Hadley. Advanced R.2nd edition. (Livro online gratuito, no formato bookdown em inglês, para entender melhor os conceitos do R) 5.11.2 R - tópicos específicos WICKHAM, H. GROLEMUND, Garret. R for Data Science. O’Reilly. 2017. (Livro Online, em inglês). IRIZARRY, Rafael A. Introduction to Data Science. Livro Online, em inglês, feito como notas de aulas da HarvardX Data Science Series CLARK, Michael. R &amp; Social Science. Getting Started with applied use of R in the Social Sciences. (pequeno manual em PDF da Universidade de Notre Dame) ggplot2 on-line version of work-in-progress 3rd edition of “ggplot2: elegant graphics for data analysis” SILGE, Julia, ROBINSON, David Text Mining with R. (ebook online) RYDBERG-COX, Jeff. Statistical Methods for Studying Literature Using R da Universidade Missouri-Kansas City. R-tutorAn R Introduction to Statistics. Site com tutoriais diversos sobre R. Em Inglês. Diversos links para livros gratuitos de R no bookdown. 5.11.3 Python HEINOLD, Brian. A Practical Introduction to Python Programming. 2012. 263 p. (PDF de introdução ao Python) Jake VanderPlas. Python Data Science Handbook: Essential Tools for Working with data. (livro online). 5.11.4 Python - tópicos específicos KARSDORP, Folgert. Python Programming for the Humanities. Livro online. Pyhton Humanities. Site com introdução às DH em Python, com alguns tutoriais. Constellate What do you want to learn today?. (Projeto Constellate da JStor junto a diversas universidades. Conta com sessão com tutoriais sobre análise textual, a maioria em Python. 5.12 Cursos EdX, Cursos online de Universidades como Harvard, MIT, etc. gratuitos como ouvinte. Paga-se pelo certificado. Há cursos grautuitos, como “Introducing Text Analytics and Natural Language Processing with Python”, “Introduction to Digital Humanities”, “Data Science: Visualization”, “Using Python for Research”. DataCamp. Cursos mais práticos, em R, Python, SQL, com exercícios, totalmente online (não é necessário instalar nada em seu computador). As partes iniciais dos cursos costumam ser gratuitas, mas há parte paga com anuidades. Udemy Possui cursos gratuitos e cursos pagos. É possível encontrar cursos pagos por volta de R$20,00. Coursera. Possui parceria com mais de 200 universidades e empresas como o Google e IBM. Cognitive Class Da IBM, Cursos gratuitos em data science, alguns gratuitos com certificado. Cursos em inglês e espanhol. Possui cursos como “Data Visualization with R”. Big Data University. Cursos em Portugues. Curso gratuito de Estatística e probabilidade da Khan Academy, em português. Inclui teste de hipótese, regressão. 5.13 Grupos de discussão/Forum 5.13.1 Telegram Processamento de Linguagem Natural em Português PT-Br Data Science - Python R Brasil R humanidades Análise Textual-Humanidades Digitais 5.14 Links de Cheat-sheets “Cheat sheets” seriam a tradução para “cola”, aquela feita para consulta em exames na escola. Em programação, refere-se a uma tabela muito bem resumida, com o que há de essencial em determinado assunto. Text Analysis Glossary Lista com mais de 100 cheat-sheets em R e Python, sobre Machine Learning: link Git-GitHub, Git-Gitlab, "]]
