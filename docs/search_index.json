[["análise-textual-text-mining.html", "Capítulo 6 Análise Textual (text mining) 6.1 Abordagens: saco de palavras (bag of words) e análise semântica (semantic parsing) 6.2 Do texto ao Corpus 6.3 Remoção de palavra vazia (stopwords) 6.4 stemização (Stemming) e lematização 6.5 Ngrams", " Capítulo 6 Análise Textual (text mining) CAPÍTULO AINDA EM CONSTRUÇÃO Conteúdo planejado: Introdução à análise textual via computador Tipos de abordagens: bag of words, semantic parsing. Frequência de termos (bag of words, n-grams, skipgrams, TF-IDF) nuvem de palavras (wordclouds), Polarized tag cloud, pyramid plot. Correlação de palavras, tipos de distâncias, dendogramas parts-of-speech keyword extraction redes de palavras (word networks) Inteligência Artificial: clusterização; topic modelling Análise de sentimentos. A análise computacional de textos é praticamente um sinônimo de Mineração de texto (text mining) Há diversas funções nativas do R que usamos na mineração de texto/análise textual, mas também há diversos pacotes focados em análise textual com diversas ferramentas, como o tidytext, quanteda (QUantitative ANalysis TExtual DAta), tm (Text Mining Package) e qdap (Quantitative Discourse Analysis Package). Estes são alguns dos mais famosos, com diversas ferramentas, mas há alguns outros pacotes focados em funções mais específicas, como o pacote wordcloud, ggwordcloud (nuvem de palavras para o ggplot2, com mais craopções) por exemplo. Há redundância entre estes pacotes, isto é, eles tem funções prórias que fazem a mesma coisa que funções de outros pacotes. O pacote quanteda acompanha outros, como o quanteda.textstats, quanteda.textplots e o quanteda.textmodels que aconselhamos instalar também. Um software bem conhecido e que possui interface gráfica é o iramuteq (Interface de R pour les Analyses Multidimensionnelles de Textes et de Questionnaires), criado em 2009 por Pierre Ratinaud. Apesar de ainda ser bastante utilizado, o Iramuteq tem diversas limitações. 6.1 Abordagens: saco de palavras (bag of words) e análise semântica (semantic parsing) Na análise textual podemos analisar levando ou não em consideração a ordem das palavras ou sua função gramatical. Se o ordenamento ou a função das palavras não é importante, e queremos saber, por exemplo, a frequência de certos termos, então faremos uma abordagem “saco de palavras”. 6.2 Do texto ao Corpus A primeira coisa a se fazer é colocar como opção global de nosso projeto que strings não sejam consideradas como fatores. # Opções globais options(stringsAsFactors = FALSE) library(dplyr) ## ## Attaching package: &#39;dplyr&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## filter, lag ## The following objects are masked from &#39;package:base&#39;: ## ## intersect, setdiff, setequal, union library(magrittr) Vamos importar os dados. Eu peguei as notas taquigráficas da 10ª sessão da CI da Pandemia, de 19/05/2021 e a estruturei em csv e Rdata. O modo mais fácil é importar o Rdata NotasTaq &lt;- readRDS(url(&quot;https://raw.githubusercontent.com/SoaresAlisson/NotasTaquigraficas/master/NotasTaquigraficas_2021-05-19_CPI.Pandemia.Rdata&quot;)) # vamos transformar nosso dataframe em tibble NotasTaq = as_tibble(NotasTaq) # conferindo se é tibble class(NotasTaq) ## [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; # Se quisermos dar uma olhada na tabela completa View(NotasTaq) Se tudo deu certo, então o tibble apareceu na sessão Environmet do seu RStudio. Tibble “NotasTaq” foi carregado no R Vamos então separar somente as falas. Falas = NotasTaq$Falas Se quisermos separar por falas de uma pessoa específica, vamos ver quais os valores da coluna “Nomes” NotasTaq$Nomes %&gt;% unique ## [1] &quot;PRESIDENTE&quot; &quot;EDUARDO PAZUELLO&quot; ## [3] &quot;RENAN CALHEIROS&quot; &quot;GEN. EDUARDO PAZUELLO&quot; ## [5] &quot;FLÁVIO BOLSONARO&quot; &quot;OTTO ALENCAR&quot; ## [7] &quot;FERNANDO BEZERRA COELHO&quot; &quot;ROGÉRIO CARVALHO&quot; ## [9] &quot;CIRO NOGUEIRA&quot; &quot;ELIZIANE GAMA&quot; ## [11] &quot;MARCOS ROGÉRIO&quot; &quot;RANDOLFE RODRIGUES&quot; ## [13] &quot;EDUARDO BRAGA&quot; &quot;HUMBERTO COSTA&quot; ## [15] &quot;JORGINHO MELLO&quot; &quot;LUIS CARLOS HEINZE&quot; ## [17] &quot;TASSO JEREISSATI&quot; &quot;ALESSANDRO VIEIRA&quot; ## [19] &quot;SORAYA THRONICKE&quot; Falas.SenHeinze &lt;- NotasTaq %&gt;% # filtrando as linhas por nome filter(Nomes == &quot;LUIS CARLOS HEINZE&quot;) %$% # separando somente as falas Falas Falas.SenHeinze ## [1] &quot;Sr. Presidente... Sr. Presidente... &quot; ## [2] &quot;Eu só quero fazer uma colocação. V. Exa. e o Senador Eduardo Braga são do Amazonas. &quot; ## [3] &quot;Foram liberados no ano passado R$2,606 bilhões. &quot; ## [4] &quot;... se tinha dinheiro lá. &quot; ## [5] &quot;Mas está aqui a... &quot; ## [6] &quot;Não estou mentindo, aqui está o valor. &quot; ## [7] &quot;Não estou mentindo, aqui está o valor liberado. &quot; ## [8] &quot;Esse é... Não senhor, aqui não pode mentir. &quot; ## [9] &quot;Aqui está o valor liberado para o Governo do Estado. &quot; ## [10] &quot;Não senhor. Não senhor. Vou lhe mostrar o valor. &quot; ## [11] &quot;Vou mandar imprimir e vou lhe mostrar. Não me chame de mentiroso! Não sou! Não sou! Vou lhe mostrar agora. &quot; ## [12] &quot;Vou puxar a tabela e vou ver quanto foi para lá. Foi o dinheiro lá. Não é irresponsabilidade do Governo Federal, é do Governo lá do Amazonas... &quot; ## [13] &quot;Vamos mudar o nome então, Presidente. Vamos mudar o nome: é raspa de tacho que os Prefeitos vêm pedir para os Deputados e Senadores. &quot; ## [14] &quot;\\&quot;Não sobrou uma raspinha de tacho aí?\\&quot; &quot; ## [15] &quot;Então tira o \\&quot;pixuleco\\&quot; fora e fica uma raspinha de tacho que fica melhor. &quot; ## [16] &quot;Sr. Presidente, existiam três... &quot; ## [17] &quot;É só um minutinho. &quot; ## [18] &quot;O.k. &quot; ## [19] &quot;Sr. Presidente... &quot; ## [20] &quot;Deixa eu só... &quot; ## [21] &quot;Está bom. &quot; ## [22] &quot;Senador Renan, deixar eu só lhe colocar. Tem notas técnicas, nº 5, nº 6, nº 9, nº 11, nº 17, desde o Ministro Mandetta, permitindo o uso da cloroquina. Essas notas técnicas existem. &quot; ## [23] &quot;Não, vou lhe dizer. Eu vou lhe dizer. &quot; ## [24] &quot;E o Ministro Pazuello explicou que, depois da pesquisa criminosa – que nós vamos discutir aqui dentro – feita lá em Manaus, que matou 22 pessoas, eles trocaram, porque usavam em qualquer fase; era para só usar nos primeiros quatro, cinco, seis dias, e não em estágio em que estavam as pessoas já hospitalizadas e intubadas. &quot; ## [25] &quot;Fora a dose; a dose lá foi mortal. &quot; ## [26] &quot;A questão de ordem é só para esclarecer isso que eu estou esclarecendo. &quot; ## [27] &quot;Todo mundo fala aqui; por que eu não posso falar? Qualquer um chega e atropela o outro. &quot; ## [28] &quot;Eu tenho direito a falar. Qualquer um chega e fala a hora que quer; eu também tenho direito e estou esclarecendo, porque eu sei do assunto. &quot; 6.2.1 Abordagem Bag of words Na abordagem de “saco de palavras” a ordem dos termos não importa. 6.3 Remoção de palavra vazia (stopwords) Ao analisarmos texto, o mais frequente são palavras bem pouco informativas, como artigos “o”, “a” “os”, “as”. Para termos uma noção melhor removemos as chamadas stopwords. E se já houvesse uma lista pronta? Existe. São as chamadas stopwords. É possível encontrar listas prontas na internet, mas diversas funções no R já incluem em si tais listas. Para ver a lista padrão no R, use: library(tm) ## Carregando pacotes exigidos: NLP stopwords(&quot;en&quot;) ## [1] &quot;i&quot; &quot;me&quot; &quot;my&quot; &quot;myself&quot; &quot;we&quot; ## [6] &quot;our&quot; &quot;ours&quot; &quot;ourselves&quot; &quot;you&quot; &quot;your&quot; ## [11] &quot;yours&quot; &quot;yourself&quot; &quot;yourselves&quot; &quot;he&quot; &quot;him&quot; ## [16] &quot;his&quot; &quot;himself&quot; &quot;she&quot; &quot;her&quot; &quot;hers&quot; ## [21] &quot;herself&quot; &quot;it&quot; &quot;its&quot; &quot;itself&quot; &quot;they&quot; ## [26] &quot;them&quot; &quot;their&quot; &quot;theirs&quot; &quot;themselves&quot; &quot;what&quot; ## [31] &quot;which&quot; &quot;who&quot; &quot;whom&quot; &quot;this&quot; &quot;that&quot; ## [36] &quot;these&quot; &quot;those&quot; &quot;am&quot; &quot;is&quot; &quot;are&quot; ## [41] &quot;was&quot; &quot;were&quot; &quot;be&quot; &quot;been&quot; &quot;being&quot; ## [46] &quot;have&quot; &quot;has&quot; &quot;had&quot; &quot;having&quot; &quot;do&quot; ## [51] &quot;does&quot; &quot;did&quot; &quot;doing&quot; &quot;would&quot; &quot;should&quot; ## [56] &quot;could&quot; &quot;ought&quot; &quot;i&#39;m&quot; &quot;you&#39;re&quot; &quot;he&#39;s&quot; ## [61] &quot;she&#39;s&quot; &quot;it&#39;s&quot; &quot;we&#39;re&quot; &quot;they&#39;re&quot; &quot;i&#39;ve&quot; ## [66] &quot;you&#39;ve&quot; &quot;we&#39;ve&quot; &quot;they&#39;ve&quot; &quot;i&#39;d&quot; &quot;you&#39;d&quot; ## [71] &quot;he&#39;d&quot; &quot;she&#39;d&quot; &quot;we&#39;d&quot; &quot;they&#39;d&quot; &quot;i&#39;ll&quot; ## [76] &quot;you&#39;ll&quot; &quot;he&#39;ll&quot; &quot;she&#39;ll&quot; &quot;we&#39;ll&quot; &quot;they&#39;ll&quot; ## [81] &quot;isn&#39;t&quot; &quot;aren&#39;t&quot; &quot;wasn&#39;t&quot; &quot;weren&#39;t&quot; &quot;hasn&#39;t&quot; ## [86] &quot;haven&#39;t&quot; &quot;hadn&#39;t&quot; &quot;doesn&#39;t&quot; &quot;don&#39;t&quot; &quot;didn&#39;t&quot; ## [91] &quot;won&#39;t&quot; &quot;wouldn&#39;t&quot; &quot;shan&#39;t&quot; &quot;shouldn&#39;t&quot; &quot;can&#39;t&quot; ## [96] &quot;cannot&quot; &quot;couldn&#39;t&quot; &quot;mustn&#39;t&quot; &quot;let&#39;s&quot; &quot;that&#39;s&quot; ## [101] &quot;who&#39;s&quot; &quot;what&#39;s&quot; &quot;here&#39;s&quot; &quot;there&#39;s&quot; &quot;when&#39;s&quot; ## [106] &quot;where&#39;s&quot; &quot;why&#39;s&quot; &quot;how&#39;s&quot; &quot;a&quot; &quot;an&quot; ## [111] &quot;the&quot; &quot;and&quot; &quot;but&quot; &quot;if&quot; &quot;or&quot; ## [116] &quot;because&quot; &quot;as&quot; &quot;until&quot; &quot;while&quot; &quot;of&quot; ## [121] &quot;at&quot; &quot;by&quot; &quot;for&quot; &quot;with&quot; &quot;about&quot; ## [126] &quot;against&quot; &quot;between&quot; &quot;into&quot; &quot;through&quot; &quot;during&quot; ## [131] &quot;before&quot; &quot;after&quot; &quot;above&quot; &quot;below&quot; &quot;to&quot; ## [136] &quot;from&quot; &quot;up&quot; &quot;down&quot; &quot;in&quot; &quot;out&quot; ## [141] &quot;on&quot; &quot;off&quot; &quot;over&quot; &quot;under&quot; &quot;again&quot; ## [146] &quot;further&quot; &quot;then&quot; &quot;once&quot; &quot;here&quot; &quot;there&quot; ## [151] &quot;when&quot; &quot;where&quot; &quot;why&quot; &quot;how&quot; &quot;all&quot; ## [156] &quot;any&quot; &quot;both&quot; &quot;each&quot; &quot;few&quot; &quot;more&quot; ## [161] &quot;most&quot; &quot;other&quot; &quot;some&quot; &quot;such&quot; &quot;no&quot; ## [166] &quot;nor&quot; &quot;not&quot; &quot;only&quot; &quot;own&quot; &quot;same&quot; ## [171] &quot;so&quot; &quot;than&quot; &quot;too&quot; &quot;very&quot; stopwords(&quot;pt&quot;) ## [1] &quot;de&quot; &quot;a&quot; &quot;o&quot; &quot;que&quot; &quot;e&quot; ## [6] &quot;do&quot; &quot;da&quot; &quot;em&quot; &quot;um&quot; &quot;para&quot; ## [11] &quot;com&quot; &quot;não&quot; &quot;uma&quot; &quot;os&quot; &quot;no&quot; ## [16] &quot;se&quot; &quot;na&quot; &quot;por&quot; &quot;mais&quot; &quot;as&quot; ## [21] &quot;dos&quot; &quot;como&quot; &quot;mas&quot; &quot;ao&quot; &quot;ele&quot; ## [26] &quot;das&quot; &quot;à&quot; &quot;seu&quot; &quot;sua&quot; &quot;ou&quot; ## [31] &quot;quando&quot; &quot;muito&quot; &quot;nos&quot; &quot;já&quot; &quot;eu&quot; ## [36] &quot;também&quot; &quot;só&quot; &quot;pelo&quot; &quot;pela&quot; &quot;até&quot; ## [41] &quot;isso&quot; &quot;ela&quot; &quot;entre&quot; &quot;depois&quot; &quot;sem&quot; ## [46] &quot;mesmo&quot; &quot;aos&quot; &quot;seus&quot; &quot;quem&quot; &quot;nas&quot; ## [51] &quot;me&quot; &quot;esse&quot; &quot;eles&quot; &quot;você&quot; &quot;essa&quot; ## [56] &quot;num&quot; &quot;nem&quot; &quot;suas&quot; &quot;meu&quot; &quot;às&quot; ## [61] &quot;minha&quot; &quot;numa&quot; &quot;pelos&quot; &quot;elas&quot; &quot;qual&quot; ## [66] &quot;nós&quot; &quot;lhe&quot; &quot;deles&quot; &quot;essas&quot; &quot;esses&quot; ## [71] &quot;pelas&quot; &quot;este&quot; &quot;dele&quot; &quot;tu&quot; &quot;te&quot; ## [76] &quot;vocês&quot; &quot;vos&quot; &quot;lhes&quot; &quot;meus&quot; &quot;minhas&quot; ## [81] &quot;teu&quot; &quot;tua&quot; &quot;teus&quot; &quot;tuas&quot; &quot;nosso&quot; ## [86] &quot;nossa&quot; &quot;nossos&quot; &quot;nossas&quot; &quot;dela&quot; &quot;delas&quot; ## [91] &quot;esta&quot; &quot;estes&quot; &quot;estas&quot; &quot;aquele&quot; &quot;aquela&quot; ## [96] &quot;aqueles&quot; &quot;aquelas&quot; &quot;isto&quot; &quot;aquilo&quot; &quot;estou&quot; ## [101] &quot;está&quot; &quot;estamos&quot; &quot;estão&quot; &quot;estive&quot; &quot;esteve&quot; ## [106] &quot;estivemos&quot; &quot;estiveram&quot; &quot;estava&quot; &quot;estávamos&quot; &quot;estavam&quot; ## [111] &quot;estivera&quot; &quot;estivéramos&quot; &quot;esteja&quot; &quot;estejamos&quot; &quot;estejam&quot; ## [116] &quot;estivesse&quot; &quot;estivéssemos&quot; &quot;estivessem&quot; &quot;estiver&quot; &quot;estivermos&quot; ## [121] &quot;estiverem&quot; &quot;hei&quot; &quot;há&quot; &quot;havemos&quot; &quot;hão&quot; ## [126] &quot;houve&quot; &quot;houvemos&quot; &quot;houveram&quot; &quot;houvera&quot; &quot;houvéramos&quot; ## [131] &quot;haja&quot; &quot;hajamos&quot; &quot;hajam&quot; &quot;houvesse&quot; &quot;houvéssemos&quot; ## [136] &quot;houvessem&quot; &quot;houver&quot; &quot;houvermos&quot; &quot;houverem&quot; &quot;houverei&quot; ## [141] &quot;houverá&quot; &quot;houveremos&quot; &quot;houverão&quot; &quot;houveria&quot; &quot;houveríamos&quot; ## [146] &quot;houveriam&quot; &quot;sou&quot; &quot;somos&quot; &quot;são&quot; &quot;era&quot; ## [151] &quot;éramos&quot; &quot;eram&quot; &quot;fui&quot; &quot;foi&quot; &quot;fomos&quot; ## [156] &quot;foram&quot; &quot;fora&quot; &quot;fôramos&quot; &quot;seja&quot; &quot;sejamos&quot; ## [161] &quot;sejam&quot; &quot;fosse&quot; &quot;fôssemos&quot; &quot;fossem&quot; &quot;for&quot; ## [166] &quot;formos&quot; &quot;forem&quot; &quot;serei&quot; &quot;será&quot; &quot;seremos&quot; ## [171] &quot;serão&quot; &quot;seria&quot; &quot;seríamos&quot; &quot;seriam&quot; &quot;tenho&quot; ## [176] &quot;tem&quot; &quot;temos&quot; &quot;tém&quot; &quot;tinha&quot; &quot;tínhamos&quot; ## [181] &quot;tinham&quot; &quot;tive&quot; &quot;teve&quot; &quot;tivemos&quot; &quot;tiveram&quot; ## [186] &quot;tivera&quot; &quot;tivéramos&quot; &quot;tenha&quot; &quot;tenhamos&quot; &quot;tenham&quot; ## [191] &quot;tivesse&quot; &quot;tivéssemos&quot; &quot;tivessem&quot; &quot;tiver&quot; &quot;tivermos&quot; ## [196] &quot;tiverem&quot; &quot;terei&quot; &quot;terá&quot; &quot;teremos&quot; &quot;terão&quot; ## [201] &quot;teria&quot; &quot;teríamos&quot; &quot;teriam&quot; Para aplicar esta função no nosso texto, usamos removeWords(texto, stopwords(\"pt\")) Para adicionar novas palavras, cria-se um novo vetor - chamamos aqui de “novas_stopwords” - com as novas palavras a serem retiradas, e em seguida o stopwords novas_stopwords &lt;- c(&quot;então&quot;, &quot;portanto&quot;, stopwords(&quot;pt&quot;)) # criando novo vetor com mais palavras # removeWords(texto, novas_stopwords) # removendo as stopwords 6.4 stemização (Stemming) e lematização 6.4.1 Palavras em contexto (keyword-in-context) CAPÍTULO AINDA EM CONSTRUÇÃO Podemos ver como certas palavras são usadas em diversas frases no texto para ter uma ideia melhor do contexto em que aparecem. No quanteda, usamos a função kwic(Dados, pattern = \"padrão\"). 6.5 Ngrams 6.5.1 GoogleNgrams A Google pegou sua enorme base de dados dos milhares de livros do Google Books e extraiu os termos mais frequentes, e os colocou disponível para consulta no site Goolge Books Ngram Viewer. O Google Ngrams facilitou a busca por ngrams nesta base de dados, naquilo que chamavam de “culturonomics”. O nome não pegou, a ferramenta tem suas limitações, mas ainda assim pode ser bem útil. A base de dados possui 5.2 milhões de livros, cerca de 4% de todos os livros já publicados. Para mais informações sobre a base de dados e sobre o GoogleNgram no site. Tanto o Python (com o get-ngrams) como o R (ngramr) possuem pacotes que usam os dados do Google Ngram. Instalando o pacote install.packages(&#39;ngramr&#39;) Carregando os pacote library(ngramr) E um exemplo de uso library(ggplot2) ## ## Attaching package: &#39;ggplot2&#39; ## The following object is masked from &#39;package:NLP&#39;: ## ## annotate ng &lt;- ngram(c(&quot;Max Weber&quot;, &quot;Émile Durkheim&quot;), year_start = 1890) ggplot(ng, aes(x=Year, y=Frequency, colour=Phrase)) + geom_line() Um exemplo da página do ngramr no Github com mais opções, usando a função ggram() no ngramr, que pega dados do GoogleNgram e plota os dados com o ggplot2: ggram(c(&quot;monarchy&quot;, &quot;democracy&quot;), year_start = 1500, year_end = 2000, corpus = &quot;eng_gb_2012&quot;, ignore_case = TRUE, geom = &quot;area&quot;, geom_options = list(position = &quot;stack&quot;)) + labs(y = NULL) É possível mudar entre diferentes corpus, que neste caso representam as diferentes línguas, como “eng_us_2019”, “eng_gb_2019”, “chi_sim_2019”, “fre_2019”, “ger_2019”, “heb_2019”, “ger_2012”, “spa_2012”, “rus_2012”, “ita_2012”. Para ver todos os corpus disponíveis veja no site busque a sessão “Corpora”. Infelizmente, não há corpus em português no Google Ngram. classicos = c(&quot;Max Weber&quot;, &quot;Émile Durkheim&quot;, &quot;Karl Marx&quot;, &quot;Gabriel Tarde&quot;, &quot;Georg Simmel&quot;) ggram(classicos, year_start = 1980, year_end = 2000, # Para mudar lingua, mude o corpus # ignore case: se diferencia maiúsculo de minúsculo corpus = &quot;fre_2019&quot;, ignore_case = TRUE, # tipo de grafico em geom geom = &quot;line&quot;, geom_options = list()) + # labs: label do eixo y labs(y = NULL) Dicas Ngramr: Site do Books Ngram Viewer explicando seus parâmetros. PDF com a documentação do ngramr Instalação/Primeiros passos com o Ngramr na página do Github do ngramr Um projeto similar ao Google Ngram - inclusive usando parte do mesmo pessoal - é o bookworm:HalthiTrust do projeto Halthi Trust-Digital Livrary, com muito mais línguas, inclusive o português e mais opções de busca. 6.5.2 TF-IDF EM CONSTRUÇÃO Dicas Analise Textual Julia Silge Learn tidytext with my new learnr course. Um curso interativo do pacote Tidytext. Textos sobre análise textual CASTELFRANCHI, Yurij. A análise de textos auxiliada pelo computador: um laboratório a céu aberto para as ciências sociais. Journal of Science Communication 16(02)(2017)C04 GRIMMER, Justin.STEWART, Brandom. Text as Data: The Promise and Pitfalls of Automatic ContentAnalysis Methods for Political Texts. Political Analysis(2013) pp. 1–31. doi:10.1093/pan/mps028. TREADWELL, Donald. Content Analysis: Understanding Text and Image in Numbers. Understanding Text and Image in Numbers. In __ Introducing Communication Research: paths of Inquiry. Sage. 2014. (Capítulo sobre análise de conteúdo) Link para diversos artigos de Gary King sobre Automated Text Analysis. Vídeos BROWN, Taylor W. Workshop on automated text analysis no Summer Institute in Computational Social Science na Universidade de Oxford em 2019. Em inglês, sem legendas, usando o pacote Quanteda. Parte 1 e Parte 2. O material da aula no Google Drive. "]]
